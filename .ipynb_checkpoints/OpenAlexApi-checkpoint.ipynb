{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2f9acc",
   "metadata": {},
   "source": [
    "NB! \n",
    "- Requirements: \n",
    "    - pip install openalexapi  \n",
    "    - pip install pdfminer OR pypdf \n",
    "\n",
    "# Libraries and packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8346be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access, use, and request OpenAlex \n",
    "import requests \n",
    "\n",
    "# To handle data \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv \n",
    "\n",
    "#To filter invalid pdf\n",
    "import pdfminer \n",
    "import pypdf \n",
    "\n",
    "#To handle files\n",
    "import glob\n",
    "import sys \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27fd6e",
   "metadata": {},
   "source": [
    "# Queries through OpenAlex \n",
    "\n",
    "First, I need to see if NeuroImage is among the sources available in OpenAlex's database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "493e3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching ID: https://openalex.org/S103225281\n"
     ]
    }
   ],
   "source": [
    "# There are 2 results when I search for sources with name 'NeuroImage'\n",
    "response_neuroimage = requests.get('https://api.openalex.org/sources?filter=display_name:NeuroImage').json()\n",
    "\n",
    "# For each result, I see which has issn 1095-9572 and issn_l 1053-8119, as that is the correct journal. \n",
    "# The target ISSN numbers to match\n",
    "target_issn = ['1095-9572', '1053-8119']\n",
    "\n",
    "# Variable to store the matching ID\n",
    "matching_id = None\n",
    "\n",
    "# Iterate through the results to find a match\n",
    "for result in response_neuroimage['results']:\n",
    "    # Check if the result's ISSN values match the target ISSN\n",
    "    if all(issn in result['issn'] for issn in target_issn):\n",
    "        # If both ISSN values are found, store the ID and break the loop\n",
    "        matching_id = result['id']\n",
    "        break\n",
    "\n",
    "# Print the matching ID (or None if no match was found)\n",
    "print(\"Matching ID:\", matching_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40fae808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the metadata about NeuroImage in Open Alex's database \n",
    "neuroimage_oa = requests.get(f'https://api.openalex.org/sources?filter=ids.openalex:{matching_id}').json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafecc2",
   "metadata": {},
   "source": [
    "Going through all of the 2022 articles manually and clicking 'Select all articles'(https://www-sciencedirect-com.ep.ituproxy.kb.dk/journal/neuroimage/issues), I get the following article counts: \n",
    "- Vol 264: 94 \n",
    "- Vol 263: 77\n",
    "- Vol 262: 33 \n",
    "- Vol 261: 25 \n",
    "- Vol 260: 55 \n",
    "- Vol 259: 33 \n",
    "- Vol 258: 50 \n",
    "- Vol 257: 62 \n",
    "- Vol 256: 43 \n",
    "- Vol 255: 41 \n",
    "- Vol 254: 42 \n",
    "- Vol 253: 37 \n",
    "- Vol 252: 30 \n",
    "- Vol 251: 44\n",
    "- Vol 250: 39 \n",
    "- Vol 249: 35 \n",
    "- Vol 248: 14 \n",
    "- Vol 247: 55 \n",
    "- Vol 246: 25 \n",
    "<br />\n",
    "<br />\n",
    "which is a total of 19 volumes containing 834 articles. The object identified by OpenAlex, with ID S103225281, has 826 articles published in 2022, which is a difference of 8 articles. \n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbbd4d04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles in the response for  https://api.openalex.org/works?filter=primary_location.source.id:https://openalex.org/S103225281,publication_year:2022,is_paratext:false :  812\n"
     ]
    }
   ],
   "source": [
    "# Common filter criteria for NeuroImage articles published in 2022\n",
    "neuroimage2022_filter = [\n",
    "    \"primary_location.source.id:\"+matching_id,\n",
    "    \"publication_year:2022\",  # Filter by the year 2022\n",
    "    \"is_paratext:false\",  # Exclude paratext\n",
    "]\n",
    "\n",
    "# Build the URL for the current source\n",
    "def build_neuroimage_works_url(filters):\n",
    "    base_url = 'https://api.openalex.org/works'\n",
    "    filters = ','.join(filters)\n",
    "    return f'{base_url}?filter={filters}'\n",
    "\n",
    "# Store the URL for the NeuroImage articles, filtered by 2022 and by being non-paratext articles\n",
    "neuroimage2022_url = build_neuroimage_works_url(neuroimage2022_filter)\n",
    "\n",
    "# Make a request to the API and store the JSON response\n",
    "response = requests.get(neuroimage2022_url).json()\n",
    "\n",
    "# Get the count of articles captured in the response\n",
    "print(\"Articles in the response for \", neuroimage2022_url, \": \", response['meta']['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3727a7",
   "metadata": {},
   "source": [
    "Looking at the journal with OpenAlex ID S103225281, there are 812 articles, excluding paratext articles (defined in their documentation as: \n",
    "\n",
    "    In our context, paratext is stuff that's in scholarly venue (like a journal) but is about the venue rather than a scholarly work properly speaking. Some examples and nonexamples: \n",
    "    \n",
    "    - yep it's paratext: front cover, back cover, tabel of contents, editorial board listing, issue information, masthead \n",
    "    - no, not paratext: research paper, dataset, lettors to the editor, figures. \n",
    "    \n",
    "Reference: https://docs.openalex.org/api-entities/works/work-object#is_paratext\n",
    "   <br> </br>  \n",
    "Looking at the different volumes of NeuroImage on Elsevier's website, each has an article titled 'Editorial board' as the first article in the journal. If these are excluded, due to the paratext attribute, that would leave 815 research articles (when we start at 834 total, from our manual count). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93cf0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all articles\n",
    "all_articles = []\n",
    "\n",
    "# Set the initial page number to 1\n",
    "page = 1\n",
    "\n",
    "# Loop until all articles are retrieved\n",
    "while True:\n",
    "    # Make a request to the API with the current page number\n",
    "    response = requests.get(neuroimage2022_url, params={\"page\": page})\n",
    "\n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract articles from the current page and append to the list\n",
    "        articles_on_page = data.get(\"results\", [])\n",
    "        all_articles.extend(articles_on_page)\n",
    "\n",
    "        # Check if there are more pages to fetch\n",
    "        if len(articles_on_page) == 0 or page * data['meta']['per_page'] >= data['meta']['count']:\n",
    "            break\n",
    "\n",
    "        # Increment the page number for the next request\n",
    "        page += 1\n",
    "    else:\n",
    "        print(\"Error fetching data. Status code:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from all articles\n",
    "articles_df = pd.DataFrame(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7d1717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'fulltext_oa_url' column: \n",
    "articles_df['fulltext_oa_url'] = articles_df['open_access'].apply(lambda x: x.get('oa_url') if isinstance(x, dict) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5068ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://doi.org/10.1016/j.neuroimage.2021.118870\n",
       "1      https://doi.org/10.1016/j.neuroimage.2021.118788\n",
       "2      https://doi.org/10.1016/j.neuroimage.2022.119027\n",
       "3      https://doi.org/10.1016/j.neuroimage.2021.118774\n",
       "4      https://doi.org/10.1016/j.neuroimage.2021.118789\n",
       "                             ...                       \n",
       "807    https://doi.org/10.1016/j.neuroimage.2022.119731\n",
       "808    https://doi.org/10.1016/j.neuroimage.2022.119749\n",
       "809    https://doi.org/10.1016/j.neuroimage.2022.119747\n",
       "810    https://doi.org/10.1016/j.neuroimage.2022.119752\n",
       "811    https://doi.org/10.1016/j.neuroimage.2022.119766\n",
       "Name: doi, Length: 812, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df['doi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c8aeb",
   "metadata": {},
   "source": [
    "# Get PDF's\n",
    "\n",
    "I want to download the fulltext of all the articles in OpenAlex from NeuroImage. \n",
    "I used a part of code written by Théo Sourget to get the PDF's. The code in the file with the following breadcrumb: code/other/download_fulltext.ipynb\n",
    "\n",
    "Reference: \n",
    "Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "caffa99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pypdf import PdfFileReader, PdfFileWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5067d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = articles_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9f914",
   "metadata": {},
   "source": [
    "At this point we have access to the pdf of the article. We first want to check whether the name of the dataset appears in the tables. The hypothesis is that if a dataset name appears in a table, it must be a table of results. And since we have removed the review papers from the list, this should indicate that the dataset is really used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab1ec404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Quantitative mapping of the brain’s structural connectivity using diffusion MRI tractography: A review\n",
      "DOI:  https://doi.org/10.1016/j.neuroimage.2021.118870\n",
      "Fulltext_url:  https://doi.org/10.1016/j.neuroimage.2021.118870\n",
      "<Response [200]>\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../OpenAlex/downloaded_pdf/Quantitative mapping of the brain’s structural connectivity using diffusion MRI tractography: A review.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m pdf_content \u001b[38;5;241m=\u001b[39m r_fulltext\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r_fulltext\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Save the PDF to the download folder\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mwrite(pdf_content)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#with open(file_path, \"wb\") as pdf_file:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m#pdf_file.write(pdf_content)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     downloaded_doi\u001b[38;5;241m.\u001b[39mappend(doi)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../OpenAlex/downloaded_pdf/Quantitative mapping of the brain’s structural connectivity using diffusion MRI tractography: A review.pdf'"
     ]
    }
   ],
   "source": [
    "# Define the folder where PDFs will be downloaded\n",
    "pdf_folder = \"../Thesis/Code/OpenAlex/downloaded_pdf/\"\n",
    "downloaded_doi = []\n",
    "title_to_doi = {}\n",
    "\n",
    "# Create the download folder if it doesn't exist\n",
    "if not os.path.exists(pdf_folder):\n",
    "    os.makedirs(pdf_folder)\n",
    "    \n",
    "# Iterate through the articles in articles_df\n",
    "for index, row in test.iterrows():\n",
    "    title = row['title'].replace('/', '')\n",
    "    doi = row['doi']\n",
    "    fulltext_url = row['fulltext_oa_url']\n",
    "    print(\"Title: \", title)\n",
    "    print(\"DOI: \", doi)\n",
    "    print(\"Fulltext_url: \", fulltext_url)\n",
    "    file_path = f\"../OpenAlex/downloaded_pdf/{title}.pdf\"   \n",
    "    \n",
    "    if title not in title_to_doi: \n",
    "        title_to_doi[title] = doi\n",
    "    if not fulltext_url:\n",
    "        continue\n",
    "    if file_path in pdf_folder:\n",
    "        continue \n",
    "\n",
    "    # Check if the DOI has already been downloaded\n",
    "    if doi not in downloaded_doi:\n",
    "        try: \n",
    "            r_fulltext = requests.get(fulltext_url, allow_redirects=True, timeout=10)\n",
    "            print(r_fulltext)\n",
    "            pdf_content = r_fulltext.content\n",
    "            if r_fulltext.status_code == 200:\n",
    "                # Save the PDF to the download folder\n",
    "                open(file_path, \"wb\").write(pdf_content)\n",
    "                #with open(file_path, \"wb\") as pdf_file:\n",
    "                    #pdf_file.write(pdf_content)\n",
    "                downloaded_doi.append(doi)\n",
    "            else:\n",
    "                continue\n",
    "        except requests.exceptions.RequestException as ce: \n",
    "            continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ee9972e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of downloaded fulltext: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of downloaded fulltext: {len(downloaded_doi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "        try:\n",
    "            # Try to read the PDF (raise an error if the file is an invalid PDF)\n",
    "            PdfReader(file_path,strict=True)\n",
    "        except PdfReadError: \n",
    "            # If there's an error reading the PDF, remove it from the downloaded list and delete the file\n",
    "            downloaded_doi.remove(doi)\n",
    "            continue\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be66e4",
   "metadata": {},
   "source": [
    "WHAT I WANT: \n",
    "- CSV/DATABASE where I can \n",
    "    - see how many articles are published in each volume (so I can check compared to Elsevier) \n",
    "    - get all the metadata and the url's for all the articles \n",
    "        - FROM THE URL I need to be able to search the texts for their databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a127cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all articles\n",
    "all_articles = []\n",
    "\n",
    "# Set the initial page number to 1\n",
    "page = 1\n",
    "\n",
    "# Loop until all articles are retrieved\n",
    "while True:\n",
    "    # Make a request to the API with the current page number\n",
    "    response = requests.get(neuroimage2022_url, params={\"page\": page})\n",
    "\n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract articles from the current page and append to the list\n",
    "        articles_on_page = data.get(\"results\", [])\n",
    "        all_articles.extend(articles_on_page)\n",
    "\n",
    "        # Check if there are more pages to fetch\n",
    "        if len(articles_on_page) == 0 or page * data['meta']['per_page'] >= data['meta']['count']:\n",
    "            break\n",
    "\n",
    "        # Increment the page number for the next request\n",
    "        page += 1\n",
    "    else:\n",
    "        print(\"Error fetching data. Status code:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from all articles\n",
    "df = pd.DataFrame(all_articles)\n",
    "\n",
    "# Export to CSV if needed\n",
    "# df.to_csv('articles.csv', index=False)\n",
    "\n",
    "# Print the total number of articles retrieved\n",
    "# print(\"Total articles retrieved:\", len(all_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcec8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'any_repository_has_fulltext' = True: 547\n",
      "Count of 'any_repository_has_fulltext' = False: 265\n",
      "Count of 'any_repository_has_fulltext' = NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# open_access is an object, that contains information about the access status of this work, as an  object\n",
    "# https://docs.openalex.org/api-entities/works/work-object#open_access \n",
    "# Initialize counters\n",
    "true_count = 0\n",
    "false_count = 0\n",
    "nan_count = 0\n",
    "\n",
    "# Iterate through rows and count True, False, and NaN\n",
    "for index, row in df.iterrows():\n",
    "    value = row['open_access'].get('any_repository_has_fulltext', np.nan)\n",
    "    if pd.isna(value):\n",
    "        nan_count += 1\n",
    "    elif value == True:\n",
    "        true_count += 1\n",
    "    elif value == False:\n",
    "        false_count += 1\n",
    "\n",
    "print(\"Count of 'any_repository_has_fulltext' = True:\", true_count)\n",
    "print(\"Count of 'any_repository_has_fulltext' = False:\", false_count)\n",
    "print(\"Count of 'any_repository_has_fulltext' = NaN:\", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b9789c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>display_name</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>ids</th>\n",
       "      <th>language</th>\n",
       "      <th>primary_location</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>grants</th>\n",
       "      <th>referenced_works_count</th>\n",
       "      <th>referenced_works</th>\n",
       "      <th>related_works</th>\n",
       "      <th>ngrams_url</th>\n",
       "      <th>abstract_inverted_index</th>\n",
       "      <th>cited_by_api_url</th>\n",
       "      <th>counts_by_year</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W3216528674</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2021.118774</td>\n",
       "      <td>A dynamic graph convolutional neural network f...</td>\n",
       "      <td>A dynamic graph convolutional neural network f...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3216528674...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'funder': 'https://openalex.org/F4320306076'...</td>\n",
       "      <td>54</td>\n",
       "      <td>[https://openalex.org/W1560723556, https://ope...</td>\n",
       "      <td>[https://openalex.org/W2087328730, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works/W3216528674/ngrams</td>\n",
       "      <td>{'The': [0, 200], 'pathological': [1], 'mechan...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W3...</td>\n",
       "      <td>[{'year': 2023, 'cited_by_count': 15}, {'year'...</td>\n",
       "      <td>2023-09-13T20:23:41.636399</td>\n",
       "      <td>2021-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://openalex.org/W4200619774</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2021.118746</td>\n",
       "      <td>Ongoing neural oscillations influence behavior...</td>\n",
       "      <td>Ongoing neural oscillations influence behavior...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4200619774...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>142</td>\n",
       "      <td>[https://openalex.org/W1449283962, https://ope...</td>\n",
       "      <td>[https://openalex.org/W176629368, https://open...</td>\n",
       "      <td>https://api.openalex.org/works/W4200619774/ngrams</td>\n",
       "      <td>{'The': [0], 'ability': [1], 'to': [2, 6, 38, ...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[{'year': 2023, 'cited_by_count': 14}, {'year'...</td>\n",
       "      <td>2023-09-02T13:08:24.356239</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://openalex.org/W4210518162</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.118970</td>\n",
       "      <td>Brain structure-function coupling provides sig...</td>\n",
       "      <td>Brain structure-function coupling provides sig...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4210518162...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'funder': 'https://openalex.org/F4320320924'...</td>\n",
       "      <td>70</td>\n",
       "      <td>[https://openalex.org/W795339718, https://open...</td>\n",
       "      <td>[https://openalex.org/W2295675667, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works/W4210518162/ngrams</td>\n",
       "      <td>{'Brain': [0], 'signatures': [1, 32, 219], 'of...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[{'year': 2023, 'cited_by_count': 11}, {'year'...</td>\n",
       "      <td>2023-09-11T16:48:03.504543</td>\n",
       "      <td>2022-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://openalex.org/W4210709080</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.118974</td>\n",
       "      <td>Periodic/Aperiodic parameterization of transie...</td>\n",
       "      <td>Periodic/Aperiodic parameterization of transie...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4210709080...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>67</td>\n",
       "      <td>[https://openalex.org/W155683135, https://open...</td>\n",
       "      <td>[https://openalex.org/W592157012, https://open...</td>\n",
       "      <td>https://api.openalex.org/works/W4210709080/ngrams</td>\n",
       "      <td>{'Two': [0], 'techniques': [1], 'for': [2, 83]...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[{'year': 2023, 'cited_by_count': 8}, {'year':...</td>\n",
       "      <td>2023-08-29T20:40:42.907402</td>\n",
       "      <td>2022-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>https://openalex.org/W4213387819</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.119009</td>\n",
       "      <td>Patterns of a structural covariance network as...</td>\n",
       "      <td>Patterns of a structural covariance network as...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4213387819...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>118</td>\n",
       "      <td>[https://openalex.org/W964942278, https://open...</td>\n",
       "      <td>[https://openalex.org/W1973509935, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works/W4213387819/ngrams</td>\n",
       "      <td>{'Dispositional': [0], 'optimism': [1, 31, 140...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[{'year': 2023, 'cited_by_count': 10}, {'year'...</td>\n",
       "      <td>2023-09-13T13:36:11.114564</td>\n",
       "      <td>2022-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>https://openalex.org/W4308346205</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.119704</td>\n",
       "      <td>Ventral tegmental area integrity measured with...</td>\n",
       "      <td>Ventral tegmental area integrity measured with...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4308346205...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>74</td>\n",
       "      <td>[https://openalex.org/W1219461777, https://ope...</td>\n",
       "      <td>[https://openalex.org/W1983138582, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works/W4308346205/ngrams</td>\n",
       "      <td>{'The': [0], 'ventral': [1], 'tegmental': [2],...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2023-09-11T10:36:33.410750</td>\n",
       "      <td>2022-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>https://openalex.org/W4308432229</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.119739</td>\n",
       "      <td>Group polarization calls for group-level brain...</td>\n",
       "      <td>Group polarization calls for group-level brain...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4308432229...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'funder': 'https://openalex.org/F4320321001'...</td>\n",
       "      <td>85</td>\n",
       "      <td>[https://openalex.org/W1526866867, https://ope...</td>\n",
       "      <td>[https://openalex.org/W348899774, https://open...</td>\n",
       "      <td>https://api.openalex.org/works/W4308432229/ngrams</td>\n",
       "      <td>{'Group': [0], 'of': [1, 8, 20, 32, 54, 120, 1...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2023-09-01T00:21:26.910969</td>\n",
       "      <td>2022-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>https://openalex.org/W4308479179</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.119731</td>\n",
       "      <td>Behavioral and neural representation of expect...</td>\n",
       "      <td>Behavioral and neural representation of expect...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4308479179...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>65</td>\n",
       "      <td>[https://openalex.org/W1499836032, https://ope...</td>\n",
       "      <td>[https://openalex.org/W1972742627, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works/W4308479179/ngrams</td>\n",
       "      <td>{'When': [0], 'faced': [1], 'with': [2, 187, 2...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2023-08-30T14:14:24.484562</td>\n",
       "      <td>2022-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>https://openalex.org/W4309294048</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.119747</td>\n",
       "      <td>Optimising the sensing volume of OPM sensors f...</td>\n",
       "      <td>Optimising the sensing volume of OPM sensors f...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4309294048...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>48</td>\n",
       "      <td>[https://openalex.org/W1976755501, https://ope...</td>\n",
       "      <td>[https://openalex.org/W1999107116, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works/W4309294048/ngrams</td>\n",
       "      <td>{'Magnetoencephalography': [0], '(MEG)': [1], ...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2023-09-13T06:30:04.653841</td>\n",
       "      <td>2022-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>https://openalex.org/W4309797002</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.119766</td>\n",
       "      <td>Evidence for predictions established by phanto...</td>\n",
       "      <td>Evidence for predictions established by phanto...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4309797002...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>article</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'funder': 'https://openalex.org/F4320321001'...</td>\n",
       "      <td>70</td>\n",
       "      <td>[https://openalex.org/W1964934384, https://ope...</td>\n",
       "      <td>[https://openalex.org/W2015649174, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works/W4309797002/ngrams</td>\n",
       "      <td>{'Predictions,': [0], 'the': [1, 4, 31, 42, 71...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W4...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2023-09-15T01:33:33.549151</td>\n",
       "      <td>2022-11-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  \\\n",
       "3    https://openalex.org/W3216528674   \n",
       "17   https://openalex.org/W4200619774   \n",
       "32   https://openalex.org/W4210518162   \n",
       "37   https://openalex.org/W4210709080   \n",
       "39   https://openalex.org/W4213387819   \n",
       "..                                ...   \n",
       "805  https://openalex.org/W4308346205   \n",
       "806  https://openalex.org/W4308432229   \n",
       "807  https://openalex.org/W4308479179   \n",
       "809  https://openalex.org/W4309294048   \n",
       "811  https://openalex.org/W4309797002   \n",
       "\n",
       "                                                  doi  \\\n",
       "3    https://doi.org/10.1016/j.neuroimage.2021.118774   \n",
       "17   https://doi.org/10.1016/j.neuroimage.2021.118746   \n",
       "32   https://doi.org/10.1016/j.neuroimage.2022.118970   \n",
       "37   https://doi.org/10.1016/j.neuroimage.2022.118974   \n",
       "39   https://doi.org/10.1016/j.neuroimage.2022.119009   \n",
       "..                                                ...   \n",
       "805  https://doi.org/10.1016/j.neuroimage.2022.119704   \n",
       "806  https://doi.org/10.1016/j.neuroimage.2022.119739   \n",
       "807  https://doi.org/10.1016/j.neuroimage.2022.119731   \n",
       "809  https://doi.org/10.1016/j.neuroimage.2022.119747   \n",
       "811  https://doi.org/10.1016/j.neuroimage.2022.119766   \n",
       "\n",
       "                                                 title  \\\n",
       "3    A dynamic graph convolutional neural network f...   \n",
       "17   Ongoing neural oscillations influence behavior...   \n",
       "32   Brain structure-function coupling provides sig...   \n",
       "37   Periodic/Aperiodic parameterization of transie...   \n",
       "39   Patterns of a structural covariance network as...   \n",
       "..                                                 ...   \n",
       "805  Ventral tegmental area integrity measured with...   \n",
       "806  Group polarization calls for group-level brain...   \n",
       "807  Behavioral and neural representation of expect...   \n",
       "809  Optimising the sensing volume of OPM sensors f...   \n",
       "811  Evidence for predictions established by phanto...   \n",
       "\n",
       "                                          display_name  publication_year  \\\n",
       "3    A dynamic graph convolutional neural network f...              2022   \n",
       "17   Ongoing neural oscillations influence behavior...              2022   \n",
       "32   Brain structure-function coupling provides sig...              2022   \n",
       "37   Periodic/Aperiodic parameterization of transie...              2022   \n",
       "39   Patterns of a structural covariance network as...              2022   \n",
       "..                                                 ...               ...   \n",
       "805  Ventral tegmental area integrity measured with...              2022   \n",
       "806  Group polarization calls for group-level brain...              2022   \n",
       "807  Behavioral and neural representation of expect...              2022   \n",
       "809  Optimising the sensing volume of OPM sensors f...              2022   \n",
       "811  Evidence for predictions established by phanto...              2022   \n",
       "\n",
       "    publication_date                                                ids  \\\n",
       "3         2022-02-01  {'openalex': 'https://openalex.org/W3216528674...   \n",
       "17        2022-02-01  {'openalex': 'https://openalex.org/W4200619774...   \n",
       "32        2022-04-01  {'openalex': 'https://openalex.org/W4210518162...   \n",
       "37        2022-05-01  {'openalex': 'https://openalex.org/W4210709080...   \n",
       "39        2022-05-01  {'openalex': 'https://openalex.org/W4213387819...   \n",
       "..               ...                                                ...   \n",
       "805       2022-12-01  {'openalex': 'https://openalex.org/W4308346205...   \n",
       "806       2022-12-01  {'openalex': 'https://openalex.org/W4308432229...   \n",
       "807       2022-12-01  {'openalex': 'https://openalex.org/W4308479179...   \n",
       "809       2022-12-01  {'openalex': 'https://openalex.org/W4309294048...   \n",
       "811       2022-12-01  {'openalex': 'https://openalex.org/W4309797002...   \n",
       "\n",
       "    language                                   primary_location     type  ...  \\\n",
       "3         en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "17        en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "32        en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "37        en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "39        en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "..       ...                                                ...      ...  ...   \n",
       "805       en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "806       en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "807       en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "809       en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "811       en  {'is_oa': True, 'landing_page_url': 'https://d...  article  ...   \n",
       "\n",
       "                                                grants referenced_works_count  \\\n",
       "3    [{'funder': 'https://openalex.org/F4320306076'...                     54   \n",
       "17                                                  []                    142   \n",
       "32   [{'funder': 'https://openalex.org/F4320320924'...                     70   \n",
       "37                                                  []                     67   \n",
       "39                                                  []                    118   \n",
       "..                                                 ...                    ...   \n",
       "805                                                 []                     74   \n",
       "806  [{'funder': 'https://openalex.org/F4320321001'...                     85   \n",
       "807                                                 []                     65   \n",
       "809                                                 []                     48   \n",
       "811  [{'funder': 'https://openalex.org/F4320321001'...                     70   \n",
       "\n",
       "                                      referenced_works  \\\n",
       "3    [https://openalex.org/W1560723556, https://ope...   \n",
       "17   [https://openalex.org/W1449283962, https://ope...   \n",
       "32   [https://openalex.org/W795339718, https://open...   \n",
       "37   [https://openalex.org/W155683135, https://open...   \n",
       "39   [https://openalex.org/W964942278, https://open...   \n",
       "..                                                 ...   \n",
       "805  [https://openalex.org/W1219461777, https://ope...   \n",
       "806  [https://openalex.org/W1526866867, https://ope...   \n",
       "807  [https://openalex.org/W1499836032, https://ope...   \n",
       "809  [https://openalex.org/W1976755501, https://ope...   \n",
       "811  [https://openalex.org/W1964934384, https://ope...   \n",
       "\n",
       "                                         related_works  \\\n",
       "3    [https://openalex.org/W2087328730, https://ope...   \n",
       "17   [https://openalex.org/W176629368, https://open...   \n",
       "32   [https://openalex.org/W2295675667, https://ope...   \n",
       "37   [https://openalex.org/W592157012, https://open...   \n",
       "39   [https://openalex.org/W1973509935, https://ope...   \n",
       "..                                                 ...   \n",
       "805  [https://openalex.org/W1983138582, https://ope...   \n",
       "806  [https://openalex.org/W348899774, https://open...   \n",
       "807  [https://openalex.org/W1972742627, https://ope...   \n",
       "809  [https://openalex.org/W1999107116, https://ope...   \n",
       "811  [https://openalex.org/W2015649174, https://ope...   \n",
       "\n",
       "                                            ngrams_url  \\\n",
       "3    https://api.openalex.org/works/W3216528674/ngrams   \n",
       "17   https://api.openalex.org/works/W4200619774/ngrams   \n",
       "32   https://api.openalex.org/works/W4210518162/ngrams   \n",
       "37   https://api.openalex.org/works/W4210709080/ngrams   \n",
       "39   https://api.openalex.org/works/W4213387819/ngrams   \n",
       "..                                                 ...   \n",
       "805  https://api.openalex.org/works/W4308346205/ngrams   \n",
       "806  https://api.openalex.org/works/W4308432229/ngrams   \n",
       "807  https://api.openalex.org/works/W4308479179/ngrams   \n",
       "809  https://api.openalex.org/works/W4309294048/ngrams   \n",
       "811  https://api.openalex.org/works/W4309797002/ngrams   \n",
       "\n",
       "                               abstract_inverted_index  \\\n",
       "3    {'The': [0, 200], 'pathological': [1], 'mechan...   \n",
       "17   {'The': [0], 'ability': [1], 'to': [2, 6, 38, ...   \n",
       "32   {'Brain': [0], 'signatures': [1, 32, 219], 'of...   \n",
       "37   {'Two': [0], 'techniques': [1], 'for': [2, 83]...   \n",
       "39   {'Dispositional': [0], 'optimism': [1, 31, 140...   \n",
       "..                                                 ...   \n",
       "805  {'The': [0], 'ventral': [1], 'tegmental': [2],...   \n",
       "806  {'Group': [0], 'of': [1, 8, 20, 32, 54, 120, 1...   \n",
       "807  {'When': [0], 'faced': [1], 'with': [2, 187, 2...   \n",
       "809  {'Magnetoencephalography': [0], '(MEG)': [1], ...   \n",
       "811  {'Predictions,': [0], 'the': [1, 4, 31, 42, 71...   \n",
       "\n",
       "                                      cited_by_api_url  \\\n",
       "3    https://api.openalex.org/works?filter=cites:W3...   \n",
       "17   https://api.openalex.org/works?filter=cites:W4...   \n",
       "32   https://api.openalex.org/works?filter=cites:W4...   \n",
       "37   https://api.openalex.org/works?filter=cites:W4...   \n",
       "39   https://api.openalex.org/works?filter=cites:W4...   \n",
       "..                                                 ...   \n",
       "805  https://api.openalex.org/works?filter=cites:W4...   \n",
       "806  https://api.openalex.org/works?filter=cites:W4...   \n",
       "807  https://api.openalex.org/works?filter=cites:W4...   \n",
       "809  https://api.openalex.org/works?filter=cites:W4...   \n",
       "811  https://api.openalex.org/works?filter=cites:W4...   \n",
       "\n",
       "                                        counts_by_year  \\\n",
       "3    [{'year': 2023, 'cited_by_count': 15}, {'year'...   \n",
       "17   [{'year': 2023, 'cited_by_count': 14}, {'year'...   \n",
       "32   [{'year': 2023, 'cited_by_count': 11}, {'year'...   \n",
       "37   [{'year': 2023, 'cited_by_count': 8}, {'year':...   \n",
       "39   [{'year': 2023, 'cited_by_count': 10}, {'year'...   \n",
       "..                                                 ...   \n",
       "805                                                 []   \n",
       "806                                                 []   \n",
       "807                                                 []   \n",
       "809                                                 []   \n",
       "811                                                 []   \n",
       "\n",
       "                   updated_date  created_date  \n",
       "3    2023-09-13T20:23:41.636399    2021-12-06  \n",
       "17   2023-09-02T13:08:24.356239    2021-12-31  \n",
       "32   2023-09-11T16:48:03.504543    2022-02-08  \n",
       "37   2023-08-29T20:40:42.907402    2022-02-08  \n",
       "39   2023-09-13T13:36:11.114564    2022-02-24  \n",
       "..                          ...           ...  \n",
       "805  2023-09-11T10:36:33.410750    2022-11-11  \n",
       "806  2023-09-01T00:21:26.910969    2022-11-11  \n",
       "807  2023-08-30T14:14:24.484562    2022-11-12  \n",
       "809  2023-09-13T06:30:04.653841    2022-11-25  \n",
       "811  2023-09-15T01:33:33.549151    2022-11-29  \n",
       "\n",
       "[265 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where 'any_repository_has_fulltext' is False\n",
    "filtered_df = df[df['open_access'].apply(lambda x: x.get('any_repository_has_fulltext', False) == False)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "442e0894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id1 = df['id'].iloc[0]\n",
    "response = requests.get(f'https://api.openalex.org/works/{id1}/ngrams')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0855bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each ID in filtered_df['id'], do a fulltext.search for the words 'Data and code availability'\n",
    "# fulltext.search \n",
    "# ids.openalex: filtered_df['id'] \n",
    "\n",
    "# Define the OpenAlex API base URL\n",
    "openalex_base_url = 'https://api.openalex.org/works?filter='\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate through the 'id' column in filtered_df\n",
    "for article_id in df['id'].iloc[0]:\n",
    "    # Construct the URL for the fulltext.search endpoint\n",
    "    fulltext_search_url = openalex_base_url + f'ids.openalex:{article_id}?fulltext.search:Data%and%code%availability'\n",
    "    #print(fulltext_search_url)\n",
    "    \n",
    "    # Make a request to OpenAlex\n",
    "    response = requests.get(fulltext_search_url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response and append it to the results list\n",
    "        results.append(response.json())\n",
    "    else:\n",
    "        # Handle any errors or exceptions here\n",
    "        print(f\"Error fetching data for article ID {article_id}\")\n",
    "\n",
    "# results now contains the responses for each article\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "977f12ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for article ID h\n",
      "Error fetching data for article ID t\n",
      "Error fetching data for article ID t\n",
      "Error fetching data for article ID p\n",
      "Error fetching data for article ID s\n",
      "Error fetching data for article ID :\n",
      "Error fetching data for article ID /\n",
      "Error fetching data for article ID /\n",
      "Error fetching data for article ID o\n",
      "Error fetching data for article ID p\n",
      "Error fetching data for article ID e\n",
      "Error fetching data for article ID n\n",
      "Error fetching data for article ID a\n",
      "Error fetching data for article ID l\n",
      "Error fetching data for article ID e\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m fulltext_search_url \u001b[38;5;241m=\u001b[39m openalex_base_url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids.openalex:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marticle_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?fulltext.search:Data%and%code%availability\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print(fulltext_search_url)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make a request to OpenAlex\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfulltext_search_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Check if the request was successful (status code 200)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Parse the JSON response and append it to the results list\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:1040\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1043\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1044\u001b[0m         (\n\u001b[1;32m   1045\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1051\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:414\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_default_certs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    411\u001b[0m ):\n\u001b[1;32m    412\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    431\u001b[0m     default_ssl_context\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39mversion() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    435\u001b[0m ):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    437\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         SNIMissingWarning,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[0;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[0;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   1038\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For each ID in filtered_df['id'], do a fulltext.search for the words 'Data and code availability'\n",
    "# fulltext.search \n",
    "# ids.openalex: filtered_df['id'] \n",
    "\n",
    "# Define the OpenAlex API base URL\n",
    "openalex_base_url = 'https://api.openalex.org/works?filter='\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate through the 'id' column in filtered_df\n",
    "for article_id in df['id'].iloc[0]:\n",
    "    # Construct the URL for the fulltext.search endpoint\n",
    "    fulltext_search_url = openalex_base_url + f'ids.openalex:{article_id}?fulltext.search:Data%and%code%availability'\n",
    "    #print(fulltext_search_url)\n",
    "    \n",
    "    # Make a request to OpenAlex\n",
    "    response = requests.get(fulltext_search_url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response and append it to the results list\n",
    "        results.append(response.json())\n",
    "    else:\n",
    "        # Handle any errors or exceptions here\n",
    "        print(f\"Error fetching data for article ID {article_id}\")\n",
    "\n",
    "# results now contains the responses for each article\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c691e91",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
