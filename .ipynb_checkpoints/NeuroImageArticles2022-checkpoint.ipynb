{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04514d4",
   "metadata": {},
   "source": [
    "# 0. Setup \n",
    "\n",
    "In this file, I download all papers published in the NeuroImage journal in 2022. \n",
    "\n",
    "## 0.1 Pipeline \n",
    "\n",
    "1. Pick targets \n",
    "2. Find input \n",
    "3. Run downloader \n",
    "4. Read PDFs \n",
    "5. Save results \n",
    "\n",
    "### 0.1.1. Target issues \n",
    "\n",
    "NeuroImage 2022: https://www.sciencedirect.com/journal/neuroimage/issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a21c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = 0\n",
    "# 246-264"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76124f25",
   "metadata": {},
   "source": [
    "### 0.1.2. Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440588d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import json \n",
    "\n",
    "import elsapy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa4bf1",
   "metadata": {},
   "source": [
    "### 0.1.3 Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfcdf6e",
   "metadata": {},
   "source": [
    "# 1. Scrape journal links \n",
    "\n",
    "I have to use Elsevier's API, using the API I generated at the beginning of this project. \n",
    "\n",
    "I use the Python SDK called **elsapy** (github link). \n",
    "I use the code in the file 'exampleProg.py'. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b3dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API key is free and available on https://dev.elsevier.com/\n",
    "# 5e101447f9a3293a580f41e255b2aba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "\n",
    "## Load configuration - it contains my API key, which is free and was created using https://dev.elsevier.com/\n",
    "con_file = open(\"config.json\")\n",
    "config = json.load(con_file)\n",
    "con_file.close()\n",
    "\n",
    "## Initialize client\n",
    "client = ElsClient(config['apikey'])\n",
    "\n",
    "# Define the search query to find NeuroImage articles published in 2022\n",
    "search_query = 'jr(NEUROIMAGE) AND pubyear=2022'\n",
    "\n",
    "# Initialize the document search object\n",
    "doc_search = ElsSearch(search_query, 'sciencedirect')\n",
    "\n",
    "# Execute the search\n",
    "doc_search.execute(client)\n",
    "\n",
    "# Print the number of results\n",
    "print(f\"Found {len(doc_search.results)} NeuroImage articles published in 2022 on ScienceDirect.\")\n",
    "\n",
    "# Print the titles of the articles\n",
    "for result in doc_search.results:\n",
    "    print(\"Title:\", result['dc:title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a10197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.elsevier.com/content/search/sciencedirect\n",
      "Error: 401 - {\"service-error\":{\"status\":{\"statusCode\":\"AUTHORIZATION_ERROR\",\"statusText\":\"The requestor is not authorized to access the requested view or fields of the resource\"}}}\n"
     ]
    }
   ],
   "source": [
    "headers = {}\n",
    "headers['Accept']='application/json'\n",
    "headers['X-ELS-APIKey'] = '5e101447f9a3293a580f41e255b2aba8'\n",
    "headers['Content-Type'] = 'application/json'\n",
    "\n",
    "data = {\n",
    "        'qs':'(\"NeuroImage\"\") AND (2022)'\n",
    "       } \n",
    "\n",
    "Url = \"https://api.elsevier.com/content/search/sciencedirect\"\n",
    "\n",
    "r = requests.put(Url, data =json.dumps(data), headers=headers)\n",
    "\n",
    "print(r.url)\n",
    "      \n",
    "# Check if the request was successful\n",
    "if r.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    result_data = r.json()\n",
    "\n",
    "    # Extract the list of article entries\n",
    "    articles = result_data.get('results', [])\n",
    "\n",
    "    # Initialize an empty list to store the article metadata\n",
    "    article_metadata = []\n",
    "\n",
    "    # Extract article metadata\n",
    "    for article in articles:\n",
    "        title = article.get('dc:title', 'N/A')\n",
    "        authors = ', '.join(author.get('preferred-name', {}).get('ce:indexed-name', 'N/A') for author in article.get('authors', []))\n",
    "        pub_date = article.get('prism:coverDate', 'N/A')\n",
    "        doi = article.get('prism:doi', 'N/A')\n",
    "        source_title = article.get('prism:publicationName', 'N/A')\n",
    "\n",
    "        article_metadata.append({\n",
    "            'Title': title,\n",
    "            'Authors': authors,\n",
    "            'Publication Date': pub_date,\n",
    "            'DOI': doi,\n",
    "            'Source Title': source_title,\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the article metadata\n",
    "    df = pd.DataFrame(article_metadata)\n",
    "\n",
    "    # Save the metadata as a CSV file\n",
    "    df.to_csv('NeuroImage_2022_Metadata.csv', index=False)\n",
    "\n",
    "    print(f\"Saved {len(df)} articles' metadata to NeuroImage_2022_Metadata.csv.\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8551dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [401]>\n",
      "Saved 0 articles' metadata to NeuroImage_2022_Metadata.csv.\n"
     ]
    }
   ],
   "source": [
    "# The API key is free and available on https://dev.elsevier.com/\n",
    "api_key = '5e101447f9a3293a580f41e255b2aba8'\n",
    "\n",
    "# Define the base URL for the Scopus API\n",
    "base_url = 'https://api.elsevier.com/content/search/scopus'\n",
    "\n",
    "# Define the search query to find NeuroImage articles published in 2022\n",
    "search_query = 'TITLE-ABS-KEY(\"NeuroImage\") AND PUBYEAR = 2022'\n",
    "\n",
    "# Define the headers with your API key and desired response format\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'X-ELS-APIKey': api_key,\n",
    "}\n",
    "\n",
    "# Define additional query parameters\n",
    "params = {\n",
    "    'query': search_query,\n",
    "    'count': '200',  # Increase count to retrieve more results if necessary\n",
    "    'view': 'COMPLETE',\n",
    "    'start': '0',\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the article metadata\n",
    "article_metadata = []\n",
    "\n",
    "# Fetch articles in batches until there are no more results\n",
    "while True:\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    print(response)\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if there are no more results\n",
    "    if 'results' not in data:\n",
    "        break\n",
    "    \n",
    "    # Extract article metadata from the response\n",
    "    for entry in data['results']:\n",
    "        article_metadata.append({\n",
    "            'Title': entry.get('dc:title', ''),\n",
    "            'Authors': ', '.join(author['authname'] for author in entry.get('author', [])),\n",
    "            'Publication Date': entry.get('prism:coverDate', ''),\n",
    "            'DOI': entry.get('prism:doi', ''),\n",
    "            'Source Title': entry.get('prism:publicationName', ''),\n",
    "        })\n",
    "    \n",
    "    # Update the 'start' parameter to fetch the next batch\n",
    "    params['start'] = str(int(params['start']) + len(data['results']))\n",
    "\n",
    "# Create a DataFrame from the article metadata\n",
    "df = pd.DataFrame(article_metadata)\n",
    "\n",
    "# Save the metadata as a CSV file\n",
    "df.to_csv('NeuroImage_2022_Metadata.csv', index=False)\n",
    "\n",
    "print(f\"Saved {len(df)} articles' metadata to NeuroImage_2022_Metadata.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900878ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94913679",
   "metadata": {},
   "source": [
    "Next steps: \n",
    "- Download PDFs\n",
    "- Text extraction using e.g., PDFMiner - save it in a structured format \n",
    "    - NB! It seems like a lot of the articles have a section called 'Data and code availability, where the information is available' \n",
    "- Dataset extraction \n",
    "    - Locate the dataset in the text \n",
    "- Store the extracted datasets for further analysis "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
