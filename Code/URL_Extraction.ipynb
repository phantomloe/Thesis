{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7067776c",
   "metadata": {},
   "source": [
    "# Table of contents \n",
    "- [Setup](#setup) \n",
    "    - [Purpose](#Purpose)\n",
    "    - [Libraries](#libraries)\n",
    "- [Ground truth URLs and sentences](#groundtruthURLsandsentences)\n",
    "- [URLs and sentences](#URLsandsentences)\n",
    "    - [Process URLs](#processURLs)\n",
    "    - [URLs in NeuroImage 2022 articles](#URLsinNeuroImage2022articles)\n",
    "- [Investigation](#investigation)\n",
    "- [References](#references) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af309d",
   "metadata": {},
   "source": [
    "<a name='setup'></a>\n",
    "# 0. Setup \n",
    "\n",
    "This notebook contains the code to extract the datasets used in the articles published in NeuroImage in 2022. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='purpose'></a> \n",
    "## 0.1. Purpose\n",
    "This notebook is one of a few whose purpose is to locate and extract publicly available datasets used for analysis in the research articles published in NeuroImage in 2022. In this specific notebook, pypdf is used to read PDF's and urlextract is used to locate and extract URLs and the sentences in which the URLs appear in. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='libraries'></a>\n",
    "## 0.2. Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf0a00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json \n",
    "import os \n",
    "import re \n",
    "import io\n",
    "\n",
    "# Read PDFs\n",
    "import pypdf \n",
    "# Extract URLs from text \n",
    "import urlextract \n",
    "\n",
    "# Random \n",
    "import random\n",
    "\n",
    "# Plot and figures \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321e92f",
   "metadata": {},
   "source": [
    "# 1. Ground truth URLs and sentences \n",
    "<a name = 'groundtruthURLsandsentences'></a>\n",
    "\n",
    "Based on my exploration of ten randomly picked articles, 75% of the articles contained URLs - of the articles that did not contain any URLs, the majority either used self-collected data or no datasets at all. This means that extracting the URLs will also extract the datasets used for analysis in the article. \n",
    "\n",
    "\n",
    "I will test the functions using the groundtruth texts as my validation set. When manually extracting the datasets from the ten groundtruth texts, we should get the following datasets (NB! Currently, I have not distinguished between links that leads the reader to data and links that leads the reader to code - this will come later): \n",
    "\n",
    "\n",
    "Similar to my processing, I will perform the following manually: \n",
    "- For each article, save only unique URLs (i.e., if the same URL is mentioned more than one time, save all the sentences in one list) \n",
    "- Remove the following URLs: \n",
    "    - 'www.elsevier.com/locate/neuroimage'\n",
    "    - URLs containing the DOI of the article\n",
    "    - Creative Commons licenses\n",
    "- Columns: \n",
    "    - DOI: The article's DOI\n",
    "    - URL: The URL\n",
    "    - Sentence: The sentence(s) in which the URL appears. The only cleaning I did included removing extra spaces, e.g., 'under- lay' is changed to 'under-lay'. \n",
    "    - Data: True if the URL and sentence(s) point to and describe a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2ef338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of groundtruth DOI values to filter \n",
    "groundtruth_dois = [\n",
    "    '10.1016/j.neuroimage.2021.118839',\n",
    "    '10.1016/j.neuroimage.2021.118854',\n",
    "    '10.1016/j.neuroimage.2022.119030',\n",
    "    '10.1016/j.neuroimage.2022.119050',\n",
    "    '10.1016/j.neuroimage.2022.119240',\n",
    "    '10.1016/j.neuroimage.2022.119443',\n",
    "    '10.1016/j.neuroimage.2022.119526',\n",
    "    '10.1016/j.neuroimage.2022.119549',\n",
    "    '10.1016/j.neuroimage.2022.119646',\n",
    "    '10.1016/j.neuroimage.2022.119676',\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3a80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_urls = [\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2021.118839',\n",
    "        'URL': 'http://neuroimage.usc.edu/brainstorm',\n",
    "        'Sentence': ['Subsequently the results were loaded in a Matlab Tool Box, Brainstorm (Tadel et al. 2011), an accredited software freely available for download online under the GNU general public license (http://neuroimage.usc.edu/brainstorm).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2021.118854',\n",
    "        'URL': 'https://www.humanconnectome.org/study/hcp-young-adult/data-releases',\n",
    "        'Sentence': ['We applied our GFA extension to the publicly available resting-state functional MRI (rs-fMRI) and non-imaging measures (e.g., demograph-ics, psychometrics and other behavioural measures) obtained from 1003 subjects (only these had rs-fMRI data available) of the 1200-subject data release of the HCP (https://www.humanconnectome.org/study/hcp-young-adult/data-releases).'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2021.118854',\n",
    "        'URL': 'https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation',\n",
    "        'Sentence': ['The data used in this study was downloaded from the Human Connectome Project website (https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation).'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2021.118854',\n",
    "        'URL': 'https://github.com/ferreirafabio80/gfa',\n",
    "        'Sentence': ['The GFA models and experiments were implemented in Python 3.9.1 and are available here: https://github.com/ferreirafabio80/gfa.'],\n",
    "        'Label': 'Model'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119030',\n",
    "        'URL': 'marmosetbrainconnectome.org',\n",
    "        'Sentence': ['To accelerate such progress, we present the Marmoset Functional Brain Connectivity Resource (marmosetbrainconnectome.org), currently consisting of over 70 h of resting-state fMRI (RS-fMRI) data acquired at 500 μm isotropic resolution from 31 fully awake marmosets in a common stereotactic space.', 'To promote progress in understanding the functional organization of the marmoset brain, we present a resource that allows for online viewing and download of three-dimensional functional connectivity (FC) maps from over 70 h of RS-fMRI collected at ultra-high field from 31 fully awake adult marmosets: marmosetbrainconnectome.org.', 'A resampled ver-sion of this atlas (at 100 μm) allows for additional anatomical detail over the in vivo template but will still load sufficiently fast as an under-lay image on marmosetbrainconnectome.org.', 'Features of the web portal: marmosetbrainconnectome.org.', 'The Marmoset Functional Connectivity Resource is publicly accessi-ble at marmosetbrainconnectome.org.', 'This resource allows users to instantaneously view and use FC topologies from any gray matter voxel in the marmoset brain online (marmosetbrainconnectome.org; Fig. 1), offering a fine-grained (500 μm) insight into how the marmoset brain is functionally con-nected in any given region, utterly agnostic to structural nomenclature.', 'Tracer maps (B & E) were downloaded from marmosetbrain.org, and FC maps (A through H) were generated from marmosetbrainconnectome.org.', 'With all the publicly available data demo-graphics, users can also download specific demographics (e.g., heavy males in late life) to address their research questions. Individual-level topologies can be loaded via the marmosetbrainconnectome.org viewer without any analysis.'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119030',\n",
    "        'URL': 'https://www.marmosetbrainconnectome.org/download.html',\n",
    "        'Sentence': ['(B) The data download page (https://www.marmosetbrainconnectome.org/download.html) allows the user to download all raw (BIDS standard formated) (Gorgolewski et al., 2016) and pre-processed data.', 'Directing to https://www.marmosetbrainconnectome.org/download.html allows for download of the “raw” structural and functional images (3D Neu-roimaging Informatics Technology Initiative (NIfTI) format) contribut-ing to the FC maps shown in the resource – for convenience, these data are in a standard format (BIDS) (Gorgolewski et al., 2016).', 'All raw and preprocessed data are openly available for download at: https://www.marmosetbrainconnectome.org/download.html'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119030',\n",
    "        'URL': 'https://rii-mango.github.io/Papaya/',\n",
    "        'Sentence': ['The resource makes use of the Papaya viewer (https://rii-mango.github.io/Papaya/), with several additional features (illustrated in Fig. 1C & D), including (1) calculation of surface over-lay maps on-demand based on the threshold chosen in volume space, (2) the ability to display atlas borders in surface space, (3) support for rotating the underlying volume, overlaying functional connectiv-ity map, and atlas boundaries together – such obliquing of the images can be of utility for presurgical planning, and (4) the ability to choose between group- and subject-level topologies.'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119030',\n",
    "        'URL': 'https://gitlab.com/cfmm/marmoset',\n",
    "        'Sentence': ['The development of the Marmoset Functional Connectivity Resource is described in full detail at https://gitlab.com/cfmm/marmoset.', 'All code for the online viewer is available at: https://gitlab.com/cfmm/marmoset'],\n",
    "        'Label': 'Code'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119030',\n",
    "        'URL': 'https://gitlab.com/cfmm/marmoset-connectivity',\n",
    "        'Sentence': ['Users can also download all code used to generate the functional connectivity maps from https://gitlab.com/cfmm/marmoset-connectivity.', 'A 3D printed model is shown in stereotactic position (with skull cut away to expose the cortical surface) to demonstrate targeting based on the resource coordinates. (D) in method 2, the user employs the supplied code (downloaded from https://gitlab.com/cfmm/marmoset-connectivity) to transform the FC map to their native animals’ anatomical MRI space.', 'All code used for processing data is openly available at: https://gitlab.com/cfmm/marmoset-connectivity'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119030',\n",
    "        'URL': 'marmosetbrain.org',\n",
    "        'Sentence': ['Explicitly, we focused on a tracer map from an area 46 injection (left; CJ801-DY; marmosetbrain.org for notes on these injections).', 'To demonstrate the additional information offered by our resource, we systematically plotted connectivity across (within) area TE3 for com-parison with available tracer injections within that region (left; CJ180- CTBr and CJ180-DY; marmosetbrain.org for notes on these injections) (Majka et al., 2020).', 'As shown in Fig. 9, we systematically plotted connectivity across (within) area TE3 and compared available tracer injections within that region (left; CJ180-CTBr and CJ180-DY; marmosetbrain.org for notes on these injections) (Majka et al., 2020).', 'Green labeled ROIs indicate FC data, whereas purple labeled ROIs show where tracer data is publicly available within area TE3 from marmosetbrain.org', 'Accordingly, these re-sources can readily perform similar comparisons in any circuitry of inter-est Fig. 9. shows an example of how our brain-wide functional connec-tivity data can complement existing resources (e.g., marmosetbrain.org) (Majka et al., 2020), demonstrating a gradient of connectivity between cortical tracer injection sites.'],\n",
    "        'Label': 'Atlas/map'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119050',\n",
    "        'URL': 'http://audition.ens.fr/adc/NoiseTools/',\n",
    "        'Sentence': ['EEG analysis used FieldTrip (Oostenveld et al., 2011), Noise-Tools (De Cheveigne and Parra, 2014; http://audition.ens.fr/adc/NoiseTools/), and custom-written scripts in Matlab.'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119050',\n",
    "        'URL': 'zenodo.org',\n",
    "        'Sentence': ['Raw EEG data from all healthy individuals, as well as Matlab code, are publicly available on zenodo.org (doi:10.5281/zenodo.6110595).'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119240',\n",
    "        'URL': 'www.cni.stanford.edu',\n",
    "        'Sentence': ['MRI data were acquired on a 3T Discovery MR750 scanner (Gen-eral Electric Healthcare, Milwaukee, WI, USA) equipped with a 32-channel head coil (Nova Medical, Wilmington, MA, USA) at the Cen-ter for Cognitive and Neurobiological Imaging at Stanford Univer-sity (www.cni.stanford.edu).'],\n",
    "        'Label': 'Resource'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119240',\n",
    "        'URL': 'http://github.com/vistalab/vistasoft/mrDiffusion',\n",
    "        'Sentence': ['Diffusion weighted images were pre-processed with Vistasoft (http://github.com/vistalab/vistasoft/mrDiffusion), an open-source software package implemented in MATLAB R2012a (Mathworks, Natick, MA).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119240',\n",
    "        'URL': 'http://www.fil.ion.ucl.ac.uk/spm/',\n",
    "        'Sentence': ['Each diffusion weighted image was registered to the mean of the b=0 images and the mean b=0 image was registered automatically to the participant’s T1w image, using a rigid body transformation (imple-mented in SPM8, http://www.fil.ion.ucl.ac.uk/spm/; no warping was applied).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119240',\n",
    "        'URL': 'https://github.com/mezera/mrQ',\n",
    "        'Sentence': ['Quantitative T1 (relaxation time, seconds) maps were calculated us-ing mrQ, (https://github.com/mezera/mrQ), an open-source software package implemented in MATLAB R2012a (Mathworks, Natick, MA).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119240',\n",
    "        'URL': 'https://github.jyeatman/AFQ',\n",
    "        'Sentence': ['Automated Fiber Quantification (AFQ; https://github.jyeatman/ AFQ; (Yeatman, Dougherty, Myall, et al., 2012)), a software package implemented in MATLAB R2012a (Mathworks, Natick, MA), was used to isolate and characterize white matter metrics from three dorsal tracts (Arc-L and bilateral SLF) and four ventral white matter tracts (bilat-eral ILF and bilateral UF).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119443',\n",
    "        'URL': 'osf.io/gazx2/',\n",
    "        'Sentence': ['EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119443',\n",
    "        'URL': 'osf.io/eucqf/',\n",
    "        'Sentence': ['EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119443',\n",
    "        'URL': 'osf.io/thsqg/',\n",
    "        'Sentence': ['EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119443',\n",
    "        'URL': 'osf.io/bndjg/',\n",
    "        'Sentence': ['EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119443',\n",
    "        'URL': 'osf.io/guwnm/',\n",
    "        'Sentence': ['Code used to reproduce the plots in Fig. 1, as well as averaged ERP data, is available from osf.io/guwnm/.'],\n",
    "        'Label': 'Processed dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://db.humanconnectome.org/data/projects/HCP_1200',\n",
    "        'Sentence': ['200 unrelated subjects were selected from the Human Con-nectome Project (HCP) 1200 Subjects Data Release with avail-able resting (task-free) and task fMRI data from a 3T MRI scan-ner (https://db.humanconnectome.org/data/projects/HCP_1200).', 'Preprocessed task fMRI data for the four tasks from the HCP were analyzed (working memory, motor, language, emotion) (https://db.humanconnectome.org/data/projects/HCP_1200).'],\n",
    "        'Label': 'Dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://www.humanconnectome.org/study/hcp-young-adult/document/wu-minn-hcp-consortium-open-access-data-use-terms',\n",
    "        'Sentence': ['This study agreed to the Open Access Data Use Terms (https://www.humanconnectome.org/study/hcp-young-adult/document/wu-minn-hcp-consortium-open-access-data-use-terms) and was exempt from the UCSF IRB because investigators could not readily ascertain the identities of the individuals to whom the data belonged.'],\n",
    "        'Label': 'Resource'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/',\n",
    "        'Sentence': ['We used FSL (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/) and AFNI (https://afni.nimh.nih.gov/) for additional fMRI preprocessing.'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://afni.nimh.nih.gov/',\n",
    "        'Sentence': ['We used FSL (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/) and AFNI (https://afni.nimh.nih.gov/) for additional fMRI preprocessing.'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'http://www.brainnetome.org/',\n",
    "        'Sentence': ['Maps were averaged within 273 regions of interest by combining a parcella-tion of 210 cortical regions and 36 subcortical regions from the Brainnetome atlas (Fan et al., 2016) (http://www.brainnetome.org/) and 27 cerebellar regions from the SUIT atlas (Diedrichsen, 2006) (http://www.diedrichsenlab.org/imaging/suit.htm).'],\n",
    "        'Label': 'Atlas/map'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'http://www.diedrichsenlab.org/imaging/suit.htm',\n",
    "        'Sentence': ['Maps were averaged within 273 regions of interest by combining a parcella-tion of 210 cortical regions and 36 subcortical regions from the Brainnetome atlas (Fan et al., 2016) (http://www.brainnetome.org/) and 27 cerebellar regions from the SUIT atlas (Diedrichsen, 2006) (http://www.diedrichsenlab.org/imaging/suit.htm).'],\n",
    "        'Label': 'Atlas/map'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://www.fil.ion.ucl.ac.uk/spm/software/spm12/',\n",
    "        'Sentence': ['Task condition block regressors were convolved with a hemo-dynamic response function using the ‘spm_get_bf’ function in SPM12 (https://www.fil.ion.ucl.ac.uk/spm/software/spm12/).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://github.com/rmarkello/abagen',\n",
    "        'Sentence': ['We compared each gradient map to Allen Human Brain spatial gene expression patterns using the ‘abagen’ package (https://github.com/rmarkello/abagen) (Arnatkevici ̆ūtė et al., 2019; Hawrylycz et al., 2012).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://brainsmash.readthedocs.io/en/latest/',\n",
    "        'Sentence': ['These surrogate gradient maps were estimated using BrainSMASH (https://brainsmash.readthedocs.io/en/latest/).'],\n",
    "        'Label': 'Atlas/map'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://sites.google.com/site/bctnet/',\n",
    "        'Sentence': ['Graph the-ory analyses were run using the Brain Connectivity Toolbox (BCT; https://sites.google.com/site/bctnet/).'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'http://human.brain-map.org/',\n",
    "        'Sentence': ['Original data was obtained from the Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil) and the Allen Hu-man Brain Atlas (http://human.brain-map.org/).'],\n",
    "        'Label': 'Atlas/map'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'URL': 'https://github.com/jbrown81/gradients',\n",
    "        'Sentence': ['All code (latent space derivation, dynamical system modeling, and gene expression corre-lation) and processed data (gradient maps/region weights, gradient timeseries, and region gene expression values) are available at https://github.com/jbrown81/gradients.', 'All code and processed data are available at https://github.com/jbrown81/gradients.'],\n",
    "        'Label': 'Processed dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119549',\n",
    "        'URL': np.nan,\n",
    "        'Sentence': np.nan,\n",
    "        'Label': np.nan\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119646',\n",
    "        'URL': np.nan,\n",
    "        'Sentence': np.nan,\n",
    "        'Label': np.nan\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        'URL': 'https://www.shutterstock.com',\n",
    "        'Sentence': ['Both experiments employed static images (modified from Shutterstock, https://www.shutterstock.com).'],\n",
    "        'Label': 'Resource'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        'URL': 'https://clippingmagic.com',\n",
    "        'Sentence': ['All image transformations were done with Clipping Magic (https://clippingmagic.com), ImageMagick, GIMP, Microsoft Paint, the MATLAB SHINE toolbox, and custom MATLAB code.'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        'URL': 'http://www.nitrc.org/projects/jip',\n",
    "        'Sentence': ['Functional volumes were realigned and motion-corrected with the Statistical Parametric Mapping software (SPM12, RRID: SCR_007037), followed by non-rigid co-registration (using JIP, http://www.nitrc.org/projects/jip, RRID: SCR_009588) to the high-resolution anatomical template of the skull-stripped brain of each monkey.'],\n",
    "        'Label': 'Software'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        'URL': 'https://caffe.berkeleyvision.org/model_zoo.html',\n",
    "        'Sentence': ['Another version of pre-trained AlexNet was im-ported from Caffe Model Zoo (https://caffe.berkeleyvision.org/model_zoo.html).'],\n",
    "        'Label': 'Model'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        'URL': 'https://osf.io/b8pfa/?view_only=b6dbb5dd6a044989a7eecdc99facb43c',\n",
    "        'Sentence': ['Preprocessed fMRI data are available at https://osf.io/b8pfa/?view_only=b6dbb5dd6a044989a7eecdc99facb43c.'],\n",
    "        'Label': 'Preprocessed dataset'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        'URL': 'https://github.com/Yozafirova/monkey-fMRI-codes',\n",
    "        'Sentence': ['Codes for the fMRI data analysis at https://github.com/Yozafirova/monkey-fMRI-codes and for the CNN data analysis at https://github.com/RajaniRaman/face_body_integration.'],\n",
    "        'Label': 'Analysis'\n",
    "    },\n",
    "    {\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        'URL': 'https://github.com/RajaniRaman/face_body_integration',\n",
    "        'Sentence': ['Codes for the fMRI data analysis at https://github.com/Yozafirova/monkey-fMRI-codes and for the CNN data analysis at https://github.com/RajaniRaman/face_body_integration.'],\n",
    "        'Label': 'Analysis'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "manual_groundtruth_urls = pd.DataFrame(groundtruth_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19b2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the 'Data' directory\n",
    "data_dir = os.path.join(os.pardir, 'Data')\n",
    "\n",
    "# File path\n",
    "file_path = os.path.join(data_dir, 'articles_groundtruth_urls_and_sentences.csv')\n",
    "\n",
    "# Save the DataFrame to CSV, overwriting the file if it exists\n",
    "manual_groundtruth_urls.to_csv(file_path, index=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ff73e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOI         43\n",
       "URL         41\n",
       "Sentence    41\n",
       "Label       41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_groundtruth_urls.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b477ddeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  URL Sentence Label\n",
       "34  10.1016/j.neuroimage.2022.119549  NaN      NaN   NaN\n",
       "35  10.1016/j.neuroimage.2022.119646  NaN      NaN   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values in the 'URL' column\n",
    "manual_groundtruth_urls[manual_groundtruth_urls['URL'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b4daa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manual_groundtruth_urls[manual_groundtruth_urls['Label']==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb6d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOI\n",
       "10.1016/j.neuroimage.2022.119526    12\n",
       "10.1016/j.neuroimage.2022.119676     7\n",
       "10.1016/j.neuroimage.2022.119030     6\n",
       "10.1016/j.neuroimage.2022.119240     5\n",
       "10.1016/j.neuroimage.2022.119443     5\n",
       "10.1016/j.neuroimage.2021.118854     3\n",
       "10.1016/j.neuroimage.2022.119050     2\n",
       "10.1016/j.neuroimage.2021.118839     1\n",
       "10.1016/j.neuroimage.2022.119549     0\n",
       "10.1016/j.neuroimage.2022.119646     0\n",
       "Name: URL, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'DOI' and count the number of URLs, setting NaN counts to 0\n",
    "url_counts = manual_groundtruth_urls.groupby('DOI')['URL'].count().fillna(0)\n",
    "\n",
    "# Sort the counts in descending order\n",
    "url_counts = url_counts.sort_values(ascending=False)\n",
    "\n",
    "url_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d7cc2",
   "metadata": {},
   "source": [
    "A total of 41 links were extracted manually from the groundtruth articles. There are between one and twelve URLs in the articles. Two of the articles did not contain any URLs. 20 of the 41 links point of data/datasets, models pretrained with data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41159d0b",
   "metadata": {},
   "source": [
    "<a name='URLsandsentences'></a>\n",
    "# 2. URLs and sentences\n",
    "I use the work of Sourget (2023) to search the PDFs for their datasets: \n",
    "\n",
    "I use the Python library *urlextract* by Lipovský (2022) to extract the URLs. \n",
    "\n",
    "I perform some initial cleaning of the sentences extracted from the PDFs, specifically removing multiple spaces with a single space, removing all \\n characters, and remove leadning and trailing spaces after a number of special characters, incl. -, (, ), /, ., _ , and between : /.\n",
    "\n",
    "The functions: \n",
    "- *get_content* is losely interpreted from Soruget (2023) using the following breadcrumb in the github repository: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "- *clean_text* \n",
    "- *split_text_into_sentence* \n",
    "- *extract_links* uses the urlextract library (Lipovský 2022). \n",
    "- *get_urls_and_sentences* calls on *extract_links* and gets both URLs and sentences containing the URL. \n",
    "- *extract_and_transform_urls_from_dataframe* \n",
    "    \n",
    "\n",
    "<br>\n",
    "\n",
    "References: \n",
    "- Lipovský, J. (2022). urlextract: Collects and extracts URLs from given text. (1.8.0) [Python]. https://github.com/lipoja/URLExtract\n",
    "- Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657273d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(pdf_path, alt_pdf_path):\n",
    "    \"\"\"Get sentences that contain URLs. \n",
    "    This function is loosely interpreted from Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget\n",
    "    specifically: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "    \n",
    "    Parameters: \n",
    "    :param pdf_path (str): Path to the PDF file.\n",
    "    :param alt_pdf_path (str): Alternative path to the PDF file. \n",
    "    \n",
    "    Returns: \n",
    "    :return: Dataframe or 'Editorial board' if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_file = open(pdf_path, 'rb')\n",
    "        pdf_reader = pypdf.PdfReader(pdf_file)\n",
    "        pdf_text = \" \".join(page.extract_text() for page in pdf_reader.pages)\n",
    "\n",
    "        # Extract sentences containing urls\n",
    "        df = get_urls_and_sentences(pdf_text)\n",
    "        pdf_file.close()\n",
    "        if df is not None:  # Check if a DataFrame is returned\n",
    "            return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            alternative_pdf_path = os.path.join(alt_pdf_path, os.path.basename(pdf_path))\n",
    "            pdf_file = open(alternative_pdf_path, 'rb')\n",
    "            return pd.DataFrame({\"url\": [np.nan], \"sentences\": [np.nan]})\n",
    "        except FileNotFoundError:\n",
    "            return pd.DataFrame({\"url\": [np.nan], \"sentences\": [np.nan]})\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "    \n",
    "    # If no URLs were found, return an empty DataFrame\n",
    "    return pd.DataFrame(columns=[\"url\", \"sentences\"])\n",
    "\n",
    "\n",
    "############### SENTENCES ################################################\n",
    "def clean_text(text): \n",
    "    \"\"\"This function performs a very simple initial cleaning of the extracted sentences. \n",
    "    This includes removing multiple spaces with a single space, removing all \\n characters, \n",
    "    and remove leadning and trailing spaces after a number of special characters, \n",
    "    incl. -, (, ), /, ., _ , and between : / \n",
    "\n",
    "    Parameters: \n",
    "    :param text(str): Input text in the form of a string. \n",
    "\n",
    "    Returns: \n",
    "    :return text(str): Returns the cleaned text.\n",
    "    \"\"\"\n",
    "    return text.replace('   ', ' ').replace('  ', ' ').replace('\\n', '').replace('- ', '-').replace('( ', '(').replace(' )', ')').replace('/ ', '/').replace(' /', '/').replace(' .', '.').replace(': /', ':/').replace(' _ ', '_').replace(' _', '_').replace('_ ', '_') \n",
    "\n",
    "def get_sentences(text):\n",
    "    \"\"\"This function splits a given text into sentences based on a regular expression pattern. \n",
    "    It uses re.split() to identify sentence boundaries, considering common sentence-ending \n",
    "    punctuation like \".\", \"!\", or \"?\". It avoids splitting sentences if a digit immediately \n",
    "    follows the punctuation, e.g., 'Fig. 1'. \n",
    "    \n",
    "    Parameters: \n",
    "    :param text(str): Input text in the form of a string. \n",
    "    \n",
    "    Returns: \n",
    "    :return sentences(list): Returns the text as a list of sentences.  \n",
    "    \"\"\"\n",
    "    sentence_pattern = r'(?<=[.!?])\\s+(?![0-9]+\\s)'\n",
    "    sentences = re.split(sentence_pattern, text)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "############### LINKS ################################################\n",
    "def get_urls(text):\n",
    "    \"\"\"This function returns all unique urls in a text that have certain characters stripped from \n",
    "    the end of them (including ',', '.', and ')'). It uses the Python library URLExtract (Lipovský 2022).\n",
    "\n",
    "    Parameters: \n",
    "    :param text(str): Input text that may or may not contain a URL. \n",
    "\n",
    "    Returns: \n",
    "    :returns unique_urls_list(list): List of unique URLs from a given text. \n",
    "    \"\"\"\n",
    "    # Instance of the URLExtract class\n",
    "    extractor = urlextract.URLExtract()\n",
    "    \n",
    "    # Create a set to store unique URLs\n",
    "    unique_urls = set()\n",
    "    \n",
    "    for url in extractor.gen_urls(text):\n",
    "        # Apply additional processing to the URL, e.g., removing characters at the end\n",
    "        processed_url = url.rstrip('.').rstrip(')').rstrip(',')\n",
    "        unique_urls.add(processed_url)\n",
    "    \n",
    "    # Convert the set back to a list if needed\n",
    "    unique_url_list = list(unique_urls)\n",
    "    \n",
    "    return unique_url_list\n",
    "\n",
    "def get_sentences_with_urls(sentences):\n",
    "    \"\"\"This function returns all text that contains URLs. It uses the Python library URLExtract (Lipovský 2022).\n",
    "\n",
    "    Parameters: \n",
    "    :param sentences(list): Input text from a list containing sentences. \n",
    "\n",
    "    Returns: \n",
    "    :returns sentences_with_urls(list): List of sentences containing URLs. \n",
    "    \"\"\"\n",
    "    # Instance of the URLExtract class\n",
    "    extractor = urlextract.URLExtract()\n",
    "    # Extract all sentences with URLs\n",
    "    sentences_with_urls = []\n",
    "    stop_processing = False  # Flag to stop processing when \"References\" is found\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if stop_processing:\n",
    "            break  # Stop processing when \"References\" is found\n",
    "        if extractor.has_urls(sentence):\n",
    "            sentences_with_urls.append(sentence)\n",
    "        if \"References\" in sentence:\n",
    "            stop_processing = True  # Set the flag to stop processing\n",
    "\n",
    "    return sentences_with_urls\n",
    "    \n",
    "def get_urls_and_sentences(text):\n",
    "    \"\"\"This function extracts URLs and their corresponding sentences from the given text. \n",
    "    If no URLs are found, an empty DataFrame with columns [\"url\", \"sentences\"] is returned.\n",
    "\n",
    "    Parameters:\n",
    "    :param text (str): Input text containing URLs and sentences.\n",
    "\n",
    "    Returns:\n",
    "    :returns pd.DataFrame: A DataFrame with two columns, 'url' and 'sentences'.\n",
    "      Each row represents a URL along with a list of sentences containing that URL.\n",
    "    \"\"\"\n",
    "    # Lists to store the extracted URLs and their corresponding sentences\n",
    "    url_list = []\n",
    "    sentence_list = []\n",
    "    # Clean sentences \n",
    "    cleaned_text = clean_text(text)\n",
    "    # Extract links\n",
    "    links = get_urls(cleaned_text)\n",
    "    # Extract sentences \n",
    "    sentences = get_sentences(cleaned_text)\n",
    "    # Extract sentences with links \n",
    "    sentences_w_links = get_sentences_with_urls(sentences)\n",
    "\n",
    "    # Process each URL \n",
    "    for link in links:\n",
    "        sentences_for_url = [sentence for sentence in sentences_w_links if link in sentence]\n",
    "        if sentences_for_url:  # Only add the URL if there are associated sentences\n",
    "            url_list.append(link)\n",
    "            sentence_list.append(sentences_for_url)\n",
    "    \n",
    "    # If no URLs were found, return an empty DataFrame\n",
    "    if not url_list:\n",
    "        return pd.DataFrame(columns=[\"url\", \"sentences\"])\n",
    "\n",
    "    return pd.DataFrame({\"url\": url_list, \"sentences\": sentence_list})\n",
    "\n",
    "\n",
    "############### DATAFRAME WITH DOI, URL, SENTENCES ################################################\n",
    "def process_groundtruth_DOIs(groundtruth_dois, articles_directory, editorialboard_directory, json_file_path):\n",
    "    \"\"\"This function processes a list of DOIs, extracts urls and sentences from PDFs, \n",
    "    and create a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    :param groundtruth_dois (list): List of DOIs to process.\n",
    "    :param articles_directory (str): Path to the directory containing PDF articles.\n",
    "    :param editorialboard_directory (str): Path to the directory with editorial board articles.\n",
    "    :param json_file_path (str): Path to a JSON file.\n",
    "\n",
    "    Returns:\n",
    "    :return pd.DataFrame: A DataFrame containing processed information from the DOIs.\n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        for doi in groundtruth_dois:\n",
    "            doi_replaced = doi.replace('/', '.')\n",
    "            pdf_path = os.path.join(articles_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "            # Call the get_content function for each DOI\n",
    "            url_df = get_content(pdf_path, editorialboard_directory)\n",
    "\n",
    "            # Append the DOI to the URL DataFrame\n",
    "            url_df['DOI'] = doi\n",
    "            results_list.append(url_df)\n",
    "\n",
    "        \"\"\" TO PROCESS JUST ONE DOI: \n",
    "        doi = '10.1016/j.neuroimage.2022.119030'\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(articles_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content function for each DOI\n",
    "        url_df = get_content(pdf_path, editorialboard_directory)\n",
    "        # Append the DOI to the URL DataFrame\n",
    "        url_df['DOI'] = doi\n",
    "        results_list.append(url_df)\n",
    "        \"\"\"\n",
    "            \n",
    "    # Concatenate the list of DataFrames into a single DataFrame\n",
    "    results_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "    # Rename the columns as needed\n",
    "    results_df.rename(columns={'url': 'URL', 'sentences': 'Sentences'}, inplace=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def process_DOIs(articles_directory, editorialboard_directory, json_file_path):\n",
    "    \"\"\"This function processes a list of DOIs, extracts urls and sentences from PDFs, \n",
    "    and create a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    :param articles_directory (str): Path to the directory containing PDF articles.\n",
    "    :param editorialboard_directory (str): Path to the directory with editorial board articles.\n",
    "    :param json_file_path (str): Path to a JSON file.\n",
    "\n",
    "    Returns:\n",
    "    :return pd.DataFrame: A DataFrame containing processed information from the DOIs.\n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        doi_data = json.load(json_file)\n",
    "        for doi in doi_data['DOIs']:\n",
    "            doi_replaced = doi.replace('/', '.')\n",
    "            pdf_path = os.path.join(articles_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "            # Call the get_content function for each DOI\n",
    "            url_df = get_content(pdf_path, editorialboard_directory)\n",
    "\n",
    "            # Append the DOI to the URL DataFrame\n",
    "            url_df['DOI'] = doi\n",
    "            results_list.append(url_df)\n",
    "            \n",
    "    # Concatenate the list of DataFrames into a single DataFrame\n",
    "    results_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "    # Rename the columns as needed\n",
    "    results_df.rename(columns={'url': 'URL', 'sentences': 'Sentences'}, inplace=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ecce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing PDFs\n",
    "articles_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_articles_doi/'\n",
    "editorialboard_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_editorialboard_doi/'\n",
    "\n",
    "# Path to the JSON file containing DOI values\n",
    "json_file_path = '../Data/ElsevierAPI/downloadedPDFs_info.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e42c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "automatic_groundtruth_df = process_groundtruth_DOIs(groundtruth_dois, articles_directory, editorialboard_directory, json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f2c6749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2021.118839</td>\n",
       "      <td>[Corticospinal projections has been shown also...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 248 (2022) 118839 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://neuroimage.usc.edu/brainstorm</td>\n",
       "      <td>[2011), an accredited software freely availabl...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>https://github.com/Yozaﬁrova/monkey-fMRI-codes</td>\n",
       "      <td>[Codes for the fMRI data analysis at https://g...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>https://github.com/RajaniRaman/face_body_integ...</td>\n",
       "      <td>[Codes for the fMRI data analysis at https://g...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https://clippingmagic.com</td>\n",
       "      <td>[NeuroImage 264 (2022) 119676 All image transf...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>https://caﬀe.berkeleyvision.org/model_zoo.html</td>\n",
       "      <td>[Another version of pre-trained AlexNet was im...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 264 (2022) 119676 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  \\\n",
       "0    https://doi.org/10.1016/j.neuroimage.2021.118839   \n",
       "1                  www.elsevier.com/locate/neuroimage   \n",
       "2   http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "3                http://neuroimage.usc.edu/brainstorm   \n",
       "4         http://creativecommons.org/licenses/by/4.0/   \n",
       "..                                                ...   \n",
       "65     https://github.com/Yozaﬁrova/monkey-fMRI-codes   \n",
       "66  https://github.com/RajaniRaman/face_body_integ...   \n",
       "67                          https://clippingmagic.com   \n",
       "68     https://caﬀe.berkeleyvision.org/model_zoo.html   \n",
       "69                 www.elsevier.com/locate/neuroimage   \n",
       "\n",
       "                                            Sentences  \\\n",
       "0   [Corticospinal projections has been shown also...   \n",
       "1   [NeuroImage 248 (2022) 118839 Contents lists a...   \n",
       "2   [This is an open access article under the CC B...   \n",
       "3   [2011), an accredited software freely availabl...   \n",
       "4   [This is an open access article under the CC B...   \n",
       "..                                                ...   \n",
       "65  [Codes for the fMRI data analysis at https://g...   \n",
       "66  [Codes for the fMRI data analysis at https://g...   \n",
       "67  [NeuroImage 264 (2022) 119676 All image transf...   \n",
       "68  [Another version of pre-trained AlexNet was im...   \n",
       "69  [NeuroImage 264 (2022) 119676 Contents lists a...   \n",
       "\n",
       "                                 DOI  \n",
       "0   10.1016/j.neuroimage.2021.118839  \n",
       "1   10.1016/j.neuroimage.2021.118839  \n",
       "2   10.1016/j.neuroimage.2021.118839  \n",
       "3   10.1016/j.neuroimage.2021.118839  \n",
       "4   10.1016/j.neuroimage.2021.118854  \n",
       "..                               ...  \n",
       "65  10.1016/j.neuroimage.2022.119676  \n",
       "66  10.1016/j.neuroimage.2022.119676  \n",
       "67  10.1016/j.neuroimage.2022.119676  \n",
       "68  10.1016/j.neuroimage.2022.119676  \n",
       "69  10.1016/j.neuroimage.2022.119676  \n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automatic_groundtruth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279facf2",
   "metadata": {},
   "source": [
    "Brief exploration of the URLs extracted from the groundtruth articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "008da580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL          70\n",
       "Sentences    70\n",
       "DOI          70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automatic_groundtruth_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aab89dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(automatic_groundtruth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c493c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1016/j.neuroimage.2022.119526    15\n",
      "10.1016/j.neuroimage.2022.119676    10\n",
      "10.1016/j.neuroimage.2022.119030     9\n",
      "10.1016/j.neuroimage.2022.119443     8\n",
      "10.1016/j.neuroimage.2022.119240     7\n",
      "10.1016/j.neuroimage.2021.118854     6\n",
      "10.1016/j.neuroimage.2022.119050     5\n",
      "10.1016/j.neuroimage.2021.118839     4\n",
      "10.1016/j.neuroimage.2022.119549     3\n",
      "10.1016/j.neuroimage.2022.119646     3\n",
      "Name: DOI, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How many URLs are saved per DOI\n",
    "doi_counts = automatic_groundtruth_df['DOI'].value_counts()\n",
    "\n",
    "# Print the number of rows for each unique DOI\n",
    "print(doi_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1fdfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with links to Creative Commons license: 10\n"
     ]
    }
   ],
   "source": [
    "# Count the rows with URLs containing 'creativecommons.org'\n",
    "cc_license_count = len(automatic_groundtruth_df[automatic_groundtruth_df['URL'].str.contains('creativecommons.org')])\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of rows with links to Creative Commons license: {cc_license_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd513f44",
   "metadata": {},
   "source": [
    "## 2.1. Process URLs\n",
    "<a name = 'processURLs'></a>\n",
    "\n",
    "Before this point, I already performed a few preprocessing steps of the URLs: \n",
    "- in *get_urls*, I returned only unique URLs. \n",
    "- in *process_url*, I stripped URLs of the characters '.' and ')', if they were at the end of the link. \n",
    "\n",
    "At this point, I have only unique URLs for each DOI. But I want to remove some URLs that I know do not point to datasets. As such, this processing step is: \n",
    "* Remove URLs: \n",
    "    * 'www.elsevier.com/locate/neuroimage' - this link is placed outside of the article's text. \n",
    "    * URLs containing the DOI of the article - this link is placed outside of the article's text. \n",
    "    * Creative Commons licenses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064b80f",
   "metadata": {},
   "source": [
    "I want to check any links that are common between the articles to see if there are some NeuroImage or Elsevier specific links that can be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fd7a063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 248 (2022) 118839 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 249 (2022) 118854 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 252 (2022) 119030 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 253 (2022) 119050 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 256 (2022) 119240 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 259 (2022) 119443 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 261 (2022) 119526 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 262 (2022) 119549 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 263 (2022) 119646 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 264 (2022) 119676 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  \\\n",
       "1                  www.elsevier.com/locate/neuroimage   \n",
       "2   http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "4         http://creativecommons.org/licenses/by/4.0/   \n",
       "7                  www.elsevier.com/locate/neuroimage   \n",
       "15  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "18                 www.elsevier.com/locate/neuroimage   \n",
       "21  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "23                 www.elsevier.com/locate/neuroimage   \n",
       "26  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "28                 www.elsevier.com/locate/neuroimage   \n",
       "34        http://creativecommons.org/licenses/by/4.0/   \n",
       "38                 www.elsevier.com/locate/neuroimage   \n",
       "41  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "52                 www.elsevier.com/locate/neuroimage   \n",
       "54  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "55                 www.elsevier.com/locate/neuroimage   \n",
       "57                 www.elsevier.com/locate/neuroimage   \n",
       "58        http://creativecommons.org/licenses/by/4.0/   \n",
       "63  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "69                 www.elsevier.com/locate/neuroimage   \n",
       "\n",
       "                                            Sentences  \\\n",
       "1   [NeuroImage 248 (2022) 118839 Contents lists a...   \n",
       "2   [This is an open access article under the CC B...   \n",
       "4   [This is an open access article under the CC B...   \n",
       "7   [NeuroImage 249 (2022) 118854 Contents lists a...   \n",
       "15  [This is an open access article under the CC B...   \n",
       "18  [NeuroImage 252 (2022) 119030 Contents lists a...   \n",
       "21  [This is an open access article under the CC B...   \n",
       "23  [NeuroImage 253 (2022) 119050 Contents lists a...   \n",
       "26  [This is an open access article under the CC B...   \n",
       "28  [NeuroImage 256 (2022) 119240 Contents lists a...   \n",
       "34  [This is an open access article under the CC B...   \n",
       "38  [NeuroImage 259 (2022) 119443 Contents lists a...   \n",
       "41  [This is an open access article under the CC B...   \n",
       "52  [NeuroImage 261 (2022) 119526 Contents lists a...   \n",
       "54  [This is an open access article under the CC B...   \n",
       "55  [NeuroImage 262 (2022) 119549 Contents lists a...   \n",
       "57  [NeuroImage 263 (2022) 119646 Contents lists a...   \n",
       "58  [This is an open access article under the CC B...   \n",
       "63  [This is an open access article under the CC B...   \n",
       "69  [NeuroImage 264 (2022) 119676 Contents lists a...   \n",
       "\n",
       "                                 DOI  \n",
       "1   10.1016/j.neuroimage.2021.118839  \n",
       "2   10.1016/j.neuroimage.2021.118839  \n",
       "4   10.1016/j.neuroimage.2021.118854  \n",
       "7   10.1016/j.neuroimage.2021.118854  \n",
       "15  10.1016/j.neuroimage.2022.119030  \n",
       "18  10.1016/j.neuroimage.2022.119030  \n",
       "21  10.1016/j.neuroimage.2022.119050  \n",
       "23  10.1016/j.neuroimage.2022.119050  \n",
       "26  10.1016/j.neuroimage.2022.119240  \n",
       "28  10.1016/j.neuroimage.2022.119240  \n",
       "34  10.1016/j.neuroimage.2022.119443  \n",
       "38  10.1016/j.neuroimage.2022.119443  \n",
       "41  10.1016/j.neuroimage.2022.119526  \n",
       "52  10.1016/j.neuroimage.2022.119526  \n",
       "54  10.1016/j.neuroimage.2022.119549  \n",
       "55  10.1016/j.neuroimage.2022.119549  \n",
       "57  10.1016/j.neuroimage.2022.119646  \n",
       "58  10.1016/j.neuroimage.2022.119646  \n",
       "63  10.1016/j.neuroimage.2022.119676  \n",
       "69  10.1016/j.neuroimage.2022.119676  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the rows with duplicate URLs, indicating which DOIs share the same URL. \n",
    "# Check the column 'url' for duplicates using subset='url' and keep=False keeps all occurrences of the duplicates.\n",
    "duplicate_urls = automatic_groundtruth_df[automatic_groundtruth_df.duplicated(subset='URL', keep=False)]\n",
    "\n",
    "# Print the rows with duplicate URLs\n",
    "duplicate_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f126047",
   "metadata": {},
   "source": [
    "Remove links: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "904a8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_urls(df, urls_to_remove):\n",
    "    \"\"\"This function filters a DataFrame containing information about articles, removing specified URLs. \n",
    "\n",
    "    Parameters:\n",
    "    :param df (pd.DataFrame): Input DataFrame with columns 'DOI', 'URL', and 'Sentences'.\n",
    "    :param urls_to_remove (list): List of URLs to be removed from the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    :returns pd.DataFrame: A filtered DataFrame with the specified URLs removed.    \n",
    "    \"\"\"\n",
    "    filtered_df = df.copy()\n",
    "    # Collect unique DOIs \n",
    "    unique_dois = filtered_df['DOI'].unique()\n",
    "     # Ensure 'URL' and 'DOI' columns are of string type\n",
    "    filtered_df['URL'] = filtered_df['URL'].astype(str)\n",
    "    filtered_df['DOI'] = filtered_df['DOI'].astype(str)\n",
    "    \n",
    "    # Remove URLs from list of URLs to remove \n",
    "    filtered_df = filtered_df[~filtered_df['URL'].isin(urls_to_remove)]\n",
    "\n",
    "    # Remove URLs referring to the Creative Commons license \n",
    "    filtered_df = filtered_df[~filtered_df['URL'].str.contains('creativecommons.org')]\n",
    "    \n",
    "    # Remove URLs containing the DOI \n",
    "    for doi in filtered_df['DOI'].unique():\n",
    "        filtered_df = filtered_df[~filtered_df['URL'].str.contains('doi')]\n",
    "    \n",
    "    # Check if all unique DOIs are still present, if not, add them with NaN values\n",
    "    missing_dois = set(unique_dois) - set(filtered_df['DOI'].unique())\n",
    "    for missing_doi in missing_dois:\n",
    "        filtered_df = filtered_df.append({'DOI': missing_doi, 'URL': np.nan, 'Sentences': np.nan}, ignore_index=True)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03310893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/yk6m9jqn41l9s2x1tfjqc9900000gn/T/ipykernel_64037/3397798183.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  filtered_df = filtered_df.append({'DOI': missing_doi, 'URL': np.nan, 'Sentences': np.nan}, ignore_index=True)\n",
      "/var/folders/hg/yk6m9jqn41l9s2x1tfjqc9900000gn/T/ipykernel_64037/3397798183.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  filtered_df = filtered_df.append({'DOI': missing_doi, 'URL': np.nan, 'Sentences': np.nan}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# URLs to remove\n",
    "urls_to_remove = [\n",
    "    'www.elsevier.com/locate/neuroimage',  # URL to remove\n",
    "]\n",
    "\n",
    "automatic_groundtruth_urls = filter_urls(automatic_groundtruth_df, urls_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35da4704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL          40\n",
       "Sentences    40\n",
       "DOI          42\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automatic_groundtruth_urls.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82856d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(automatic_groundtruth_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbdccd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOI\n",
       "10.1016/j.neuroimage.2022.119526    12\n",
       "10.1016/j.neuroimage.2022.119676     7\n",
       "10.1016/j.neuroimage.2022.119030     6\n",
       "10.1016/j.neuroimage.2022.119443     5\n",
       "10.1016/j.neuroimage.2022.119240     4\n",
       "10.1016/j.neuroimage.2021.118854     3\n",
       "10.1016/j.neuroimage.2022.119050     2\n",
       "10.1016/j.neuroimage.2021.118839     1\n",
       "10.1016/j.neuroimage.2022.119549     0\n",
       "10.1016/j.neuroimage.2022.119646     0\n",
       "Name: URL, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many URLs are saved per DOI\n",
    "doi_counts = automatic_groundtruth_urls.groupby('DOI')['URL'].count().fillna(0) \n",
    "\n",
    "doi_counts = doi_counts.sort_values(ascending=False)\n",
    "\n",
    "doi_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3bb05c",
   "metadata": {},
   "source": [
    "The automatic URL extraction found a total of 40 links across the ten articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c90af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average URLs per DOI: 4.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average number of URLs per DOI\n",
    "average_urls_per_doi = doi_counts.mean()\n",
    "print(\"Average URLs per DOI:\", average_urls_per_doi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e215e",
   "metadata": {},
   "source": [
    "The counts don't fully match up with my manual exploration. \n",
    "- 10.1016/j.neuroimage.2022.119240 has one less than my manual count, specifically the link: 'https://github.jyeatman/AFQ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b196663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>www.cni.stanford.edu</td>\n",
       "      <td>[MRI data were acquired on a 3T Discovery MR75...</td>\n",
       "      <td>Resource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>http://github.com/vistalab/vistasoft/mrDiffusion</td>\n",
       "      <td>[Diffusion weighted images were pre-processed ...</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>http://www.fil.ion.ucl.ac.uk/spm/</td>\n",
       "      <td>[Each diffusion weighted image was registered ...</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>https://github.com/mezera/mrQ</td>\n",
       "      <td>[Quantitative T1 (relaxation time, seconds) ma...</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>https://github.jyeatman/AFQ</td>\n",
       "      <td>[Automated Fiber Quantification (AFQ; https://...</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "12  10.1016/j.neuroimage.2022.119240   \n",
       "13  10.1016/j.neuroimage.2022.119240   \n",
       "14  10.1016/j.neuroimage.2022.119240   \n",
       "15  10.1016/j.neuroimage.2022.119240   \n",
       "16  10.1016/j.neuroimage.2022.119240   \n",
       "\n",
       "                                                 URL  \\\n",
       "12                              www.cni.stanford.edu   \n",
       "13  http://github.com/vistalab/vistasoft/mrDiffusion   \n",
       "14                 http://www.fil.ion.ucl.ac.uk/spm/   \n",
       "15                     https://github.com/mezera/mrQ   \n",
       "16                       https://github.jyeatman/AFQ   \n",
       "\n",
       "                                             Sentence     Label  \n",
       "12  [MRI data were acquired on a 3T Discovery MR75...  Resource  \n",
       "13  [Diffusion weighted images were pre-processed ...  Software  \n",
       "14  [Each diffusion weighted image was registered ...  Software  \n",
       "15  [Quantitative T1 (relaxation time, seconds) ma...  Software  \n",
       "16  [Automated Fiber Quantification (AFQ; https://...  Software  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_groundtruth_urls[manual_groundtruth_urls['DOI'] == '10.1016/j.neuroimage.2022.119240']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "836f011a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://github.com/vistalab/vistasoft/mrDiﬀusion</td>\n",
       "      <td>[Diﬀusion weighted images were pre-processed w...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://github.com/mezera/mrQ</td>\n",
       "      <td>[Quantitative T1 (relaxation time, seconds) ma...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http://www.ﬁl.ion.ucl.ac.uk/spm/</td>\n",
       "      <td>[Each diﬀusion weighted image was registered t...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>www.cni.stanford.edu</td>\n",
       "      <td>[MRI data acquisition and processing MRI data ...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URL  \\\n",
       "12  http://github.com/vistalab/vistasoft/mrDiﬀusion   \n",
       "13                    https://github.com/mezera/mrQ   \n",
       "14                 http://www.ﬁl.ion.ucl.ac.uk/spm/   \n",
       "15                             www.cni.stanford.edu   \n",
       "\n",
       "                                            Sentences  \\\n",
       "12  [Diﬀusion weighted images were pre-processed w...   \n",
       "13  [Quantitative T1 (relaxation time, seconds) ma...   \n",
       "14  [Each diﬀusion weighted image was registered t...   \n",
       "15  [MRI data acquisition and processing MRI data ...   \n",
       "\n",
       "                                 DOI  \n",
       "12  10.1016/j.neuroimage.2022.119240  \n",
       "13  10.1016/j.neuroimage.2022.119240  \n",
       "14  10.1016/j.neuroimage.2022.119240  \n",
       "15  10.1016/j.neuroimage.2022.119240  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automatic_groundtruth_urls[automatic_groundtruth_urls['DOI'] == '10.1016/j.neuroimage.2022.119240']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8cd93",
   "metadata": {},
   "source": [
    "Looking at the links before filtering them, the link was not caught: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3676ccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>http://github.com/vistalab/vistasoft/mrDiﬀusion</td>\n",
       "      <td>[Diﬀusion weighted images were pre-processed w...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://github.com/mezera/mrQ</td>\n",
       "      <td>[Quantitative T1 (relaxation time, seconds) ma...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>[This is an open access article under the CC B...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>http://www.ﬁl.ion.ucl.ac.uk/spm/</td>\n",
       "      <td>[Each diﬀusion weighted image was registered t...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>[NeuroImage 256 (2022) 119240 Contents lists a...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>www.cni.stanford.edu</td>\n",
       "      <td>[MRI data acquisition and processing MRI data ...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>[The sample included FT and PT children across...</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  \\\n",
       "24    http://github.com/vistalab/vistasoft/mrDiﬀusion   \n",
       "25                      https://github.com/mezera/mrQ   \n",
       "26  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "27                   http://www.ﬁl.ion.ucl.ac.uk/spm/   \n",
       "28                 www.elsevier.com/locate/neuroimage   \n",
       "29                               www.cni.stanford.edu   \n",
       "30   https://doi.org/10.1016/j.neuroimage.2022.119240   \n",
       "\n",
       "                                            Sentences  \\\n",
       "24  [Diﬀusion weighted images were pre-processed w...   \n",
       "25  [Quantitative T1 (relaxation time, seconds) ma...   \n",
       "26  [This is an open access article under the CC B...   \n",
       "27  [Each diﬀusion weighted image was registered t...   \n",
       "28  [NeuroImage 256 (2022) 119240 Contents lists a...   \n",
       "29  [MRI data acquisition and processing MRI data ...   \n",
       "30  [The sample included FT and PT children across...   \n",
       "\n",
       "                                 DOI  \n",
       "24  10.1016/j.neuroimage.2022.119240  \n",
       "25  10.1016/j.neuroimage.2022.119240  \n",
       "26  10.1016/j.neuroimage.2022.119240  \n",
       "27  10.1016/j.neuroimage.2022.119240  \n",
       "28  10.1016/j.neuroimage.2022.119240  \n",
       "29  10.1016/j.neuroimage.2022.119240  \n",
       "30  10.1016/j.neuroimage.2022.119240  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automatic_groundtruth_df[automatic_groundtruth_df['DOI'] == '10.1016/j.neuroimage.2022.119240']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f1c61",
   "metadata": {},
   "source": [
    "Compared to the manual extraction, 39 of the 40 links were picked up on by the code. I will move on with the current code and extract all URLs from the entire corpus of NeuroImage 2022 articles. \n",
    "\n",
    "<a name='URLsinNeuroImage2022articles'></a>\n",
    "## 2.2. URLs in NeuroImage 2022 articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "478fc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing PDFs\n",
    "articles_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_articles_doi/'\n",
    "editorialboard_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_editorialboard_doi/'\n",
    "\n",
    "# Path to the JSON file containing DOI values\n",
    "json_file_path = '../Data/ElsevierAPI/downloadedPDFs_info.json'\n",
    "\n",
    "# URLs to remove\n",
    "urls_to_remove = [\n",
    "    'www.elsevier.com/locate/neuroimage',  # URL to remove\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed9ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last run on October 29th\n",
    "# Extract all URLs in NeuroImage 2022 articles \n",
    "df = process_DOIs(articles_directory, editorialboard_directory, json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed6663fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the extracted URLs\n",
    "filtered_df = filter_urls(df, urls_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b8ef38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the URLs (filtered and unfiltered) to csv \n",
    "# The file path\n",
    "path_all_urls = os.path.join(os.pardir, 'Data/articles_all_urls.csv')\n",
    "path_filtered_urls = os.path.join(os.pardir, 'Data/articles_filtered_urls.csv')\n",
    "\n",
    "# Save the DataFrame to CSV, overwriting the file if it exists\n",
    "df.to_csv(path_all_urls, index=False, mode='w')\n",
    "filtered_df.to_csv(path_filtered_urls, index=False, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494e80e-26d0-42af-8e21-be0f3018e085",
   "metadata": {},
   "source": [
    "<a name='investigation'></a>\n",
    "# Investigation \n",
    "\n",
    "I will explore and generate some simple statistics about the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53700c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_all_urls = os.path.join(os.pardir, 'Data/articles_all_urls.csv')\n",
    "path_filtered_urls = os.path.join(os.pardir, 'Data/articles_filtered_urls.csv')\n",
    "all_urls = pd.read_csv(path_all_urls)\n",
    "filtered_urls = pd.read_csv(path_filtered_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ff3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the Editorial Board DOIs to exclude them \n",
    "path = os.path.join(os.pardir,'Data/ElsevierAPI/downloaded_pdfs/fulltext_editorialboard_doi')\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Extract the DOIs from the file names\n",
    "editorial_dois = [file.split('_')[0] for file in files]\n",
    "editorial_dois = list(editorial_dois)\n",
    "editorial_dois = [doi.replace('.pdf', '').replace('.S', '/S') for doi in editorial_dois]\n",
    "\n",
    "# Exclude the Editorial Board articles \n",
    "all_urls = all_urls[~all_urls['DOI'].isin(editorial_dois)]\n",
    "filtered_urls = filtered_urls[~filtered_urls['DOI'].isin(editorial_dois)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6194f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique DOIs:  815\n",
      "Extracted URLs (excl. NaN values):  5382\n",
      "Count of DOIs with NaN values in the 'URL' column: 0\n",
      "'www.elsevier.com/locate/neuroimage':  815\n",
      "creativecommons.org:  815\n",
      "doi:  891\n",
      "URLs to be filtered out:  2521\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique DOIs: \", len(all_urls['DOI'].unique()))\n",
    "print(\"Extracted URLs (excl. NaN values): \", len(all_urls[~all_urls['URL'].isna()]))\n",
    "count_of_nan_dois = all_urls['URL'].isna().sum()\n",
    "print(\"Count of DOIs with NaN values in the 'URL' column:\", count_of_nan_dois)\n",
    "\n",
    "urls_elsevier = len(all_urls[all_urls['URL'].str.contains('www.elsevier.com/locate/neuroimage')])\n",
    "urls_creativecommons = len(all_urls[all_urls['URL'].str.contains('creativecommons.org')])\n",
    "urls_doi = len(all_urls[all_urls['URL'].str.contains('doi')])\n",
    "print(\"'www.elsevier.com/locate/neuroimage': \", urls_elsevier)\n",
    "print('creativecommons.org: ', urls_creativecommons)\n",
    "print('doi: ', urls_doi)\n",
    "print(\"URLs to be filtered out: \", urls_elsevier+urls_creativecommons+urls_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f9c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [URL, Sentences, DOI]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls[all_urls['URL'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74d3080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique DOIs:  815\n",
      "Extracted URLs (excl. NaN values):  2861\n",
      "Count of DOIs with NaN values in the 'URL' column: 122\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique DOIs: \", len(filtered_urls['DOI'].unique()))\n",
    "print(\"Extracted URLs (excl. NaN values): \", len(filtered_urls[~filtered_urls['URL'].isna()]))\n",
    "count_of_nan_dois = filtered_urls['URL'].isna().sum()\n",
    "print(\"Count of DOIs with NaN values in the 'URL' column:\", count_of_nan_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18abbfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2021.118840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.118982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      URL Sentences                               DOI\n",
       "2880  NaN       NaN  10.1016/j.neuroimage.2022.119207\n",
       "2881  NaN       NaN  10.1016/j.neuroimage.2022.119328\n",
       "2882  NaN       NaN  10.1016/j.neuroimage.2022.119643\n",
       "2883  NaN       NaN  10.1016/j.neuroimage.2021.118840\n",
       "2884  NaN       NaN  10.1016/j.neuroimage.2022.118982\n",
       "...   ...       ...                               ...\n",
       "2997  NaN       NaN  10.1016/j.neuroimage.2022.119406\n",
       "2998  NaN       NaN  10.1016/j.neuroimage.2022.119058\n",
       "2999  NaN       NaN  10.1016/j.neuroimage.2022.119633\n",
       "3000  NaN       NaN  10.1016/j.neuroimage.2022.119137\n",
       "3001  NaN       NaN  10.1016/j.neuroimage.2022.119678\n",
       "\n",
       "[122 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_urls[filtered_urls['URL'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15753f3c",
   "metadata": {},
   "source": [
    "There are a 122 articles that do not contain any URLs (excluding the 'Editorial Board' articles). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e12ca69c-8c2f-4f7d-aede-ab3b6f226f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Num_URLs</th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.neuroimage.2022.119406</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      URL Sentences                               DOI  Num_URLs   URLs\n",
       "2997  nan       NaN  10.1016/j.neuroimage.2022.119406         1  [nan]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_urls[filtered_urls['DOI']=='10.1016/j.neuroimage.2022.119406']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c19b72d-e815-4f38-a212-af6b540131c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs per DOI:\n",
      "                                   DOI  URL_count  \\\n",
      "0     10.1016/j.neuroimage.2021.118698          1   \n",
      "1     10.1016/j.neuroimage.2021.118698          1   \n",
      "2     10.1016/j.neuroimage.2021.118698          1   \n",
      "3     10.1016/j.neuroimage.2021.118698          1   \n",
      "4     10.1016/j.neuroimage.2021.118714          1   \n",
      "...                                ...        ...   \n",
      "2978  10.1016/j.neuroimage.2022.119768          1   \n",
      "2979  10.1016/j.neuroimage.2022.119769          1   \n",
      "2980  10.1016/j.neuroimage.2022.119769          1   \n",
      "2981  10.1016/j.neuroimage.2022.119771          1   \n",
      "2982  10.1016/j.neuroimage.2022.119772          1   \n",
      "\n",
      "                                                    URL  \n",
      "0                http://audition.ens.fr/adc/NoiseTools/  \n",
      "1            https://github.com/mickcrosse/mTRF-Toolbox  \n",
      "2                                 https://osf.io/q9s5k/  \n",
      "3             https://sccn.ucsd.edu/eeglab/download.php  \n",
      "4                                 childrens.harvard.edu  \n",
      "...                                                 ...  \n",
      "2978               nitrc.org/indi/CoRR/html/bnu_3.html)  \n",
      "2979                  http://surfer.nmr.mgh.harvard.edu  \n",
      "2980  https://github.com/brainneuro/Multi-Face-attri...  \n",
      "2981                                                nan  \n",
      "2982                                                nan  \n",
      "\n",
      "[2983 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set URL_count to 0 for rows where URL is NaN\n",
    "filtered_urls['URL_count'] = np.where(filtered_urls['URL'].isna(), 0, 1)\n",
    "\n",
    "# Group by DOI and URL for the rest\n",
    "grouped_urls = (\n",
    "    filtered_urls[filtered_urls['URL_count'] == 1]\n",
    "    .groupby(['DOI', 'URL'])\n",
    "    .size()\n",
    "    .reset_index(name='URL_count')\n",
    ")\n",
    "\n",
    "# Concatenate the two results\n",
    "final_url_count_per_doi = pd.concat([filtered_urls[filtered_urls['URL_count'] == 0][['DOI', 'URL_count']], grouped_urls], ignore_index=True)\n",
    "\n",
    "print(\"Number of URLs per DOI:\")\n",
    "print(final_url_count_per_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c874fee7-0d2d-48af-b954-27451565eb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>URLs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DOI, URLs_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_count_per_doi[url_count_per_doi['URLs_count']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4a2cec3-29c1-42dd-844b-5a429ee7a0d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m filtered_urls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURLs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_urls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(x) \u001b[38;5;28;01melse\u001b[39;00m [])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Count the number of URLs per DOI, treating NaN as 0\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m url_count_per_doi \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_urls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDOI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mURLs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublist\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of URLs per DOI:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(url_count_per_doi)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/generic.py:244\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m    239\u001b[0m     _apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, examples\u001b[38;5;241m=\u001b[39m_apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m )\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1423\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_selection_context():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1464\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     not_indexed_same: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1464\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1467\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    760\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 761\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    763\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m filtered_urls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURLs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_urls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(x) \u001b[38;5;28;01melse\u001b[39;00m [])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Count the number of URLs per DOI, treating NaN as 0\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m url_count_per_doi \u001b[38;5;241m=\u001b[39m filtered_urls\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOI\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURLs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(y \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m sublist)) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(x\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of URLs per DOI:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(url_count_per_doi)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Urls per article on average, including the ranges \n",
    "filtered_urls['URL'] = filtered_urls['URL'].astype(str)\n",
    "filtered_urls['DOI'] = filtered_urls['DOI'].astype(str)\n",
    "\n",
    "# Split multiple URLs in 'URL' column\n",
    "filtered_urls['URLs'] = filtered_urls['URL'].apply(lambda x: x.split(',') if pd.notna(x) else [])\n",
    "\n",
    "# Count the number of URLs per DOI, treating NaN as 0\n",
    "url_count_per_doi = filtered_urls.groupby('DOI')['URLs'].apply(lambda x: len(set(y for sublist in x for y in sublist)) if pd.notna(x.iloc[0]) else 0).reset_index()\n",
    "\n",
    "print(\"Number of URLs per DOI:\")\n",
    "print(url_count_per_doi)\n",
    "print(\"Highest number of URLs in an article:\", url_count_per_doi['URLs'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b214340-6698-4540-8d99-f0da56d40699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DOI, URLs]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_count_per_doi[url_count_per_doi['URLs']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f6c307-7a0e-4a02-a930-754190c6be9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(url_count_per_doi['URLs'], bins=range(0, url_count_per_doi['URLs'].max() + 1), edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Number of URLs')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.title('Distribution of URLs per Article')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d11cd",
   "metadata": {},
   "source": [
    "<a name='references'></a>\n",
    "# References\n",
    "\n",
    "- Lipovský, J. (2022). urlextract: Collects and extracts URLs from given text. (1.8.0) [Python]. https://github.com/lipoja/URLExtract\n",
    "- Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, É. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12(85), 2825–2830.\n",
    "- Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
