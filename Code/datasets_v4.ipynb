{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7067776c",
   "metadata": {},
   "source": [
    "# Table of contents \n",
    "- [Setup](#setup) \n",
    "    - [Target](#target)\n",
    "    - [Libraries](#libraries)\n",
    "- [Get datasets](#getdatasets)\n",
    "    - [Get URLs](#geturls)\n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[Old code](#oldcode)\n",
    "- [Gather datasets](#gatherdatasets)\n",
    "    - [Get text sections](#gettextsections)\n",
    "        - [Section patterns v1](#sectionpatternsv1)\n",
    "        - [Section patterns v2](#sectionpatternsv2)\n",
    "        - [Section patterns v3](#sectionpatternsv3)\n",
    "    - [Preprocessing text sections](#preprocessingtextsections) \n",
    "        - [Start patterns](#startpatterns)\n",
    "        - [Clean text](#cleantext)\n",
    "    - [Get datasets](#getdatasets)\n",
    "        - ['Availability' pattern](#availabilitypattern)\n",
    "        - [Other section patterns](#othersectionpatterns)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af309d",
   "metadata": {},
   "source": [
    "<a name='setup'></a>\n",
    "# 0. Setup \n",
    "\n",
    "This notebook contains the code to extract the datasets used in the articles published in NeuroImage in 2022. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='target'></a> \n",
    "## 0.1. Target\n",
    "The goal is the use pypdf to locate and extract the datasets used for analysis in the research articles. Based on an initial review of nine random \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='libraries'></a>\n",
    "## 0.2. Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0a00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json \n",
    "import os \n",
    "import re \n",
    "\n",
    "# Read PDFs\n",
    "import pypdf \n",
    "# Extract URLs from text \n",
    "import urlextract "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c327e",
   "metadata": {},
   "source": [
    "# 1. Get datasets \n",
    "<a name='getdatasets'></a>\n",
    "Steps: \n",
    "- Get sentences that contain URLs. \n",
    "- Clean sentences. \n",
    "\n",
    "<br>\n",
    "\n",
    "## 1.1. Get URLs \n",
    "<a name='geturls'></a>\n",
    "Based on my exploration of ten randomly picked articles, 75% of the articles contained links to the dataset(s) used for analysis - of the articles that did not contain links, they either used self-collected data or no datasets at all. \n",
    "\n",
    "I use the work of Sourget (2023) to search the PDFs for their datasets: \n",
    "- *get_content* is losely interpreted from Soruget (2023) using the following breadcrumb in the github repository: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "\n",
    "I use the Python library urlextract by Lipovský (2022) to extract the URLs. \n",
    "\n",
    "<br>\n",
    "\n",
    "References: \n",
    "- Lipovský, J. (2022). urlextract: Collects and extracts URLs from given text. (1.8.0) [Python]. https://github.com/lipoja/URLExtract\n",
    "- Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9ac1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(pdf_path, alt_pdf_path):\n",
    "    \"\"\"Get sentences that contain URLs. \n",
    "    This function is loosely interpreted from Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget\n",
    "    specifically: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "    \n",
    "    Parameters: \n",
    "    :param pdf_path (str): Path to the PDF file.\n",
    "    :param alt_pdf_path (str): Alternative path to the PDF file. \n",
    "    \n",
    "    Returns: \n",
    "    :return: Extracted sentence or 'Editorial board' if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_file = open(pdf_path, 'rb')\n",
    "        pdf_reader = pypdf.PdfReader(pdf_file)\n",
    "        # Read the entire PDF content\n",
    "        pdf_text = \" \".join(page.extract_text() for page in pdf_reader.pages)\n",
    "        \n",
    "        # Extract sentences containing datasets\n",
    "        content = get_datasets(pdf_text)\n",
    "        if content: \n",
    "            return content \n",
    "        pdf_file.close()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            # Try to open the PDF from the alternative directory\n",
    "            alternative_pdf_path = os.path.join(alt_pdf_path, os.path.basename(pdf_path))\n",
    "            # print(alternative_pdf_path)\n",
    "            pdf_file = open(alternative_pdf_path, 'rb')\n",
    "            return 'Editorial board'\n",
    "        except FileNotFoundError:\n",
    "            # If PDF is not found in the original or alternative directory, return 'Editorial board'\n",
    "            return 'Editorial board'\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "        \n",
    "\n",
    "############### SENTENCES ################################################\n",
    "def split_text_into_sentences(text):\n",
    "    \"\"\"This function splits a given text into sentences based on a regular expression pattern. \n",
    "    It uses re.split() to identify sentence boundaries, considering common sentence-ending \n",
    "    punctuation like \".\", \"!\", or \"?\". It avoids splitting sentences if a digit immediately \n",
    "    follows the punctuation, e.g., 'Fig. 1'. \n",
    "    \n",
    "    Parameters: \n",
    "    :param text(str): \n",
    "    \n",
    "    Returns: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    sentence_pattern = r'(?<=[.!?])\\s+(?![0-9]+\\s)'\n",
    "    sentences = re.split(sentence_pattern, text)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "############### LINKS ################################################\n",
    "def extract_links(text): \n",
    "    # Create an instance of the URLExtract class\n",
    "    extractor = urlextract.URLExtract()\n",
    "\n",
    "    urls = []\n",
    "    for url in extractor.gen_urls(text):\n",
    "        urls.append(url)\n",
    "        \n",
    "    return urls \n",
    "\n",
    "############### DATASETS ################################################\n",
    "def get_datasets(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Initialize lists to store extracted datasets and their corresponding sentences\n",
    "    extracted_datasets = []\n",
    "    dataset_sentences = []\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = split_text_into_sentences(text)\n",
    "    \n",
    "    # Extract links and capitalized words\n",
    "    links = extract_links(text)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        datasets_in_sentence = []\n",
    "        \n",
    "        # Check if the sentence contains a link\n",
    "        for link in links:\n",
    "            if link in sentence:\n",
    "                datasets_in_sentence.append(link)\n",
    "        \n",
    "        # Check if the sentence contains the word \"request\"\n",
    "        if \"request\" in sentence.lower():\n",
    "            datasets_in_sentence.append(\"Request\")\n",
    "        \n",
    "        if datasets_in_sentence:\n",
    "            # If any datasets were found in the sentence, add them and the sentence itself\n",
    "            extracted_datasets.extend(datasets_in_sentence)\n",
    "            dataset_sentences.extend([sentence] * len(datasets_in_sentence))\n",
    "    \n",
    "    # If no dataset was found, return None\n",
    "    if not extracted_datasets:\n",
    "        return None\n",
    "    \n",
    "    #df = pd.DataFrame({'dataset': extracted_datasets, 'dataset_sentence': dataset_sentences})\n",
    "    #return df\n",
    "\n",
    "    return extracted_datasets, dataset_sentences\n",
    "\n",
    "\n",
    "###############\n",
    "def extract_and_add_datasets(row, text_column):\n",
    "    \"\"\"This function needs a description \n",
    "    \n",
    "    Parameters: \n",
    "    :param row: \n",
    "    :param text_column: \n",
    "    \n",
    "    Returns: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    result = get_datasets(row[text_column])\n",
    "    \n",
    "    if result is None:\n",
    "        return None\n",
    "    \n",
    "    if len(result) == 2:\n",
    "        datasets, sentences = result\n",
    "    else:\n",
    "        # Handle the case where get_datasets didn't return the expected two values\n",
    "        datasets, sentences = [\"N/A\"], [\"N/A\"]\n",
    "    \n",
    "    rows_list = []\n",
    "    for dataset, sentence in zip(datasets, sentences):\n",
    "        new_row = row.copy()\n",
    "        new_row['dataset'] = dataset\n",
    "        new_row['dataset_sentence'] = sentence\n",
    "        rows_list.append(new_row)\n",
    "    \n",
    "    return rows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "869869e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing PDFs\n",
    "articles_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_articles_doi/'\n",
    "editorialboard_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_editorialboard_doi/'\n",
    "\n",
    "# Path to the JSON file containing DOI values\n",
    "json_file_path = '../Data/ElsevierAPI/downloadedPDFs_info.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71bff6",
   "metadata": {},
   "source": [
    "I will test the functions using the groundtruth texts as my validation set. \n",
    "When manually extracting the datasets from the ten groundtruth texts, we should get the following datasets (NB! Currently, I have not distinguished between links that leads the reader to data and links that leads the reader to code - this will come later): \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "| DOI                                   | Dataset                                      | Dataset_sentence                                                                                                                                                                                            |\n",
    "|---------------------------------------|----------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 10.1016/j.neuroimage.2022.119526       | Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil)                       | Original data was obtained from the Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil) and the Allen Hu-man Brain Atlas (http://human.brain-map.org/).                    |\n",
    "|                                        | Allen Hu-man Brain Atlas (http://human.brain-map.org/)                                | Original data was obtained from the Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil) and the Allen Hu-man Brain Atlas (http://human.brain-map.org/).                    |\n",
    "|                                        | https://github.com/jbrown81/gradients                                    | All code (latent space derivation, dynamical system modeling, and gene expression corre-lation) and processed data (gradient maps/region weights, gradient timeseries, and region gene expression values) are available at https://github.com/jbrown81/gradients. |\n",
    "| 10.1016/j.neuroimage.2022.119443       | osf.io/gazx2/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/eucqf/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/thsqg/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/bndjg/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/guwnm/                               | Code used to reproduce the plots in Fig. 1 , as well as averaged ERP data, is available from osf.io/guwnm/.                                      |\n",
    "| 10.1016/j.neuroimage.2022.119240       | Request                                           | statement Data used in this study are available from the corresponding author upon reasonable request.                                                                         |\n",
    "| 10.1016/j.neuroimage.2022.119050       | zenodo.org (doi: 10.5281/zenodo.6110595) | Raw EEG data from all healthy individuals, as well as Matlab code, are publicly available on zenodo.org (doi: 10.5281/zenodo.6110595).                         |\n",
    "| 10.1016/j.neuroimage.2021.118854       | Human Connectome Project website (https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation) | The data used in this study was downloaded from the Human Connectome Project website (https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation). |\n",
    "|                                       | https://github.com/ferreirafabio80/gfa | The GFA models and experiments were implemented in Python 3.9.1 and are available here: https://github.com/ferreirafabio80/gfa.                                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c96314be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of groundtruth DOI values to filter \n",
    "validation_dois = [\n",
    "    '10.1016/j.neuroimage.2021.118839',\n",
    "    '10.1016/j.neuroimage.2021.118854',\n",
    "    '10.1016/j.neuroimage.2022.119030',\n",
    "    '10.1016/j.neuroimage.2022.119050',\n",
    "    '10.1016/j.neuroimage.2022.119240',\n",
    "    '10.1016/j.neuroimage.2022.119443',\n",
    "    '10.1016/j.neuroimage.2022.119526',\n",
    "    '10.1016/j.neuroimage.2022.119549',\n",
    "    '10.1016/j.neuroimage.2022.119646',\n",
    "    '10.1016/j.neuroimage.2022.119676',\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbc29f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store individual results\n",
    "results_list = []\n",
    "\n",
    "# Read DOI values from the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    doi_data = json.load(json_file)\n",
    "\n",
    "    # Get the first 10 DOIs\n",
    "    #first_10_dois = doi_data['DOIs'][:10]\n",
    "\n",
    "    for doi in validation_dois:\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(articles_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content function for each DOI\n",
    "        sentence = get_content(pdf_path, editorialboard_directory)\n",
    "\n",
    "        # Create a dictionary for each result and add it to the list\n",
    "        results_list.append({\"DOI\": doi, \"Section\": sentence})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267979e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_datasets, dataset_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8816f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['www.elsevier.com/locate/neuroimage',\n",
       "  'https://doi.org/10.1016/j.neuroimage.2021.118839',\n",
       "  'http://creativecommons.org/licenses/by-nc-nd/4.0/',\n",
       "  'http://neuroimage.usc.edu/brainstorm'],\n",
       " ['NeuroImage  248 (2022) 118839 \\nContents  lists available  at ScienceDirect  \\nNeuroImage  \\njournal  homepage:  www.elsevier.com/locate/neuroimage  \\nMotor  impairment  evoked  by direct  electrical  stimulation  of human  \\nparietal  cortex  during  object  manipulation  \\nLuca Fornia  a , c , Marco  Rossi b , Marco  Rabuﬀetti  c , Andrea  Bellacicca  a , Luca Viganòb , \\nLuciano  Simone  d , Henrietta  Howells  a , Guglielmo  Puglisi  a , Antonella  Leonetti  a , \\nVincenzo  Callipo  e , Lorenzo  Bello b , Gabriella  Cerri e , ∗ \\na Laboratory  of Motor Control, Department  of Medical Biotechnologies  and Translational  Medicine,  Universitàdegli  Studi di Milano, Italy \\nb Neurosurgical  Oncology Unit, Department  of Oncology and Hemato-Oncology,  Universitàdegli  Studi di Milano, Italy \\nc IRCCS Fondazione  Don Carlo Gnocchi, Milano, Italy \\nd Cognition,  Motion & Neuroscience,  Center for Human Technologies,  Istituto Italiano di Tecnologia,  Genoa, Italy \\ne Laboratory  of Motor Control, Department  of Medical Biotechnologies  and Translational  Medicine,  Universitàdegli  Studi di Milano, Humanitas  Research Hospital \\nIRCSS, Rozzano, Milano, Italy \\na r t i c l e i n f o \\nKeywords:  \\nHuman Parietal cortex \\nmotor control \\nhand-manipulation  \\nEMG \\nintraoperative  stimulation  a b s t r a c t \\nIn primates,  the parietal cortex plays a crucial role in hand-object  manipulation.',\n",
       "  'Corticospinal  projections  has been shown also from other pari- \\netal sectors including  area 1, 2, anterior  intraparietal  and inferior  pari- \\netal areas ( Nudo et al., 1990 ; Rozzi et al., 2006 ; Innocenti  et al., 2019 ), \\nhttps://doi.org/10.1016/j.neuroimage.2021.118839  .',\n",
       "  'This is an open access article under the CC BY-NC-ND  license \\n( http://creativecommons.org/licenses/by-nc-nd/4.0/  )  L.',\n",
       "  'Subsequently  the results were loaded in a Matlab \\nTool Box, Brainstorm  ( Tadel et al. 2011 ), an accredited  software  freely \\navailable  for download  online under the GNU general  public license \\n( http://neuroimage.usc.edu/brainstorm  ).'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Section'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c830a052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.elsevier.com/locate/neuroimage</td>\n",
       "      <td>https://doi.org/10.1016/j.neuroimage.2021.118839</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/4.0/</td>\n",
       "      <td>http://neuroimage.usc.edu/brainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuroImage  248 (2022) 118839 \\nContents  list...</td>\n",
       "      <td>Corticospinal  projections  has been shown als...</td>\n",
       "      <td>This is an open access article under the CC BY...</td>\n",
       "      <td>Subsequently  the results were loaded in a Mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                 www.elsevier.com/locate/neuroimage   \n",
       "1  NeuroImage  248 (2022) 118839 \\nContents  list...   \n",
       "\n",
       "                                                   1  \\\n",
       "0   https://doi.org/10.1016/j.neuroimage.2021.118839   \n",
       "1  Corticospinal  projections  has been shown als...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  http://creativecommons.org/licenses/by-nc-nd/4.0/   \n",
       "1  This is an open access article under the CC BY...   \n",
       "\n",
       "                                                   3  \n",
       "0               http://neuroimage.usc.edu/brainstorm  \n",
       "1  Subsequently  the results were loaded in a Mat...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed9db3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['www.elsevier.com/locate/neuroimage',\n",
       "  'https://doi.org/10.1016/j.neuroimage.2021.118854',\n",
       "  'http://creativecommons.org/licenses/by/4.0/',\n",
       "  'https://www.humanconnectome.org/study/hcp-',\n",
       "  'https://www.humanconnectome.org/study/hcp-',\n",
       "  'https://www.humanconnectome.org/study/hcp-young-',\n",
       "  'https://github.com/ferreirafabio80/gfa',\n",
       "  'https://statistics.berkeley.edu/tech-reports/688',\n",
       "  'https://dl.acm.org/doi/book/10.5555/1162264',\n",
       "  'https://dl.acm.org/doi/10.5555/3104482.3104540',\n",
       "  'http://proceedings.mlr.press/v22/virtanen12.html',\n",
       "  'https://dl.acm.org/doi/10.5555/2946645.3053478'],\n",
       " ['NeuroImage  249 (2022) 118854 \\nContents  lists available  at ScienceDirect  \\nNeuroImage  \\njournal  homepage:  www.elsevier.com/locate/neuroimage  \\nA hierarchical  Bayesian  model  to ﬁnd brain-behaviour  associations  in \\nincomplete  data  sets \\nFabio  S.',\n",
       "  'Second,  the \\nassociations  within data modalities,  which might explain  important  vari- \\nhttps://doi.org/10.1016/j.neuroimage.2021.118854  .',\n",
       "  'This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/  )  F.S.',\n",
       "  'subjects  (only these had rs-fMRI  data available)  of the 1200-subject  data \\nrelease of the HCP ( https://www.humanconnectome.org/study/hcp-  \\nyoung-adult/data-releases  ).',\n",
       "  'Data and code availability  \\nThe data used in this study was downloaded  \\nfrom the Human  Connectome  Project website  \\n( https://www.humanconnectome.org/study/hcp-young-  \\nadult/document/extensively-processed-fmri-data-documentation  ).',\n",
       "  'Data and code availability  \\nThe data used in this study was downloaded  \\nfrom the Human  Connectome  Project website  \\n( https://www.humanconnectome.org/study/hcp-young-  \\nadult/document/extensively-processed-fmri-data-documentation  ).',\n",
       "  'The GFA models and experiments  were implemented  in Python 3.9.1 \\nand are available  here: https://github.com/ferreirafabio80/gfa  .',\n",
       "  'https://statistics.berkeley.edu/tech-reports/688  \\nBijsterbosch,  J.D., Woolrich,  M.W., Glasser, M.F., Robinson,  E.C., Beckmann,  C.F., Van Es- \\nsen, D.C., Harrison,  S.J., Smith, S.M., 2018.',\n",
       "  'https://dl.acm.org/doi/book/10.5555/1162264  .',\n",
       "  'https://dl.acm.org/doi/10.5555/3104482.3104540  \\nVirtanen,  S., Klami, A., Khan, S., Kaski, S., 2012.',\n",
       "  'http://proceedings.mlr.press/v22/virtanen12.html  \\nWaaijenborg,  S., Verselewel  de Witt Hamer, P.C., Zwinderman,  A.H., 2008.',\n",
       "  'https://dl.acm.org/doi/10.5555/2946645.3053478  \\n15 '])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Section'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ed499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308e655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd6bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cd6525d",
   "metadata": {},
   "source": [
    "---\n",
    "<a name = 'oldcode'></a>\n",
    "# OLD CODE \n",
    "\n",
    "<a name='gatherdatasets'></a>\n",
    "# 1. Gather datasets \n",
    "\n",
    "PLAN OF ATTACK TO EXPLORE: \n",
    "* IF - Locate 'Data availability' (or similar) section and look for links - if multiple, save all of them and look at surrounding words for context \n",
    "* ELSE If there is no 'Data availability' (or similar) section \n",
    "\t* Look at wording in section 2.1 \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='gettextsections'></a>\n",
    "## 1.1. Get text sections \n",
    "\n",
    "I use the work of Akkoç (2023) and Sourget (2023) to search the PDFs for their datasets. I am using the code from two separate git repositories as inspiration for the two functions presented in this section. \n",
    "- *get_section* is losely interpreted from Akkoç (2023) using the following breadcrumb in the github repository: PublicDatasets/ArticleAnalyser.ipynb, section '2.1 Get section function'\n",
    "- *get_content* is losely interpreted from Soruget (2023) using the following breadcrumb in the github repository: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "\n",
    "<br>\n",
    "\n",
    "References: \n",
    "- Akkoç, A. (2023). PublicDatasets [Jupyter Notebook]. https://github.com/madprogramer/PublicDatasets (Original work published 2022)\n",
    "- Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fc7a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(pdf_path, alt_pdf_path, section_patterns):\n",
    "    \"\"\"Get a PDF. \n",
    "    This function is loosely interpreted from Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget\n",
    "    specifically: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "    \n",
    "    Parameters: \n",
    "    :param pdf_path (str): Path to the PDF file.\n",
    "    :param json_file_path (str): Path to the JSON file containing the DOIs of the relevant research articles. \n",
    "    \n",
    "    Returns: \n",
    "    :return: Extracted content or 'Editorial board' if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_file = open(pdf_path, 'rb')\n",
    "        pdf_reader = pypdf.PdfReader(pdf_file)\n",
    "        # Read the entire PDF content\n",
    "        pdf_text = \" \".join(page.extract_text() for page in pdf_reader.pages)\n",
    "        \n",
    "        # Extract sections using the provided section patterns\n",
    "        content = get_section(pdf_text, section_patterns)\n",
    "        if content: \n",
    "            return content \n",
    "        pdf_file.close()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            # Try to open the PDF from the alternative directory\n",
    "            alternative_pdf_path = os.path.join(alt_pdf_path, os.path.basename(pdf_path))\n",
    "            print(alternative_pdf_path)\n",
    "            pdf_file = open(alternative_pdf_path, 'rb')\n",
    "            return 'Editorial board'\n",
    "        except FileNotFoundError:\n",
    "            # If PDF is not found in the original or alternative directory, return 'Editorial board'\n",
    "            return 'Editorial board'\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "\n",
    "\n",
    "def get_section(article, section_patterns):\n",
    "    \"\"\"Get sections from a research paper based on patterns.\n",
    "    This function is losely interpreted from Akkoç, A. (2023). PublicDatasets [Jupyter Notebook]. https://github.com/madprogramer/PublicDatasets (Original work published 2022) with some alterations.\n",
    "    specifically PublicDatasets/ArticleAnalyser.ipynb, section '2.1 Get section function'\n",
    "    \n",
    "    Parameters: \n",
    "    :param article (str): Text contents of the research paper.\n",
    "    :param section_patterns (list of lists): A list of lists where each inner list represents the start and end patterns.\n",
    "    \n",
    "    Returns: \n",
    "    :return: The extracted section text.\n",
    "    \"\"\"\n",
    "    article_lower = article.lower()  # Convert contents to lowercase\n",
    "\n",
    "    # Attempt to find the section based on the current patterns (case-insensitive)\n",
    "    for start_patterns, end_patterns in section_patterns:\n",
    "        for start_pattern in start_patterns:\n",
    "            start_pattern = re.compile(re.escape(start_pattern), re.IGNORECASE)\n",
    "            match_start = start_pattern.search(article_lower)\n",
    "            if match_start:\n",
    "                idx0 = match_start.start()\n",
    "                for end_pattern in end_patterns:\n",
    "                    end_pattern = re.compile(re.escape(end_pattern), re.IGNORECASE)\n",
    "                    match_end = end_pattern.search(article_lower[idx0:])\n",
    "                    if match_end:\n",
    "                        end_idx = idx0 + match_end.end()\n",
    "                        section = article[idx0:end_idx]  # Extract the matched section\n",
    "                        return section\n",
    "\n",
    "    # If no match is found, return an empty string\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3593a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing PDFs\n",
    "pdf_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_articles_doi/'\n",
    "alternative_pdf_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_editorialboard_doi/'\n",
    "\n",
    "# Path to the JSON file containing DOI values\n",
    "json_file_path = '../Data/ElsevierAPI/downloadedPDFs_info.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4c760",
   "metadata": {},
   "source": [
    "<a name='sectionpatternsv1'></a>\n",
    "### 1.1.1. Section patterns v1 \n",
    "Before I continue working on extracting the dataset names and potential links from the sections, I am curious to see how the section pattern performs. \n",
    "\n",
    "I investigate the first ten DOIs in downloadedPDFs_info.json() to see exactly what text sections were extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "055f59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_patterns = [\n",
    "    ([\"Data and Code Availability\", \"Data Availability\"], [\"3\", \"CRediT authorship contribution statement\", \"Acknowledgements\", \"References\"]),\n",
    "    ([\"2.1\"], [\"2.2\"]),\n",
    "    ([\"Resource\", \"3.1 'Resource'\"], [\"3.2\"]),\n",
    "    ([\"Fig.\\d+\", \"Fig.\\d+\\.?\", \"Figure \\d+\"], [\"https?://[^\\s]+\"]),\n",
    "    ([\"Tab.\\d+\", \"Table \\d+\\.?\"], [\"https?://[^\\s]+\", \"[\\w\\s-]+\\d{4}\"]),\n",
    "    ([\"Introduction\", \"1\"], [\"2\"]),\n",
    "    ([\"Abstract\"], [\"1\", \"Introduction\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc263ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store individual results\n",
    "results_list = []\n",
    "\n",
    "# Read DOI values from the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    doi_data = json.load(json_file)\n",
    "\n",
    "    # Get the first 10 DOIs\n",
    "    first_10_dois = doi_data['DOIs'][:10]\n",
    "\n",
    "    for doi in first_10_dois:\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(pdf_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content function for each DOI\n",
    "        section_content = get_content(pdf_path, alternative_pdf_directory, section_patterns)\n",
    "\n",
    "        # Create a dictionary for each result and add it to the list\n",
    "        results_list.append({\"DOI\": doi, \"Section\": section_content})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052a4712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119451</td>\n",
       "      <td>Data and code availability  statements  \\nSpec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119632</td>\n",
       "      <td>Data and code availability  \\nThe data incorpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119584</td>\n",
       "      <td>Data Availability  \\nData will be made availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119550</td>\n",
       "      <td>Data and code availability  \\nAll data used in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119710</td>\n",
       "      <td>Data and code availability  statement  \\nAll i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119338</td>\n",
       "      <td>Data and code availability  \\nNo data were acq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118986</td>\n",
       "      <td>Data and Code Availability  Statement  \\nAll c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119192</td>\n",
       "      <td>Data and code availability  statement  \\nData ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119177</td>\n",
       "      <td>Data and code availability  statement  \\nThe E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119110</td>\n",
       "      <td>Data and code availability  statements  : The ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DOI  \\\n",
       "0  10.1016/j.neuroimage.2022.119451   \n",
       "1  10.1016/j.neuroimage.2022.119632   \n",
       "2  10.1016/j.neuroimage.2022.119584   \n",
       "3  10.1016/j.neuroimage.2022.119550   \n",
       "4  10.1016/j.neuroimage.2022.119710   \n",
       "5  10.1016/j.neuroimage.2022.119338   \n",
       "6  10.1016/j.neuroimage.2022.118986   \n",
       "7  10.1016/j.neuroimage.2022.119192   \n",
       "8  10.1016/j.neuroimage.2022.119177   \n",
       "9  10.1016/j.neuroimage.2022.119110   \n",
       "\n",
       "                                             Section  \n",
       "0  Data and code availability  statements  \\nSpec...  \n",
       "1  Data and code availability  \\nThe data incorpo...  \n",
       "2  Data Availability  \\nData will be made availab...  \n",
       "3  Data and code availability  \\nAll data used in...  \n",
       "4  Data and code availability  statement  \\nAll i...  \n",
       "5  Data and code availability  \\nNo data were acq...  \n",
       "6  Data and Code Availability  Statement  \\nAll c...  \n",
       "7  Data and code availability  statement  \\nData ...  \n",
       "8  Data and code availability  statement  \\nThe E...  \n",
       "9  Data and code availability  statements  : The ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2943c03",
   "metadata": {},
   "source": [
    "*In the following description, I refer to the index of the articles in results_df.*\n",
    "\n",
    "Observations from the text sections extracted with section_patterns: \n",
    "* In 1, 2, 4, 7, and 9, **the text is cut short because there's a mention of a number 3** within the section (in a link, in a release number, etc.). \n",
    "* In 2, they call it: 'Data/code availability statement'\n",
    "* In 2 and 9, the **end of the section can be 'Acknowledgements'**.\n",
    "* In 3 and 6, the **end of the section can be 'Declaration of Competing Interest'**.\n",
    "* In 4, 5, and 8, the **section ends with 'Credit authorship contribution statement'**.\n",
    "* In 5, we see that the use of a **URL does not necessarily mean that it's pointing to data (in this case, it's code and software)**. \n",
    "* In 6, we see that **the formulation of the text is important** (as the github link both contains data and code, but that is tricky to see). \n",
    "* In 7 and 8, they **mention which dataset they used, but do not link it**. \n",
    "* In 9, it says: \"The review summarizes data but does not contain new data.\" (this is important if I want to look into and further filter the documents for significance testing). \n",
    "\n",
    "<br>\n",
    "From this investigation I can see that I need to edit the section patterns. Ideas: \n",
    "\n",
    "- Maybe the end of a section can be \\n\\n? \n",
    "- Section end '3' should be called '3. ' - maybe this will fix some \n",
    "- Add variations: \n",
    "    - Section starts: \n",
    "        - Data/code availability statement\n",
    "    - Section ends: \n",
    "        - [data and code] Declaration of Competing Interest\n",
    "        - [data and code] Acknowledgements\n",
    "        - [data and code] Credit authorship contribution statement\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "FOR FUTURE STEPS: \n",
    "- URLs do not necessarily link to the data. \n",
    "- A git repository can contain both data and code - but not always. \n",
    "- The dataset might only be mentioned by name and not linked (so far, I've only seen the names in camelcase). \n",
    "- QUESTION: How do we treat reviews that summarizes data but does not contain new data? Is the reuse of a dataset not also the same as not containing new data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92ce80",
   "metadata": {},
   "source": [
    "<a name='sectionpatternsv2'></a>\n",
    "### 1.1.2. Section patterns v2 \n",
    "Based on my exploration on the performance of the first section patterns, I can see that they need to be rewritten. For version 2, I made a few edits: \n",
    "* Add variations\n",
    "    * Section starts: \n",
    "        * Data/code availability statement \n",
    "    * Section ends: \n",
    "        * '\\n\\n' (this could be a general way to end the section) \n",
    "        * [data and code] Declaration of Competing Interest\n",
    "        * [data and code] Acknowledgements\n",
    "        * [data and code] Credit authorship contribution statement\n",
    "* Change pattern containing numbers (e.g., '3' is now '3. ')\n",
    "<br>\n",
    "I investigate the next ten DOIs in downloadedPDFs_info.json() to see exactly what text sections were extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a805110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_patterns_v2 = [\n",
    "    ([\"Data and Code Availability\", \"Data Availability\", \"Data/code availability\"], [\"3. \", \"CRediT authorship contribution statement\", \"Acknowledgements\", \"References\", \"Declaration of Competing Interests\", \"Credit authorship contribution statement\", \"\\n\\n\"]),\n",
    "    ([\"2.1.\"], [\"2.2.\"]),\n",
    "    ([\"Resource\", \"3.1.\"], [\"3.2.\"]),\n",
    "    ([\"Fig.\\d+\", \"Fig.\\d+\\.?\", \"Figure \\d+\"], [\"https?://[^\\s]+\"]),\n",
    "    ([\"Tab.\\d+\", \"Table \\d+\\.?\"], [\"https?://[^\\s]+\", \"[\\w\\s-]+\\d{4}\"]),\n",
    "    ([\"Introduction\", \"1. \"], [\"2. \"]),\n",
    "    ([\"Abstract\"], [\"1. \", \"Introduction\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878c40a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/ElsevierAPI/downloaded_pdfs/fulltext_editorialboard_doi/10.1016.S1053-8119(22)00043-X.pdf\n"
     ]
    }
   ],
   "source": [
    "# Empty list to store individual results\n",
    "results_list_v2 = []\n",
    "\n",
    "# Read DOI values from the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    doi_data = json.load(json_file)\n",
    "\n",
    "    # Get the first 10 DOIs\n",
    "    first_10_dois = doi_data['DOIs'][11:21]\n",
    "\n",
    "    for doi in first_10_dois:\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(pdf_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content function for each DOI\n",
    "        section_content = get_content(pdf_path, alternative_pdf_directory, section_patterns_v2)\n",
    "\n",
    "        # Create a dictionary for each result and add it to the list\n",
    "        results_list_v2.append({\"DOI\": doi, \"Section\": section_content})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df2 = pd.DataFrame(results_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8340b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118931</td>\n",
       "      <td>Data availability  \\nThe Matlab code for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119447</td>\n",
       "      <td>2.1. Participants  \\nThirty-ﬁve  people (20 fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119403</td>\n",
       "      <td>Data and code availability  statement  \\nData ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118831</td>\n",
       "      <td>Data and code availability  statements  \\nThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119308</td>\n",
       "      <td>Data and code availability  statement  \\nFinni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1016/S1053-8119(22)00043-X</td>\n",
       "      <td>Editorial board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118792</td>\n",
       "      <td>data availability  \\nThe Shen 268 atlas is ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118890</td>\n",
       "      <td>data availability  \\nThe code used to run the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119339</td>\n",
       "      <td>Data and code availability  statement  \\nThe h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119295</td>\n",
       "      <td>Introduction  \\nReal-time  functional  magneti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DOI  \\\n",
       "0  10.1016/j.neuroimage.2022.118931   \n",
       "1  10.1016/j.neuroimage.2022.119447   \n",
       "2  10.1016/j.neuroimage.2022.119403   \n",
       "3  10.1016/j.neuroimage.2021.118831   \n",
       "4  10.1016/j.neuroimage.2022.119308   \n",
       "5     10.1016/S1053-8119(22)00043-X   \n",
       "6  10.1016/j.neuroimage.2021.118792   \n",
       "7  10.1016/j.neuroimage.2022.118890   \n",
       "8  10.1016/j.neuroimage.2022.119339   \n",
       "9  10.1016/j.neuroimage.2022.119295   \n",
       "\n",
       "                                             Section  \n",
       "0  Data availability  \\nThe Matlab code for the p...  \n",
       "1  2.1. Participants  \\nThirty-ﬁve  people (20 fe...  \n",
       "2  Data and code availability  statement  \\nData ...  \n",
       "3  Data and code availability  statements  \\nThe ...  \n",
       "4  Data and code availability  statement  \\nFinni...  \n",
       "5                                    Editorial board  \n",
       "6  data availability  \\nThe Shen 268 atlas is ava...  \n",
       "7  data availability  \\nThe code used to run the ...  \n",
       "8  Data and code availability  statement  \\nThe h...  \n",
       "9  Introduction  \\nReal-time  functional  magneti...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc69422",
   "metadata": {},
   "source": [
    "*In the following description, I refer to the index of the articles in results_df2.*\n",
    "\n",
    "Observations from the text sections extracted with section_patterns_v2: \n",
    "- In 0, there are links, but these are not to the dataset - they write \"The used data can be shared with other researchers upon reasonable request.\" \n",
    "- In 0 and 7, the next section is called 'Supplementary materials' - which means that my attempt at \\n\\n did not work.  \n",
    "- In 2, the only mention of data was picked up in section 2.1.\n",
    "- In 2, the 'Declaration  of Competing  Interest' was not picked up - it looks like it's because there are double spaces between the words. \n",
    "- In 3, the 'Credit authorship  contribution  statement' is not picked - double spaces?\n",
    "- In 6, the data section is called 'Code and data availability' - but it was picked up by 'data availability'. \n",
    "- In 6, there are multiple links mentioned - one for data (an atlas), one for the code, and one for the data. \n",
    "    - NB! When copying the URL for the data, it is broken up by the formatting: https://www.humanconnectome.org/study/hcp-young-adult/ document/1200-subjects-data-release - this is also the case for the atlas. \n",
    "- In 7 and 8, there are spaces in the URL. \n",
    "- In 8, the following section 'Declaration of Competing Interest' was not picked up. \n",
    "- In 9, the introduction was picked up: but it does not look like any data is analysed in this article. \n",
    "\n",
    "<br>\n",
    "From this investigation I can see that I need to edit the section patterns further. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "TO DO: \n",
    "\n",
    "- Section_patterns that do not work: \n",
    "    - Section_end: \\n\\n\n",
    "    - Section_end: 'Declaration  of Competing  Interest' + Section_end: 'Credit authorship  contribution  statement' + Section_end: 'Supplementary materials'\n",
    "        - double-spaces between words mess these up\n",
    "- Section_patterns I'm worried about: \n",
    "    - Section_start: 2.1. - what if it's '2.1'?\n",
    "    - Section_start: 'Code and data availability'\n",
    "- Undiscovered section_patterns: \n",
    "    - Section_end: 'Ethics statement'\n",
    "- Worries \n",
    "    - How to get the name of the dataset itself and the url\n",
    "        - The URL can be broken up by spaces (due to line changes in the pdf) - can I find a way to find out which is the entire URL? \n",
    "            - Is there any slashes in the text ahead? A parenthesis, dot, comma, or another symbol might end it URL. \n",
    "    - If someone uses e.g., HCP, do they use all of the data? Do I need to catch more text-sections to learn this (in relation to the discussion of significance testing - if they use different parts of the dataset, they are not testing on the same). \n",
    "        - \"Due to HCP and dHCP privacy policies, the preprocessed resting-state images of human adults and neonates (with their IDs) can only be shared upon request with qualified investigators who agree to the Restricted Data Use Terms of these two datasets.\" (from 10.1016/j.neuroimage.2022.119339)\n",
    "    - What if the article does not analyse any data? (e.g., 10.1016/j.neuroimage.2022.119295 presents a software package for the execution of RT-fMRI experiments. \n",
    "- FUNCTION GET_CONTENT: Make a comment about trying the \"Editorial board\" texts in the other file - just so I don't get en \"Error reading PDF:\" \n",
    "    - Make an addition to 'get_section' where the says 'Editorial board' instead of None for the section text. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be6ece",
   "metadata": {},
   "source": [
    "### 1.1.3. Section patterns v3 \n",
    "\n",
    "I want to make a regex_pattern work, as it seems like a double space after \n",
    "\n",
    "TO DO: \n",
    "- Section_patterns that do not work: \n",
    "    - Section_end: \\n\\n\n",
    "    - Section_end: 'Declaration  of Competing  Interest' + Section_end: 'Credit authorship  contribution  statement' + Section_end: 'Supplementary materials'\n",
    "        - double-spaces between words messed these up. \n",
    "- Section_patterns I'm worried about: \n",
    "    - Section_start: '2.1.' - what if it's '2.1'?\n",
    "    - Section_start: 'Code and data availability'\n",
    "- Undiscovered section_patterns: \n",
    "    - Section_end: 'Ethics statement'\n",
    "- Make the titles case sensitive, and it seems like most only capitalize the first word (see investigation in ../Code/articles_groundtruth.ipynb under 'Ground truth/Investigation/Section titles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43fe3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_regex(pdf_path, alt_pdf_path, section_patterns):\n",
    "    try:\n",
    "        pdf_file = open(pdf_path, 'rb')\n",
    "        pdf_reader = pypdf.PdfReader(pdf_file)\n",
    "        # Read the entire PDF content\n",
    "        pdf_text = \" \".join(page.extract_text() for page in pdf_reader.pages)\n",
    "        \n",
    "        # Extract sections using the provided section patterns\n",
    "        content, matched_start_pattern, start_pattern, end_pattern = get_section_regex(pdf_text, section_patterns)\n",
    "        \n",
    "        if content:\n",
    "            return content, matched_start_pattern, start_pattern, end_pattern\n",
    "        else:\n",
    "            # Handle the case where no content is found\n",
    "            return content, matched_start_pattern, start_pattern, end_pattern\n",
    "        pdf_file.close()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            # Try to open the PDF from the alternative directory\n",
    "            alternative_pdf_path = os.path.join(alt_pdf_path, os.path.basename(pdf_path))\n",
    "            pdf_file = open(alternative_pdf_path, 'rb')\n",
    "            return 'Editorial board', '', '', ''\n",
    "        except FileNotFoundError:\n",
    "            # If PDF is not found in the original or alternative directory, return 'Editorial board'\n",
    "            return 'Editorial board', '', '', ''\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "\n",
    "\n",
    "def get_section_regex(article, section_patterns):\n",
    "    \"\"\"This function extracts text sections from articles based on provided regex patterns.\n",
    "\n",
    "    Parameters:\n",
    "    :param article (str): The text of the article.\n",
    "    :param section_patterns (list of tuple): A list of tuples containing start and end regex patterns.\n",
    "\n",
    "    Returns:\n",
    "    :returns tuple: A tuple containing the extracted section text, the matched start pattern, and the matched end pattern.\n",
    "               If no section is found, it returns ('', '', '').\n",
    "    \"\"\"\n",
    "    matched_pattern = None  # Variable to store the matched start pattern\n",
    "    start_match = None      # Variable to store the specific matched start pattern\n",
    "    end_match = None        # Variable to store the specific matched end pattern\n",
    "    \n",
    "    # Iterate through each pattern pair\n",
    "    for start_pattern, end_pattern in section_patterns:\n",
    "        # Find all matches of the start pattern in the article\n",
    "        start_matches = re.finditer(start_pattern, article)\n",
    "\n",
    "        # Iterate through each start match\n",
    "        for match in start_matches:\n",
    "            start_idx = match.start()  # Get the start position of the start match\n",
    "\n",
    "            # Search for the end pattern starting from the end position of the start match\n",
    "            end_match = re.search(end_pattern, article[start_idx:])\n",
    "            \n",
    "            if end_match:\n",
    "                end_idx = start_idx + end_match.start()  # Calculate the end position of the section\n",
    "                section_text = article[start_idx:end_idx].strip()  # Extract the section text\n",
    "\n",
    "                # Store the matched start and end patterns\n",
    "                matched_pattern = start_pattern\n",
    "                start_match = match\n",
    "                end_match = end_match\n",
    "\n",
    "                # Return the section text and matched patterns\n",
    "                return section_text, matched_pattern, start_match, end_match\n",
    "\n",
    "    # If no match is found, return an empty string and the last matched patterns\n",
    "    return '', '', '', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "075aca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_patterns_regex = [\n",
    "    (r'(?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availability |(?<![\\'\"]) \\s*?\\n?Data\\s+availability |(?<![\\'\"]) \\s*?\\n?Data/code\\s+availability', r'\\s*?\\n\\n |\\s*?\\n?3\\. | \\s*?\\n?CRediT\\s+authorship\\s+contribution\\s+statement(?:s)? | \\s*?\\n?Acknowledgement(?:s)? | \\s*?\\n?Acknowledgment(?:s)? | \\s*?\\n?Reference(?:s)? | \\s*?\\n?Declaration\\s+of\\s+Competing\\s+Interest(?:s)? | \\s*?\\n?Credit\\s+authorship\\s+contribution\\s+statement(?:s)? | \\s*?\\n?Funding | \\s*?\\n?Supplementary\\s+materials | \\s*?\\n?Ethic(?:s)? statement(?:s)?'),\n",
    "    (r'\\n?2\\. | \\n?2\\.1\\.', r'\\s*?\\n?3\\.\\s*?\\n?'),\n",
    "    # (r'\\n?Resource | \\n?3\\.1\\.\\s*?\\n?', r'\\n?3\\.2.\\s*?| \\s*?\\n\\n '),\n",
    "    (r'\\n?Introduction\\s*?\\n? | \\s*?\\n?1\\.\\s*?\\n? ', r'\\s*?\\n?2\\.\\s*?\\n? | \\s*?\\n\\n '),\n",
    "    (r'\\n?Abstract\\s*?\\n? | \\s*?\\n?1\\.\\s*?\\n? ', r'\\n?Introduction\\s*?\\n? | \\s*?\\n\\n '),\n",
    "    (r'\\n?Fig\\.\\d+ | \\n?Fig\\.\\d+\\.? | \\n?Figure \\d+', r'https?://[^\\s]+ | \\s*?\\n\\n '),\n",
    "    (r'\\n?Tab\\.\\d+ | \\n?Table \\d+\\.?', r'https?://[^\\s]+ | [\\w\\s-]+\\d{4} | \\s*?\\n\\n ')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e7f81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store individual results\n",
    "results_list_regex = []\n",
    "\n",
    "# Read DOI values from the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    doi_data = json.load(json_file)\n",
    "\n",
    "    # Get the first X DOIs\n",
    "    first_dois = doi_data['DOIs'][11:21] # 0:11 to compare with results_df, 11:21 to compare with results_df2\n",
    "\n",
    "    for doi in first_dois:\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(pdf_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content function for each DOI\n",
    "        section_content_regex, matched_pattern, start_match, end_match = get_content_regex(pdf_path, alternative_pdf_directory, section_patterns_regex)\n",
    "\n",
    "        # Create a dictionary for each result and add it to the list\n",
    "        results_list_regex.append({\"DOI\": doi, \"Section\": section_content_regex, \"Matched_pattern\": matched_pattern, \"Start_pattern\": start_match, \"End_pattern\": end_match})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df_regex = pd.DataFrame(results_list_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac93db",
   "metadata": {},
   "source": [
    "results_df: 0-10, i.e., [0:11]\n",
    "\n",
    "results_df2: 11-20, i.e., [11:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d88753dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data availability  \\nThe Matlab code for the proposed  vein segmentation  algorithm  \\nis available  on github: https://github.com/SinaStraub/GRE  _ vessel _ \\nseg.git and example  data on Zenodo.org:  https://doi.org/10.  \\n5281/zenodo.5791233  \\nThe used data can be shared with other researchers  upon reasonable  \\nrequest.  \\nSupplementary  materials  \\nSupplementary  material  associated  with this article can be found, in \\nthe online version,  at doi:10.1016/j.neuroimage.2022.118931  . \\nAppendices  \\nAll equations  are to be understood  voxel-wise,  however,  spatial co- \\nordinates  are omitted  when possible.  \\nA. True susceptibility-weighted  images \\nIn contrast  to susceptibility-weighted  data, true susceptibility-  \\nweighted  images (tSWI) are generated  using susceptibility  masks 𝑊 in- \\nstead of phase masks ( Liu et al., 2014 ), \\n𝑡𝑆𝑊 𝐼 = 𝑚𝑎𝑔 ⋅𝑊 𝑛 , where 𝑊 = ⎧ \\n⎪ \\n⎨ \\n⎪ ⎩ 1 , 𝑓𝑜𝑟 𝜒≤ 𝜒1 , \\n1 − 𝜒− 𝜒1 \\n𝜒2 − 𝜒1 , 𝑓𝑜𝑟 𝜒1 < 𝜒≤ 𝜒2 , \\n0 , 𝑓𝑜𝑟 𝜒> χ2 , (A.1) \\nwhere [ 𝜒1 , 𝜒2 ] deﬁnes the range of susceptibility  values for which the \\ncontrast  will be improved.  tSWI has been shown to provide  a better \\nvisualization  of the venous vasculature,  especially  for data at isotropic  \\nresolution.  \\nB. Background  suppression  and suppression  of ﬁeld inhomogeneity  artifacts  \\nJin et al. proposed  an inverted  two-dimensional  Hamming  ﬁlter ap- \\nproach to enhance  venous vasculature  through  background  suppression  \\n( Jin et al., 2014 ). In the presented  study, a three-dimensional  ﬁlter with \\nﬁlter size 2H x , 2H y and 2H z is used. The inverted  Hamming  ﬁlter 𝑖𝐻\\n𝑖𝐻 (𝑛 𝑥 , 𝑛 𝑦 , 𝑛 𝑧 )\\n= ⎧ \\n⎪ \\n⎨ \\n⎪ ⎩ 0 . 6 [ \\n1 . 0 − cos ( \\n𝜋√ \\n𝑛 2 𝑥 \\n𝐻 2 𝑥 + 𝑛 2 𝑦 \\n𝐻 2 𝑦 + 𝑛 2 𝑧 \\n𝐻 2 𝑧 ) ] \\n, 𝑓𝑜𝑟 𝑛 2 \\n𝑥 \\n𝐻 2 𝑥 + 𝑛 2 \\n𝑦 \\n𝐻 2 𝑦 + 𝑛 2 \\n𝑧 \\n𝐻 2 𝑧 ≤ 1 , \\n1 . 0 , 𝑒𝑙𝑠𝑒. \\n(B.1) \\ncan be applied  by a simple point-wise  multiplication  in the Fourier  do- \\nmain. Moreover,  due to its sensitivity  to non-local  ﬁeld inhomogeneities,  \\ngradient  echo data, often inherit severe signal drop-outs  in magnitude  \\ndata and excess gradients  in phase images,  especially  bilaterally  in the \\ntemporo-basal  region and the medial fronto-basal  region. In vesselness  \\nfunctions,  this can lead to vessel-like  artifacts.  Therefore,  it has been \\nproposed  to regularize  the vesselness  function  to reduce these artifacts  \\n( Monti et al., 2017 ). According  to Monti et al., a regularization  func- \\ntion 𝑟𝑒𝑔with values between  0 and 1, which is close to zero where the \\nprobability  for vessel like-artifacts  is high, can be computed  from the \\ndiﬀerence  Δbetween  the unwrapped  phase image and the local phase \\nimage (see also Section  3.2 Data Processing)  as \\n𝑟𝑒𝑔 = ⎧ \\n⎪ \\n⎨ \\n⎪ ⎩ 𝑝 𝑚𝑎𝑥 − |̃Δ|\\n𝑝 𝑚𝑎𝑥 − 𝑝 𝑚𝑖𝑛 , 𝑝 𝑚𝑖𝑛 ≤ ||̃Δ||≤ 𝑝 𝑚𝑎𝑥 \\n1 , ||̃Δ||< 𝑝 𝑚𝑖𝑛 \\n0 , 𝑒𝑙𝑠𝑒 (B.2) \\n9  S. Straub, J. Stiegeler, E. El-Sanosy  et al. NeuroImage  250 (2022) 118931 \\nwhere ̃Δis the extension  of Δafter erosion  using the local mean values, \\n𝑝 𝑚𝑎𝑥 and 𝑝 𝑚𝑖𝑛 are the 99.7th and 88th percentiles  of |̃Δ|. \\nC. The shearlet  transform  and shearlet  denoising  \\nThe shearlet  transform  \\ue23f\\ue234( Kutyniok  et al., 2016 ) is a multiscale  \\ntransform  and a natural  extension  of the wavelet  transform.  It is based \\non parabolic  scaling,  shearing  and translation  applied  to a few gener- \\nating functions  and allows therefore  for an eﬃcient  representation  of \\nanisotropic  features  in images ( Guo and Labate,  2007 ) \\nMathematically,  the discrete  shearlet  transform  of a function  𝑓 ∈\\n𝐿 2 ( ℝ 3 ) associated  to the pyramid-adapted  shearlet  system \\n𝑆𝐻 (\\n𝜙, 𝜓, ̃𝜓 , ⌣ 𝜓 ; 𝑐 )\\n= Φ(𝜙; 𝑐 1 )∪Ψ( 𝜓; 𝑐 ) ∪̃Ψ( ̃𝜓 ; 𝑐 ) ∪⌣ 𝜓 (⌣ 𝜓 ; 𝑐 )\\n, \\nwith \\nΦ(𝜙, 𝑐 1 )= { 𝜙𝑚 = 𝜙( ⋅− 𝑚 ) ∶ 𝑚 ∈𝑐 1 ℤ 3 } , \\nΨ( 𝜓, 𝑐 ) = { \\n𝜓 𝑗,𝑘,𝑚 = 2 𝑗 𝜓 (𝑆 𝑘 𝐴 2 𝑗 ⋅− 𝑚 )∶ 𝑗 ≥ 0 , |𝑘 |≤ 2 𝑗 \\n2 , 𝑚 ∈𝑀 𝑐 ℤ 3 } \\n, \\ñΨ( ̃𝜓 , 𝑐 ) = { \\ñ𝜓 𝑗,𝑘,𝑚 = 2 𝑗 ̃𝜓 (̃𝑆 𝑘 ̃𝐴 2 𝑗 ⋅− 𝑚 )∶ 𝑗 ≥ 0 , |𝑘 |≤ 2 𝑗 \\n2 , 𝑚 ∈̃𝑀 𝑐 ℤ 3 } \\n, \\n⌣ \\nΨ( ⌣ \\nΨ, 𝑐 ) \\n= { ⌣ \\nΨ𝑗,𝑘,𝑚 = 2 𝑗 ⌣ \\nΨ( ⌣ \\n𝑆 𝑘 ⌣ \\n𝐴 2 𝑗 ⋅− 𝑚 ) \\n∶ 𝑗 ≥ 0 , |𝑘 |≤ 2 𝑗 \\n2 , 𝑚 ∈⌣ \\n𝑀 𝑐 ℤ 3 } \\n, \\n𝐴, ̃𝐴 , ⌣ \\n𝐴 parabolic  scaling matrices,  𝑆 𝑘 , ̃𝑆 𝑘 , ⌣ \\n𝑆 𝑘 shearing  matrices,  \\n𝜙, 𝜓, ̃𝜓 , ⌣ 𝜓 ∈𝐿 2 ( ℝ 3 ) the scaling function  and the shearlet  generators,  \\n𝑗 ∈ℕ 0 , 𝑐 = ( 𝑐 1 , 𝑐 2 ) ∈ℝ 2 \\n+ , 𝑘 ∈ℤ 2 is deﬁned  as \\n𝑆 𝐻 𝜙,𝜓, ̃𝜓 , ⌣ 𝜓 𝑓 ( \\n𝑚 ′, ( 𝑗, 𝑘, 𝑚 ) , (̃𝑗 , ̃𝑘 , ̃𝑚 ), ( ⌣ \\n𝑗 , ⌣ \\n𝑘 , ⌣ 𝑚 ) ) \\n= ( \\n⟨𝑓, 𝜙𝑚 ′⟩, ⟨𝑓, 𝜓 𝑗,𝑘,𝑚 ⟩, ⟨𝑓, ̃𝜓 ̃𝑗 , ̃𝑘 , ̃𝑚 ⟩, ⟨ \\n𝑓, ⌣ 𝜓 ⌣ \\n𝑗 , ⌣ \\n𝑘 , ⌣ 𝑚 ⟩ ) \\n, \\nwhere ( 𝑚 ′, ( 𝑗, 𝑘, 𝑚 ) , ( ̃𝑗 , ̃𝑘 , ̃𝑚 ) , ( ⌣ \\n𝑗 , ⌣ \\n𝑘 , ⌣ 𝑚 ) ) ∈ℤ 3 ×Λ×Λ×Λ , and Λ= ℕ 0 ×\\n{ − ⌈2 𝑗( 𝛼𝑗 −1 ) \\n2 ⌉, …, ⌈2 𝑗( 𝛼𝑗 −1 ) \\n2 ⌉} 2 ×ℤ 3 . \\nUsing the shearlet  transform,  a denoised  image 𝐼 𝑑𝑒𝑛𝑜𝑖𝑠𝑒𝑑 can be cal- \\nculated  ( Kutyniok  et al., 2016 ) \\n𝐼 𝑑𝑒𝑛𝑜𝑖𝑠𝑒𝑑 = \\ue23f \\ue234 −1 𝑇 𝛿\\ue23f\\ue234 𝐼 𝑛𝑜𝑖𝑠𝑦, \\nusing a hard thresholding  operator  𝑇 𝛿𝐼 = { 𝐼, 𝑓𝑜𝑟 𝐼 ≥ 𝛿𝑗 = 𝐾 𝑗 𝜎\\n0 , 𝑒𝑙𝑠𝑒. (assum-  \\ning 𝐼 𝑛𝑜𝑖𝑠𝑦 = 𝐼 + 𝑛 , and 𝑛 ∼\\ue23a ( 0 , 𝜎2 ) , and 𝐾 𝑗 a thresholding  factor for each \\nscale). \\nIn this study, the implementation  of the digital shearlet  transform  in \\nShearLab3D  ( Kutyniok  et al., 2016 ) was used. The decomposition  and \\nreconstruction  of the data can be calculated  at once or in a serial manner  \\nto avoid high RAM usage. Then, only the coeﬃcients  of the translations  \\nof one single shearlet  (with ﬁxed scale and shear level) are stored at one \\npoint in time ( Kutyniok  et al., 2016 ). \\nD. Vesselness  ﬁlters \\nFor the purpose  of vessel segmentation  algorithms,  multiscale  vessel \\nenhancement  ﬁlters are a commonly  used preprocessing  technique.  A \\npopular  example  is Frangi’s  ﬁlter ( Frangi et al., 1998 ) which computes  \\nthe likelihood  of a voxel to belong to a vessel. A scale space represen-  \\ntation from the imaging  data 𝐼, on which vessels are segmented  is gen- \\nerated by ﬁltering  𝐼with Gaussian  kernels  with diﬀerent  standard  de- \\nviations  𝜎according  to diﬀerent  vessel diameters.  Inspired  by Frangi’s  \\nvesselness  ﬁlter, enhancement  ﬁlters have been proposed  such as the \\nvesselness  fractional  anisotropy  tensor ( Alhasson  et al., 2018 ; Cui et al., \\n2019 ; Jerman  et al., 2015 ; Prados et al., 2010 ) that yields a close-to-  \\nuniform  response  in all vascular  structures  and enhances  the border be- \\ntween vascular  structures  and the background.  D.1. . Frangi’s  vesselness  ﬁlter \\nThe eigenvalues  of the Hessian  matrix 𝐻 𝜎of the Gaussian  scale space \\nrepresentations  are calculated,  and ordered  by the size of their absolute  \\nvalue |𝜆𝜎, 1 |≤ |𝜆𝜎, 2 |≤ |𝜆𝜎, 3 |. If vessels are represented  as dark struc- \\ntures in 𝐼, Frangi’s  vesselsness  is calculated  as: \\n\\ue242 𝐹 \\n𝜎( 𝐼 ) = { 0 , 𝑓𝑜𝑟 𝜆𝜎, 2 < 0 ∨𝜆𝜎, 3 < 0 , ( \\n1 − 𝑒 − 𝐴 2 𝜎\\n2 𝛼2 ) \\n𝑒 − 𝐵 2 𝜎\\n2 𝛽2 ⎛ \\n⎜ \\n⎜ ⎝ 1 − 𝑒 − 𝑆 2 𝜎\\n2 𝛾2 𝜎⎞ \\n⎟ \\n⎟ ⎠ , 𝑒𝑙𝑠𝑒, \\nand otherwise:  \\n\\ue242 𝐹 \\n𝜎( 𝐼 ) = { 0 , 𝑓𝑜𝑟 𝜆𝜎, 2 > 0 ∨𝜆𝜎, 3 > 0 , ( \\n1 − 𝑒 − 𝐴 2 𝜎\\n2 𝛼2 ) \\n𝑒 − 𝐵 2 𝜎\\n2 𝛽2 ⎛ \\n⎜ \\n⎜ ⎝ 1 − 𝑒 − 𝑆 2 𝜎\\n2 𝛾2 𝜎⎞ \\n⎟ \\n⎟ ⎠ , 𝑒𝑙𝑠𝑒, \\nwhere 𝐴 𝜎= |𝜆𝜎, 2 |\\n|𝜆𝜎, 3 |, 𝐵 𝜎= |𝜆𝜎, 1 |√𝜆𝜎, 2 𝜆𝜎, 3 , and 𝑆 𝜎= √ \\n𝜆2 \\n𝜎, 1 + 𝜆2 \\n𝜎, 2 + 𝜆2 \\n𝜎, 3 and \\n𝛼, 𝛽, 𝛾tuning parameters.  The ﬁnal vesselness  function  is computed  \\nas the maximum  across the scales 𝜎. \\nD.2. Vesselness  fractional  anisotropy  tensor \\nIf vessels are represented  as dark structures  in 𝐼, it is deﬁned  as \\nfollows:  \\n\\ue242 𝐹𝐴𝑇 \\n𝜎,𝜆( 𝐼 ) = √ \\n3 \\n2 √ √ √ √ √ (𝜆𝜎, 2 − 𝐷 𝜎,𝜆)2 + (𝜆𝜎,𝑝 − 𝐷 𝜎, 𝜆)2 + (𝜆𝜎,𝜈− 𝐷 𝜎, 𝜆)2 \\n𝜆2 \\n𝜎, 2 + 𝜆2 \\n𝜎,𝑝 + 𝜆2 \\n𝜎,𝜈\\nwhere 𝐷 𝜎, 𝜆= ∑3 \\n𝑖 =1 𝜆𝜎, 𝑖 \\n3 , 𝜆𝜎,𝜌,𝜈= ⎧ \\n⎪ \\n⎪ \\n⎪ \\n⎨ \\n⎪ \\n⎪ \\n⎪ ⎩ 𝜆𝜎, 3 , 𝑓𝑜𝑟 𝜆𝜎, 3 > 𝜏𝜎,𝑝,𝜈max \\n𝐼 𝜆𝜎, 3 , \\n𝜏𝜎,𝑝,𝜈max \\n𝐼 𝜆𝜎, 3 , 𝑓𝑜𝑟 0 < 𝜆𝜎, 3 \\n≤ 𝜏𝜎,𝑝,𝜈max \\n𝐼 𝜆𝜎, 3 , \\n0 , 𝑒𝑙𝑠𝑒 and \\n𝜏𝜎,𝑝 , 𝜏𝜎,𝜈∈[ 0 , 1 ] . \\nThe ﬁnal enhancement  function  is computed  as \\n\\ue242 𝜎, 𝜆,𝑝 𝑀𝐹𝐴𝑇 ( 𝐼 ) = \\ue242 𝜎−1 , 𝜆,𝑝 𝑀𝐹𝐴𝑇 ( 𝐼 ) + 𝛿tanh (𝑅 𝜎,𝜆, 𝑝 ( 𝐼 ) − 𝛿)\\n\\ue242 𝜆,𝑝 𝑀𝐹𝐴𝑇 ( 𝐼 ) = max 𝜎(\\ue242 𝜎,𝜆,𝑝 𝑀𝐹𝐴𝑇 ( 𝐼 ) , 𝑅 𝜎,𝜆, 𝑝 ( 𝐼 ) ) (D.2.1) \\nwhere \\n𝑅 𝜎,𝜆,𝑝 ( 𝐼 ) = ⎧ \\n⎪ \\n⎨ \\n⎪ ⎩ 0 , 𝑓𝑜𝑟 𝜆𝜎,𝑝 > 𝜆𝜎,𝑝 − 𝜆𝜎, 2 ∨𝜆𝜎,𝑝 ≥ 0 ∨𝜆𝜎, 2 ≥ 0 , \\n1 , 𝑓𝑜𝑟 𝜆𝜎,𝑝 − 𝜆𝜎, 2 = max \\n𝐼 (𝜆𝜎,𝑝 − 𝜆𝜎, 2 ), \\n1 − \\ue242 𝜎, 𝜆𝐹𝐴𝑇 , 𝑒𝑙𝑠𝑒, \\nand 𝛿is the step size for the calculation  of the solution.  The output is \\na probability  map, i.e. each voxel has values between  0 and 1 which is \\nthe probability  for being a vein voxel. \\nReferences  \\nAlhasson,  H.F. , Alharbi, S.S. , Obara, B. , 2018. 2D and 3D Vascular Structures  Enhancement  \\nVia Multiscale  Fractional  Anisotropy  tensor. Springer,  Munich, Germany  European  \\nConference  On Computer  Vision . \\nAshburner,  J. , Friston, K.J. , 2005. Uniﬁed segmentation.  Neuroimage  26, 839–851 . \\nBazin, P. , Plessis, V. , Fan, A.P. , Villringer,  A. , Gauthier,  C.J. , 2016. Vessel segmenta-  \\ntion from quantitative  susceptibility  maps for local oxygenation  venography.  In: Pro- \\nceedings of the IEEE 13th International  Symposium  on Biomedical  Imaging (ISBI), \\npp. 1135–1138  . \\nBeriault, S. , Xiao, Y.M. , Collins, D.L. , Pike, G.B. , 2015. Automatic  SWI venography  seg- \\nmentation  using conditional  random ﬁelds. IEEE Trans. Med. Imaging 34, 2478–2491  . \\nCui, H.F. , Xia, Y. , Zhang, Y.N. , 2019. 2D and 3D vascular structures  enhancement  \\nvia improved  vesselness  ﬁlter and vessel enhancing  diﬀusion.  IEEE Access 7, \\n123969–123980  . \\nDeistung,  A. , Dittrich, E. , Sedlacik,  J. , Rauscher,  A. , Reichenbach,  J.R. , 2009. ToF-SWI:  \\nsimultaneous  time of ﬂight and fully ﬂow compensated  susceptibility  weighted  imag- \\ning. J. Magn. Reson. Imaging 29, 1478–1484  . \\nDerdeyn,  C.P. , Videen, T.O. , Grubb, R.L. , Powers, W.J. , 2001. Comparison  of PET oxy- \\ngen extraction  fraction methods for the prediction  of stroke risk. J. Nucl. Med. 42, \\n1195–1197  . \\n10  S. Straub, J. Stiegeler, E. El-Sanosy  et al. NeuroImage  250 (2022) 118931 \\nDubuisson,  M. , Jain, A.K. , 1994. A modiﬁed  Hausdorﬀdistance  for object matching.  In: \\nProceedings  of 12th International  Conference  on Pattern Recognition,  1, Jerusalem,  \\nIsrael, pp. 566–568 . \\nDuyn, J.H. , Schenck, J. , 2017. Contributions  to magnetic  susceptibility  of brain tissue. \\nNMR Biomed. 30 . \\nEckstein,  K. , Bachrata,  B. , Hangel, G. , Widhalm,  G. , Enzinger,  C. , Barth, M. , Trattnig, S. , \\nRobinson,  S.D. , 2021. Improved  susceptibility  weighted  imaging at ultra-high  ﬁeld \\nusing bipolar multi-echo  acquisition  and optimized  image processing:  CLEAR-SWI.  \\nNeuroimage  237 . \\nEckstein,  K. , Dymerska,  B. , Bachrata,  B. , Bogner, W. , Poljanc, K. , Trattnig, S. , Robin- \\nson, S.D. , 2018. Computationally  eﬃcient combination  of multi-channel  phase data \\nfrom multi-echo  acquisitions  (ASPIRE).  Magn. Reson. Med. 79, 2996–3006  . \\nFischl, B. , 2012. FreeSurfer.  Neuroimage  62, 774–781 . \\nFrangi, A.F. , Niessen, W.J. , Vincken, K.L. , Viergever,  M.A. , 1998. Multiscale  vessel en- \\nhancement  ﬁltering. In: Proceedings  of the Medical Image Computing  and Comput- \\ner-Assisted  Intervention  - MICCAI’98,  1496, pp. 130–137 . \\nFu, W., Breininger,  K., Würﬂ, T., Ravikumar,  N., Schaﬀert,  R., Maier, A.K.J.A., 2017. \\nFrangi-net:  a neural network approach  to vessel segmentation.  abs/1711.03345.  \\nGe, Y.L. , Zohrabian,  V.M. , Osa, E.O. , Xu, J. , Jaggi, H. , Herbert, J. , Haacke, E.M. , Gross- \\nman, R.I. , 2009. Diminished  visibility of cerebral venous vasculature  in multiple scle- \\nrosis by susceptibility-weighted  imaging at 3.0 Tesla. J. Magn. Reson. Imaging 29, \\n1190–1194  . \\nGuo, K. , Labate, D. , 2007. Optimally  sparse multidimensional  representation  using shear- \\nlets. SIAM J. Math. Anal. 39, 298–318 . \\nGuo, Y.H. , Budak, U. , Sengur, A. , Smarandache,  F. , 2017. A retinal vessel detection  ap- \\nproach based on shearlet transform  and indeterminacy  ﬁltering on fundus images. \\nSymmetry  9 Basel . \\nGupta, A. , Baradaran,  H. , Schweitzer,  A.D. , Kamel, H. , Pandya, A. , Delgado, D. , Wright, D. , \\nHurtado-Rua,  S. , Wang, Y. , Sanelli, P.C. , 2014. Oxygen extraction  fraction and stroke \\nrisk in patients with carotid stenosis or occlusion:  a systematic  review and meta-anal-  \\nysis. AJNR Am. J. Neuroradiol.  35, 250–255 . \\nHaacke, E.M. , Liu, S. , Buch, S. , Zheng, W. , Wu, D. , Ye, Y. , 2015. Quantitative  susceptibility  \\nmapping:  current status and future directions.  Magn. Reson. Imaging 33, 1–25 . \\nHaacke, E.M. , Tang, J. , Neelavalli,  J. , Cheng, Y.C.N. , 2010. Susceptibility  mapping as a \\nmeans to visualize veins and quantify oxygen saturation.  J. Magn. Reson. Imaging 32, \\n663–676 . \\nHuntenburg,  J.M. , Steele, C.J. , Bazin, P.L. , 2018. Nighres: processing  tools for high-reso-  \\nlution neuroimaging.  Gigascience  7 . \\nHyder, F. , Rothman,  D.L. , Bennett, M.R. , 2013. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2['Section'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "182516bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data availability  \\nThe Matlab code for the proposed  vein segmentation  algorithm  \\nis available  on github: https://github.com/SinaStraub/GRE  _ vessel _ \\nseg.git and example  data on Zenodo.org:  https://doi.org/10.  \\n5281/zenodo.5791233  \\nThe used data can be shared with other researchers  upon reasonable  \\nrequest.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_regex['Section'].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05023e",
   "metadata": {},
   "source": [
    "**Fixed issues**: \n",
    "- Edited get_content_regex function to be case sensitive instead of insensitive \n",
    "    - When searching using all lowercase, results_df2['Section'].loc[2], this is cut short\n",
    "        - From 'Data and code availability  statement  \\nData used in the study are available  upon direct request.  Conditions  \\nfor its sharing  involve  the formalisation  of a research  agreement.  The \\ndata and code sharing  adopted  by the authors  comply  with the require-  \\nments of the funding  body or institute,  and with the institutional  ethics \\napproval.  Parts of the data are conﬁdential  and additional  ethical ap- \\nproval may be needed  for re-use. \\n'\n",
    "        - To: 'Data and code availability  statement  \\nData used in the study are available  upon direct request.  Conditions  \\nfor its sharing  involve  the formalisation  of a research  agreement.  The \\ndata and code sharing  adopted  by the authors  comply  with the require-  \\nments of the'\n",
    "        \n",
    "**Persisting issues**: \n",
    "- Reading the PDF \n",
    "    - By page-shift, the header is picked up (results_df_regex['Section'].loc[6], DOI  10.1016/j.neuroimage.2022.118986)\n",
    "    - Double (or more) spaces\n",
    "    - \\n characters \n",
    "- Section titles \n",
    "    - There are variations of section_start titles that I have not included in my pattern, e.g., \"Data Availability\", which I discovered in articles_groundtruth\n",
    "    - There are infinitely many undiscovered section_end titles, that I have not included in my pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09c69b",
   "metadata": {},
   "source": [
    "NB! THIS TAKES MORE THAN AN HOUR TO RUN!\n",
    "started at 16.09 - saw it was done at 18.15 - but checked at 17:40+, where it hadn't finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f030f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store individual results\n",
    "results = []\n",
    "\n",
    "# Read DOI values from the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    doi_data = json.load(json_file)\n",
    "\n",
    "    for doi in doi_data['DOIs']:\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(pdf_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content_regex function for each DOI \n",
    "        section_content_regex, matched_pattern, start_match, end_match = get_content_regex(pdf_path, alternative_pdf_directory, section_patterns_regex)\n",
    "\n",
    "        # Create a dictionary for each result and add it to the list\n",
    "        results.append({\"DOI\": doi, \"Section\": section_content_regex, \"Matched_pattern\": matched_pattern, \"Start_pattern\": start_match, \"End_pattern\": end_match})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "articles_dataset_sections = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd72858",
   "metadata": {},
   "source": [
    "NB! The code above takes between one and two hours to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91be971d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# articles_dataset_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1039d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the 'Code-git/Data' directory\n",
    "data_dir = os.path.join(os.pardir, 'Data')\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(data_dir, 'articles_dataset_sections.csv')\n",
    "\n",
    "# Save the DataFrame to CSV, overwriting the file if it exists\n",
    "articles_dataset_sections.to_csv(file_path, index=False, mode='w')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964f11d",
   "metadata": {},
   "source": [
    "<a name='preprocessingtextsections'></a>\n",
    "## 1.2. Preprocessing text sections\n",
    "Before I continue to the extraction of the datasets from the text sections, I want to clean the current data a bit. This includes: \n",
    "- Clean the matching start patterns \n",
    "- Clean the extracted text sections, including \n",
    "    - Remove characters like '\\n' \n",
    "    - Remove double (or more) spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078c06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file\n",
    "csv_file_path = os.path.join(os.pardir, 'Data/articles_dataset_sections.csv') \n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "articles_dataset_sections = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f581f97d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "      <th>Matched_pattern</th>\n",
       "      <th>Start_pattern</th>\n",
       "      <th>End_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119451</td>\n",
       "      <td>Data and code availability  statements  \\nSpec...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(25302, 25330), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(705, 709), match=' 3. '&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119632</td>\n",
       "      <td>Data and code availability  \\nThe data incorpo...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(39700, 39730), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(689, 727), match=' \\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119584</td>\n",
       "      <td>Data/code  availability  statement  \\nData and...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(26185, 26209), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(80, 86), match='  \\n3. '&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119550</td>\n",
       "      <td>Data and code availability  \\nAll data used in...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(104602, 104632), match...</td>\n",
       "      <td>&lt;re.Match object; span=(479, 518), match='  \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119710</td>\n",
       "      <td>Data and code availability  statement  \\nAll i...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(70621, 70650), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(596, 641), match=' \\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118922</td>\n",
       "      <td>Data and code availability  statement  \\nThe b...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(48329, 48358), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(328, 373), match=' \\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119713</td>\n",
       "      <td>Data availability  \\nROI time series, along wi...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(58431, 58452), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(468, 507), match='  \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119688</td>\n",
       "      <td>2. \\n1053-8119/©2022  The Authors.  Published ...</td>\n",
       "      <td>\\n?2\\. | \\n?2\\.1\\.</td>\n",
       "      <td>&lt;re.Match object; span=(5336, 5339), match='2. '&gt;</td>\n",
       "      <td>&lt;re.Match object; span=(6586, 6588), match='3.'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118939</td>\n",
       "      <td>Data and code availability  \\nDe-identiﬁed  da...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(50360, 50390), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(125, 152), match=' \\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119149</td>\n",
       "      <td>2. \\n1053-8119/©2022  The Authors.  Published ...</td>\n",
       "      <td>\\n?2\\. | \\n?2\\.1\\.</td>\n",
       "      <td>&lt;re.Match object; span=(4755, 4758), match='2. '&gt;</td>\n",
       "      <td>&lt;re.Match object; span=(7533, 7535), match='3.'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DOI  \\\n",
       "0    10.1016/j.neuroimage.2022.119451   \n",
       "1    10.1016/j.neuroimage.2022.119632   \n",
       "2    10.1016/j.neuroimage.2022.119584   \n",
       "3    10.1016/j.neuroimage.2022.119550   \n",
       "4    10.1016/j.neuroimage.2022.119710   \n",
       "..                                ...   \n",
       "829  10.1016/j.neuroimage.2022.118922   \n",
       "830  10.1016/j.neuroimage.2022.119713   \n",
       "831  10.1016/j.neuroimage.2022.119688   \n",
       "832  10.1016/j.neuroimage.2022.118939   \n",
       "833  10.1016/j.neuroimage.2022.119149   \n",
       "\n",
       "                                               Section  \\\n",
       "0    Data and code availability  statements  \\nSpec...   \n",
       "1    Data and code availability  \\nThe data incorpo...   \n",
       "2    Data/code  availability  statement  \\nData and...   \n",
       "3    Data and code availability  \\nAll data used in...   \n",
       "4    Data and code availability  statement  \\nAll i...   \n",
       "..                                                 ...   \n",
       "829  Data and code availability  statement  \\nThe b...   \n",
       "830  Data availability  \\nROI time series, along wi...   \n",
       "831  2. \\n1053-8119/©2022  The Authors.  Published ...   \n",
       "832  Data and code availability  \\nDe-identiﬁed  da...   \n",
       "833  2. \\n1053-8119/©2022  The Authors.  Published ...   \n",
       "\n",
       "                                       Matched_pattern  \\\n",
       "0    (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "1    (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "2    (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "3    (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "4    (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "..                                                 ...   \n",
       "829  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "830  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "831                                 \\n?2\\. | \\n?2\\.1\\.   \n",
       "832  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "833                                 \\n?2\\. | \\n?2\\.1\\.   \n",
       "\n",
       "                                         Start_pattern  \\\n",
       "0    <re.Match object; span=(25302, 25330), match='...   \n",
       "1    <re.Match object; span=(39700, 39730), match='...   \n",
       "2    <re.Match object; span=(26185, 26209), match='...   \n",
       "3    <re.Match object; span=(104602, 104632), match...   \n",
       "4    <re.Match object; span=(70621, 70650), match='...   \n",
       "..                                                 ...   \n",
       "829  <re.Match object; span=(48329, 48358), match='...   \n",
       "830  <re.Match object; span=(58431, 58452), match='...   \n",
       "831  <re.Match object; span=(5336, 5339), match='2. '>   \n",
       "832  <re.Match object; span=(50360, 50390), match='...   \n",
       "833  <re.Match object; span=(4755, 4758), match='2. '>   \n",
       "\n",
       "                                           End_pattern  \n",
       "0     <re.Match object; span=(705, 709), match=' 3. '>  \n",
       "1    <re.Match object; span=(689, 727), match=' \\nD...  \n",
       "2    <re.Match object; span=(80, 86), match='  \\n3. '>  \n",
       "3    <re.Match object; span=(479, 518), match='  \\n...  \n",
       "4    <re.Match object; span=(596, 641), match=' \\nC...  \n",
       "..                                                 ...  \n",
       "829  <re.Match object; span=(328, 373), match=' \\nC...  \n",
       "830  <re.Match object; span=(468, 507), match='  \\n...  \n",
       "831   <re.Match object; span=(6586, 6588), match='3.'>  \n",
       "832  <re.Match object; span=(125, 152), match=' \\nS...  \n",
       "833   <re.Match object; span=(7533, 7535), match='3.'>  \n",
       "\n",
       "[834 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dataset_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78d655",
   "metadata": {},
   "source": [
    "<a name='startpatterns'></a>\n",
    "### 1.2.1. Start patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e800d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matched_text(text):\n",
    "    \"\"\"This function extracts matched text from a string containing a regular expression \n",
    "    match object and performs data cleaning.\n",
    "\n",
    "    Parameters:\n",
    "    :param text (str): A string containing a regular expression match object (e.g., \"<re.Match object; span=(start, end), match='text'>\").\n",
    "\n",
    "    Returns:\n",
    "    :returns: If a match is found in the input text, the function returns the matched text after performing the following operations:\n",
    "        Stripping leading and trailing spaces from the matched text.\n",
    "        Replacing '\\n' (newline) characters with empty strings.\n",
    "    :returns: If no match is found or the resulting matched text is empty, the function returns NaN.\n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r\"match='(.*?)'\", str(text))\n",
    "    if match:\n",
    "        matched_text = match.group(1).strip().replace('\\\\n', '').replace('  ', ' ').replace('   ', ' ')\n",
    "        if matched_text:\n",
    "            return matched_text\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e298bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to clean up the 'Start_pattern' column\n",
    "articles_dataset_sections['Start_pattern_clean'] = articles_dataset_sections['Start_pattern'].apply(extract_matched_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f9f3f",
   "metadata": {},
   "source": [
    "Overview of how many articles matches each of the section patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c8a00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Matched_pattern  Count\n",
      "0  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...    563\n",
      "1                                 \\n?2\\. | \\n?2\\.1\\.    248\n",
      "2       \\n?Fig\\.\\d+ | \\n?Fig\\.\\d+\\.? | \\n?Figure \\d+      1\n",
      "3        \\n?Introduction\\s*?\\n? | \\s*?\\n?1\\.\\s*?\\n?       1\n",
      "4                                                NaN     21\n",
      "Total Count: 834\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Matched_pattern' and count the number of rows in each group\n",
    "pattern_counts = articles_dataset_sections['Matched_pattern'].value_counts()\n",
    "\n",
    "# Count NaN values and add it to the pattern_counts Series\n",
    "nan_count = articles_dataset_sections['Matched_pattern'].isna().sum()\n",
    "pattern_counts['NaN'] = nan_count\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "articles_section_patterns = pd.DataFrame({\n",
    "    'Matched_pattern': pattern_counts.index,\n",
    "    'Count': pattern_counts.values\n",
    "})\n",
    "\n",
    "# Print the result DataFrame\n",
    "print(articles_section_patterns)\n",
    "\n",
    "# Calculate and print the total count\n",
    "total_count = articles_section_patterns['Count'].sum()\n",
    "print(\"Total Count:\", total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c242a",
   "metadata": {},
   "source": [
    "I was only expecting to see 19 articles with NaN as a matched pattern (since there are 19 editorial board papers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "295e5dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter and display rows where 'Start_pattern_clean' is None\n",
    "no_pattern = articles_dataset_sections[articles_dataset_sections['Start_pattern_clean'].isna()]\n",
    "len(no_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2b9b5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "      <th>Matched_pattern</th>\n",
       "      <th>Start_pattern</th>\n",
       "      <th>End_pattern</th>\n",
       "      <th>Start_pattern_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DOI Section Matched_pattern Start_pattern  \\\n",
       "517  10.1016/j.neuroimage.2022.119154     NaN             NaN           NaN   \n",
       "670  10.1016/j.neuroimage.2022.118921     NaN             NaN           NaN   \n",
       "\n",
       "    End_pattern Start_pattern_clean  \n",
       "517         NaN                 NaN  \n",
       "670         NaN                 NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where 'Section' is not 'Editorial board'\n",
    "no_pattern[no_pattern['Section'] != 'Editorial board']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e19617",
   "metadata": {},
   "source": [
    "There should only be 19 articles where there is no pattern-match, as there are 19 'Editorial Board' articles. The articles that were not filtered properly by my code are: \n",
    "- 10.1016/j.neuroimage.2022.119560\n",
    "    - This has a section called 'Data Availability'\n",
    "- 10.1016/j.neuroimage.2021.118776\n",
    "    - This article does not have any distinct sections. It presents all the articles in the particular volume of Neuroimaging. \n",
    "- 10.1016/j.neuroimage.2022.119154\n",
    "    - This article does not have any distinct sections. It is a commentary.     \n",
    "- 10.1016/j.neuroimage.2022.118921\n",
    "    - This article does not have any distinct sections. It is a corrigendum. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Of the four articles that did not contain one of my start patterns, only one should have been picked up. The rest seems to have been properly filtered. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### 1.2.3. Clean text \n",
    "I will do a very simple initial cleaning of the extracted text sections: \n",
    "- Replace multiple spaces with a single space\n",
    "    - [.replace('   ', ' ').replace('  ', ' ')]\n",
    "- Remove all \\n characters \n",
    "    - [.replace('\\n', '')]\n",
    "- Remove leading and trailing spaces after the following characters: -, (, ), /, ., _ , and between : / \n",
    "    - [.replace('- ', '-').replace('( ', '(').replace(' )', ')').replace('/ ', '/').replace(' /', '/').replace(' .', '.').replace(': /', ':/').replace(' _ ', '_').replace(' _', '_').replace('_ ', '_')] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e66acab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Data and code availability  statements  \\nSpec...\n",
       "1      Data and code availability  \\nThe data incorpo...\n",
       "2      Data/code  availability  statement  \\nData and...\n",
       "3      Data and code availability  \\nAll data used in...\n",
       "4      Data and code availability  statement  \\nAll i...\n",
       "                             ...                        \n",
       "829    Data and code availability  statement  \\nThe b...\n",
       "830    Data availability  \\nROI time series, along wi...\n",
       "831    2. \\n1053-8119/©2022  The Authors.  Published ...\n",
       "832    Data and code availability  \\nDe-identiﬁed  da...\n",
       "833    2. \\n1053-8119/©2022  The Authors.  Published ...\n",
       "Name: Section, Length: 834, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dataset_sections['Section']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b1994f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(articles_dataset_sections['Section'])):\n",
    "    articles_dataset_sections['Section'].loc[i] = articles_dataset_sections['Section'].astype(str).loc[i].replace('   ', ' ').replace('  ', ' ').replace('\\n', '').replace('- ', '-').replace('( ', '(').replace(' )', ')').replace('/ ', '/').replace(' /', '/').replace(' .', '.').replace(': /', ':/').replace(' _ ', '_').replace(' _', '_').replace('_ ', '_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba9ed1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Data and code availability statements Speciﬁca...\n",
       "1      Data and code availability The data incorporat...\n",
       "2      Data/code availability statement Data and code...\n",
       "3      Data and code availability All data used in th...\n",
       "4      Data and code availability statement All indiv...\n",
       "                             ...                        \n",
       "829    Data and code availability statement The brain...\n",
       "830    Data availability ROI time series, along with ...\n",
       "831    2. 1053-8119/©2022 The Authors. Published by E...\n",
       "832    Data and code availability De-identiﬁed data a...\n",
       "833    2. 1053-8119/©2022 The Authors. Published by E...\n",
       "Name: Section, Length: 834, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dataset_sections['Section']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a0a54",
   "metadata": {},
   "source": [
    "# NB! PROBLEM WITH LINKS\n",
    "\n",
    "osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/ - BUT THE WORD 'AND' IS NOT A PART OF THE LINK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c96e6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = articles_dataset_sections[articles_dataset_sections['DOI'] == '10.1016/j.neuroimage.2022.119443']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea80214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data and code availability statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/. Code used to reproduce the plots in Fig. 1 , as well as averaged ERP data, is available from osf.io/guwnm/.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['Section'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31b647",
   "metadata": {},
   "source": [
    "Additionally, I want to remove the section titles from the text, as they can cause issues with the code I will be writing for extracting the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d20477f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Start_pattern_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data and code availability statements Speciﬁca...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data and code availability The data incorporat...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/code availability statement Data and code...</td>\n",
       "      <td>Data/code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data and code availability All data used in th...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data and code availability statement All indiv...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Data and code availability statement The brain...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Data availability ROI time series, along with ...</td>\n",
       "      <td>Data availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2. 1053-8119/©2022 The Authors. Published by E...</td>\n",
       "      <td>2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>Data and code availability De-identiﬁed data a...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2. 1053-8119/©2022 The Authors. Published by E...</td>\n",
       "      <td>2.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Section  \\\n",
       "0    Data and code availability statements Speciﬁca...   \n",
       "1    Data and code availability The data incorporat...   \n",
       "2    Data/code availability statement Data and code...   \n",
       "3    Data and code availability All data used in th...   \n",
       "4    Data and code availability statement All indiv...   \n",
       "..                                                 ...   \n",
       "829  Data and code availability statement The brain...   \n",
       "830  Data availability ROI time series, along with ...   \n",
       "831  2. 1053-8119/©2022 The Authors. Published by E...   \n",
       "832  Data and code availability De-identiﬁed data a...   \n",
       "833  2. 1053-8119/©2022 The Authors. Published by E...   \n",
       "\n",
       "            Start_pattern_clean  \n",
       "0    Data and code availability  \n",
       "1    Data and code availability  \n",
       "2        Data/code availability  \n",
       "3    Data and code availability  \n",
       "4    Data and code availability  \n",
       "..                          ...  \n",
       "829  Data and code availability  \n",
       "830           Data availability  \n",
       "831                          2.  \n",
       "832  Data and code availability  \n",
       "833                          2.  \n",
       "\n",
       "[834 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dataset_sections[['Section', 'Start_pattern_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03afa149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_starting_pattern(row):\n",
    "    \"\"\"This function removes the matching start_pattern text from the extracted section texts. \n",
    "    E.g., if the start pattern is 'Data and code availability', and the extracted section text \n",
    "    is 'Data and code availability The data incorporat...', the returned clean_text will be \n",
    "    'The data incorporat...'. \n",
    "    \"\"\"\n",
    "    section = row['Section']\n",
    "    start_pattern = str(row['Start_pattern_clean']) \n",
    "    section = section.replace(start_pattern, '')\n",
    "    \n",
    "    return section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a40bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row\n",
    "articles_dataset_sections['Section_wo_pattern'] = articles_dataset_sections.apply(remove_starting_pattern, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03c8d88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_pattern_clean</th>\n",
       "      <th>Section</th>\n",
       "      <th>Section_wo_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Data and code availability statements Speciﬁca...</td>\n",
       "      <td>statements Speciﬁcally, GES, PC and LiNGAM we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Data and code availability The data incorporat...</td>\n",
       "      <td>The data incorporated in the primary analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/code availability</td>\n",
       "      <td>Data/code availability statement Data and code...</td>\n",
       "      <td>statement Data and code are available upon re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Data and code availability All data used in th...</td>\n",
       "      <td>All data used in this project is from the Hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Data and code availability statement All indiv...</td>\n",
       "      <td>statement All individual-level raw data used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Data and code availability statement The brain...</td>\n",
       "      <td>statement The brain MR data was obtained from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Data availability</td>\n",
       "      <td>Data availability ROI time series, along with ...</td>\n",
       "      <td>ROI time series, along with the underlying MA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2.</td>\n",
       "      <td>2. 1053-8119/©2022 The Authors. Published by E...</td>\n",
       "      <td>1053-8119/©2022 The Authors. Published by Els...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Data and code availability De-identiﬁed data a...</td>\n",
       "      <td>De-identiﬁed data and custom-built MATLAB cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2.</td>\n",
       "      <td>2. 1053-8119/©2022 The Authors. Published by E...</td>\n",
       "      <td>1053-8119/©2022 The Authors. Published by Els...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Start_pattern_clean  \\\n",
       "0    Data and code availability   \n",
       "1    Data and code availability   \n",
       "2        Data/code availability   \n",
       "3    Data and code availability   \n",
       "4    Data and code availability   \n",
       "..                          ...   \n",
       "829  Data and code availability   \n",
       "830           Data availability   \n",
       "831                          2.   \n",
       "832  Data and code availability   \n",
       "833                          2.   \n",
       "\n",
       "                                               Section  \\\n",
       "0    Data and code availability statements Speciﬁca...   \n",
       "1    Data and code availability The data incorporat...   \n",
       "2    Data/code availability statement Data and code...   \n",
       "3    Data and code availability All data used in th...   \n",
       "4    Data and code availability statement All indiv...   \n",
       "..                                                 ...   \n",
       "829  Data and code availability statement The brain...   \n",
       "830  Data availability ROI time series, along with ...   \n",
       "831  2. 1053-8119/©2022 The Authors. Published by E...   \n",
       "832  Data and code availability De-identiﬁed data a...   \n",
       "833  2. 1053-8119/©2022 The Authors. Published by E...   \n",
       "\n",
       "                                    Section_wo_pattern  \n",
       "0     statements Speciﬁcally, GES, PC and LiNGAM we...  \n",
       "1     The data incorporated in the primary analysis...  \n",
       "2     statement Data and code are available upon re...  \n",
       "3     All data used in this project is from the Hum...  \n",
       "4     statement All individual-level raw data used ...  \n",
       "..                                                 ...  \n",
       "829   statement The brain MR data was obtained from...  \n",
       "830   ROI time series, along with the underlying MA...  \n",
       "831   1053-8119/©2022 The Authors. Published by Els...  \n",
       "832   De-identiﬁed data and custom-built MATLAB cod...  \n",
       "833   1053-8119/©2022 The Authors. Published by Els...  \n",
       "\n",
       "[834 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dataset_sections[['Start_pattern_clean', 'Section', 'Section_wo_pattern']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac9ed8",
   "metadata": {},
   "source": [
    "<a name='getdatasets'></a>\n",
    "## 1.3. Get datasets\n",
    "I need to extract the datasets from the text sections we extracted above. \n",
    "\n",
    "Based on my previous observations, I will start the extraction with the following notions in mind: \n",
    "- Not open access datasets (meaning either fully private or available upon request) \n",
    "    - Markers include words such as \"request\", \"no data\", \"new data\", \"not be shared\" . E.g., \n",
    "        - \"Data and code are available upon request.\"\n",
    "        - \"Data and code availability statement All individual-level raw data used in this study cannot be shared because of the ethical code of Tokyo Metropolitan University. How-ever, the acquired metadata (e.g., group level activation maps) are available upon request. The corresponding author should be contacted by email for all data requests.\"\n",
    "        - \"No data were acquired for this study.\"\n",
    "        - \"The review summarizes data but does not contain new data.\"\n",
    "        - \"The data and code presented here are available upon request to the corresponding author.\"\n",
    "- Open access datasets (meaning it's available to everyone with a link or title of the dataset)\n",
    "    - Markers include hyperlinks and capitalized words \n",
    "        - Hyperlink \n",
    "        - Capitalized words \n",
    "    - Word like \"code\", \"data\", or \"package\" is typically featured in the sentences with links, pointing to what the link refers to. \n",
    "    \n",
    "- Issues (**code**)\n",
    "    - The URL can be broken up by spaces due to line changes in the PDF. Do we stop at the parenthesis, comma or another symbol that might end the URL? \n",
    "        - EXAMPLES \n",
    "    - Not all links point to the dataset - some are to the code, e.g., \n",
    "        - \"Speciﬁcally, GES, PC and LiNGAM were implemented using the widely used R package pcalg , which is available at https://cran.r-project.org/web/packages/pcalg/. Notears method was implemented using Python available at https://github.com/xunzheng/notears . The proposed joint DAG method was implemented with Python and the code is available at https://github.com/gmeng92/joint-notears . The cohort data is accessible through the website (https://coins.trendscenter.org/) of COINS (COllaborative Infor-matics Neuroimaging Suite) database (Scott et al., 2011).\"\n",
    "        - \"Data and code availability The data incorporated in the primary analysis were gathered from the public UK Biobank resource and will be made pub-licly available together with the code used to generate the data through the UK Biobank Returns Catalogue (https://biobank.ndph. ox.ac.uk/showcase/docs.cgi?id = 1). ABCD study data release 3.0 is available for approved researchers in NIMH Data Archive (NDA DOI:10.151.54/1,519,007). Code for conducting discovery and replication is available at https: //github.com/robloughnan/MOSTest _ generalization . Code for simu-lations is available at https://github.com/precimed/mostest/tree/master/simu.\"    \n",
    "    \n",
    "- Issues (**analysis**)\n",
    "    - If someone uses e.g., HCP, do they use all of the data? Do I need to catch more text-sections to learn this (in relation to the discussion of significance testing - if they use different parts of the dataset, they are not testing on the same). \n",
    "        - \"Due to HCP and dHCP privacy policies, the preprocessed resting-state images of human adults and neonates (with their IDs) can only be shared upon request with qualified investigators who agree to the Restricted Data Use Terms of these two datasets.\" (from 10.1016/j.neuroimage.2022.119339)\n",
    "    - What if the article does not analyse any data? (e.g., 10.1016/j.neuroimage.2022.119295 presents a software package for the execution of RT-fMRI experiments. \n",
    "    - What if there are multiple sections and the text is slightly different (e.g., 10.1016/j.neuroimage.2022.118986)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "TO DO Columns: \n",
    "- (DONE) Section text \n",
    "- (DONE) Section pattern (multiple reasons: \n",
    "    - 1) I can get a sense of whether the data statement is common in NeuroImage, \n",
    "    2) I can go back and handle potential more difficult cases) \n",
    "- Extracted dataset \n",
    "\n",
    "Validation dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e81eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of groundtruth DOI values to filter \n",
    "validation_dois = [\n",
    "    '10.1016/j.neuroimage.2021.118839',\n",
    "    '10.1016/j.neuroimage.2021.118854',\n",
    "    '10.1016/j.neuroimage.2022.119030',\n",
    "    '10.1016/j.neuroimage.2022.119050',\n",
    "    '10.1016/j.neuroimage.2022.119240',\n",
    "    '10.1016/j.neuroimage.2022.119443',\n",
    "    '10.1016/j.neuroimage.2022.119526',\n",
    "    '10.1016/j.neuroimage.2022.119549',\n",
    "    '10.1016/j.neuroimage.2022.119646',\n",
    "    '10.1016/j.neuroimage.2022.119676',\n",
    "] \n",
    "\n",
    "# Filter rows based on DOI values\n",
    "validation_set = articles_dataset_sections[articles_dataset_sections['DOI'].isin(validation_dois)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47d5e0",
   "metadata": {},
   "source": [
    "<a name='availabilitypattern'></a>\n",
    "### 1.3.1. 'Availability' pattern \n",
    "\n",
    "I will start by examining and dealing with the text sections that were filtered by the first section_pattern, namely: \n",
    "\n",
    "    r'(?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availability |(?<![\\'\"]) \\s*?\\n?Data\\s+availability |(?<![\\'\"]) \\s*?\\n?Data/code\\s+availability' \n",
    " \n",
    "The corresponding ending pattern: \n",
    "\n",
    "    r'\\s*?\\n\\n |\\s*?\\n?3\\. | \\s*?\\n?CRediT\\s+authorship\\s+contribution\\s+statement(?:s)? | \\s*?\\n?Acknowledgement(?:s)? | \\s*?\\n?Acknowledgment(?:s)? | \\s*?\\n?Reference(?:s)? | \\s*?\\n?Declaration\\s+of\\s+Competing\\s+Interest(?:s)? | \\s*?\\n?Credit\\s+authorship\\s+contribution\\s+statement(?:s)? | \\s*?\\n?Funding | \\s*?\\n?Supplementary\\s+materials | \\s*?\\n?Ethic(?:s)? statement(?:s)?'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f842e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?<![\\\\\\'\"]) \\\\s*?\\\\n?Data\\\\s+and\\\\s+code\\\\s+availability |(?<![\\\\\\'\"]) \\\\s*?\\\\n?Data\\\\s+availability |(?<![\\\\\\'\"]) \\\\s*?\\\\n?Data/code\\\\s+availability'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dataset_sections['Matched_pattern'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f42cef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_1 = articles_dataset_sections[articles_dataset_sections['Matched_pattern'] == '(?<![\\\\\\'\"]) \\\\s*?\\\\n?Data\\\\s+and\\\\s+code\\\\s+availability |(?<![\\\\\\'\"]) \\\\s*?\\\\n?Data\\\\s+availability |(?<![\\\\\\'\"]) \\\\s*?\\\\n?Data/code\\\\s+availability']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3ac5d",
   "metadata": {},
   "source": [
    "A total of 563 articles have a section where the title matches the pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a29cdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section_wo_pattern</th>\n",
       "      <th>Start_pattern_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statements Speciﬁcally, GES, PC and LiNGAM we...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The data incorporated in the primary analysis...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statement Data and code are available upon re...</td>\n",
       "      <td>Data/code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All data used in this project is from the Hum...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>statement All individual-level raw data used ...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>The data that support the ﬁndings of this stu...</td>\n",
       "      <td>Data availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>statement The underlying raw data to this man...</td>\n",
       "      <td>Data availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>statement The brain MR data was obtained from...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>ROI time series, along with the underlying MA...</td>\n",
       "      <td>Data availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>De-identiﬁed data and custom-built MATLAB cod...</td>\n",
       "      <td>Data and code availability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Section_wo_pattern  \\\n",
       "0     statements Speciﬁcally, GES, PC and LiNGAM we...   \n",
       "1     The data incorporated in the primary analysis...   \n",
       "2     statement Data and code are available upon re...   \n",
       "3     All data used in this project is from the Hum...   \n",
       "4     statement All individual-level raw data used ...   \n",
       "..                                                 ...   \n",
       "827   The data that support the ﬁndings of this stu...   \n",
       "828   statement The underlying raw data to this man...   \n",
       "829   statement The brain MR data was obtained from...   \n",
       "830   ROI time series, along with the underlying MA...   \n",
       "832   De-identiﬁed data and custom-built MATLAB cod...   \n",
       "\n",
       "            Start_pattern_clean  \n",
       "0    Data and code availability  \n",
       "1    Data and code availability  \n",
       "2        Data/code availability  \n",
       "3    Data and code availability  \n",
       "4    Data and code availability  \n",
       "..                          ...  \n",
       "827           Data availability  \n",
       "828           Data availability  \n",
       "829  Data and code availability  \n",
       "830           Data availability  \n",
       "832  Data and code availability  \n",
       "\n",
       "[563 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_1[['Section_wo_pattern', 'Start_pattern_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ade476bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### SENTENCES ################################################\n",
    "def split_text_into_sentences(text):\n",
    "    \"\"\"This function splits a given text into sentences based on a regular expression pattern. \n",
    "    It uses re.split() to identify sentence boundaries, considering common sentence-ending \n",
    "    punctuation like \".\", \"!\", or \"?\". It avoids splitting sentences if a digit immediately \n",
    "    follows the punctuation, e.g., 'Fig. 1'. \n",
    "    \n",
    "    Parameters: \n",
    "    :param text(str): \n",
    "    \n",
    "    Returns: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    sentence_pattern = r'(?<=[.!?])\\s+(?![0-9]+\\s)'\n",
    "    sentences = re.split(sentence_pattern, text)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "############### LINKS ################################################\n",
    "def extract_links(text):\n",
    "    \"\"\"This function identifies and extracts URLs (web links) from a given text using a \n",
    "    regular expression pattern. It also cleans and formats the extracted links by \n",
    "    removing leading and trailing spaces. The pattern accounts for various URL formats, \n",
    "    including those starting with \"http://\" or \"https://,\" DOI format, and domain names \n",
    "    with specific characters, e.g., 'osf.io'.\n",
    "\n",
    "    Parameters: \n",
    "    :param text(str): \n",
    "    \n",
    "    Returns: \n",
    "    :return: links  \n",
    "    \"\"\"\n",
    "    # ORIGINAL \n",
    "    #url_pattern = r'''(https?://[^\\s)(]+|\\bdoi:\\s*\\d+(?:\\.\\d+)*(?:/[a-zA-Z0-9\\./_\\-]+)?|[a-z]+\\.[a-z]+[a-zA-Z0-9\\./_\\-]*)(?:\\s*(?:[),]|\\.\\s*[\\r\\n]?|,\\s*|/and|$))'''\n",
    "    # NEW \n",
    "    \n",
    "    #url_pattern = r'(?i)(https?://[^\\s)(]+(?:/[^\\s)(]+)*(?:\\s*\\([^)]*\\))?|osf\\.io/[a-z0-9/]+/|doi:\\s*10\\.\\d+/\\S+|www\\.[a-z0-9.-]+\\.[a-z]{2,}/[^\\s)(]+)(?:\\s*(?:[),]|\\.\\s*[\\r\\n]?|,\\s*|/and|$))'\n",
    "    \n",
    "    url_pattern = r'(?i)(https?://[^\\s)(]+(?:/[^\\s)(]+)*(?:\\(\\S+\\))?|osf\\.io/[a-z0-9/]+|(?:www\\.)?[a-z0-9.-]+\\.[a-z]{2,}/[^\\s)(]+|doi:\\s*10\\.\\d+/\\S+)(?:\\s*(?:[),]|\\.\\s*[\\r\\n]?|,\\s*|/and|$))'\n",
    "\n",
    "    matches = re.findall(url_pattern, text)\n",
    "    cleaned_links = [\"\".join(match).strip() for match in matches]\n",
    "    return cleaned_links\n",
    "\n",
    "\n",
    "############### CAPITALIZED ################################################\n",
    "def extract_capitalized_words(text):\n",
    "    \"\"\"This function detects and extracts capitalized words from a text, e.g., 'Human \n",
    "    Connectome Project'. It also includes capitalized words followed by parentheses. \n",
    "    The regular expression pattern captures words with mixed case and optional hyphens. \n",
    "    It identifies words that are part of a capitalized notation and may be followed by text \n",
    "    within parentheses, e.g., \"In this sentence Dataset Example (www.linktodataset.com) \n",
    "    would be extracted\" returns \"Dataset Example (www.linktodataset.com)\"\n",
    "    \n",
    "    Parameters: \n",
    "    :param text(str): \n",
    "    \n",
    "    Returns: \n",
    "    :return: all capitalized words  \n",
    "    \"\"\"\n",
    "    capitalized_pattern = r'([A-Z][a-zA-Z\\-]+(?:\\s+[A-Z][a-zA-Z\\-]+)*(?:\\s*\\(.*?\\)))(?=\\s*\\.|\\s|$)'\n",
    "    return re.findall(capitalized_pattern, text)\n",
    "\n",
    "\n",
    "############### DATASETS ################################################\n",
    "def get_datasets(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Initialize lists to store extracted datasets and their corresponding sentences\n",
    "    extracted_datasets = []\n",
    "    dataset_sentences = []\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = split_text_into_sentences(text)\n",
    "    \n",
    "    # Extract links and capitalized words\n",
    "    links = extract_links(text)\n",
    "    capitalized_words = extract_capitalized_words(text)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        datasets_in_sentence = []\n",
    "        \n",
    "        # Check if the sentence contains any capitalized words\n",
    "        for cap_word in capitalized_words:\n",
    "            if cap_word in sentence:\n",
    "                datasets_in_sentence.append(cap_word)\n",
    "        \n",
    "        # Check if the sentence contains a link\n",
    "        for link in links:\n",
    "            if link in sentence:\n",
    "                # Check if the link is already captured as a capitalized word in the same sentence\n",
    "                if not any(link in cap_word for cap_word in capitalized_words):\n",
    "                    datasets_in_sentence.append(link)\n",
    "        \n",
    "        # Check if the sentence contains the word \"request\"\n",
    "        if \"request\" in sentence.lower():\n",
    "            datasets_in_sentence.append(\"Request\")\n",
    "        \n",
    "        if datasets_in_sentence:\n",
    "            # If any datasets were found in the sentence, add them and the sentence itself\n",
    "            extracted_datasets.extend(datasets_in_sentence)\n",
    "            dataset_sentences.extend([sentence] * len(datasets_in_sentence))\n",
    "    \n",
    "    # If no dataset was found, return \"N/A\"\n",
    "    if not extracted_datasets:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    #df = pd.DataFrame({'dataset': extracted_datasets, 'dataset_sentence': dataset_sentences})\n",
    "    #return df\n",
    "\n",
    "    return extracted_datasets, dataset_sentences\n",
    "\n",
    "\n",
    "###############\n",
    "def extract_and_add_datasets(row, text_column):\n",
    "    \"\"\"This function needs a description \n",
    "    \n",
    "    Parameters: \n",
    "    :param row: \n",
    "    :param text_column: \n",
    "    \n",
    "    Returns: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    result = get_datasets(row[text_column])\n",
    "    \n",
    "    if result is None:\n",
    "        return None\n",
    "    \n",
    "    if len(result) == 2:\n",
    "        datasets, sentences = result\n",
    "    else:\n",
    "        # Handle the case where get_datasets didn't return the expected two values\n",
    "        datasets, sentences = [\"N/A\"], [\"N/A\"]\n",
    "    \n",
    "    rows_list = []\n",
    "    for dataset, sentence in zip(datasets, sentences):\n",
    "        new_row = row.copy()\n",
    "        new_row['dataset'] = dataset\n",
    "        new_row['dataset_sentence'] = sentence\n",
    "        rows_list.append(new_row)\n",
    "    \n",
    "    return rows_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c9105",
   "metadata": {},
   "source": [
    "pattern = r'(?i)(https?://[^\\s)(]+(?:/[^\\s)(]+)*(?:\\s*\\([^)]*\\))?|osf\\.io/[a-z0-9/]+/|doi:\\s*10\\.\\d+/\\S+|www\\.[a-z0-9.-]+\\.[a-z]{2,}/[^\\s)(]+)(?:\\s*(?:[),]|\\.\\s*[\\r\\n]?|,\\s*|/and|$))'\n",
    "\n",
    "This pattern captures the following formats:\n",
    "- URLs starting with http:// or https://, including paths, and optional (dataset ...) parts.\n",
    "- osf.io/.../ format links.\n",
    "- DOI links in the format doi: 10.xxxxx/xxxx.\n",
    "- URLs starting with www. and followed by domain and path.\n",
    "\n",
    "The (?:\\s*(?:[),]|\\.\\s*[\\r\\n]?|,\\s*|/and|$)) part at the end is used to capture various possible endings. \n",
    "\n",
    "Here's how the pattern works:\n",
    "\n",
    "    (https?://[^\\s)(]+(?:/[^\\s)(]+)*(?:\\s*\\([^)]*\\))?: Captures HTTP/HTTPS links with paths and optional (dataset ...) parts.\n",
    "    osf\\.io/[a-z0-9/]+/: Captures osf.io/.../ format links.\n",
    "    doi:\\s*10\\.\\d+/\\S+: Captures DOI links.\n",
    "    www\\.[a-z0-9.-]+\\.[a-z]{2,}/[^\\s)(]+: Captures links starting with www. and followed by domain and path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887867f3",
   "metadata": {},
   "source": [
    "<a name='testingavailabilitypattern'></a>\n",
    "#### 1.3.1.1. Testing 'Availability' pattern\n",
    "\n",
    "I will test the functions using the groundtruth texts as my validation set. \n",
    "When manually extracting the datasets from the ten groundtruth texts, we should get the following datasets (NB! Currently, I have not distinguished between links that leads the reader to data and links that leads the reader to code - this will come later): \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "| DOI                                   | Dataset                                      | Dataset_sentence                                                                                                                                                                                            |\n",
    "|---------------------------------------|----------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 10.1016/j.neuroimage.2022.119526       | Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil)                       | Original data was obtained from the Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil) and the Allen Hu-man Brain Atlas (http://human.brain-map.org/).                    |\n",
    "|                                        | Allen Hu-man Brain Atlas (http://human.brain-map.org/)                                | Original data was obtained from the Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil) and the Allen Hu-man Brain Atlas (http://human.brain-map.org/).                    |\n",
    "|                                        | https://github.com/jbrown81/gradients                                    | All code (latent space derivation, dynamical system modeling, and gene expression corre-lation) and processed data (gradient maps/region weights, gradient timeseries, and region gene expression values) are available at https://github.com/jbrown81/gradients. |\n",
    "| 10.1016/j.neuroimage.2022.119443       | osf.io/gazx2/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/eucqf/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/thsqg/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/bndjg/                               | statement EEG datasets used to create the ﬁgure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/and osf.io/bndjg/.                  |\n",
    "|                                        | osf.io/guwnm/                               | Code used to reproduce the plots in Fig. 1 , as well as averaged ERP data, is available from osf.io/guwnm/.                                      |\n",
    "| 10.1016/j.neuroimage.2022.119240       | Request                                           | statement Data used in this study are available from the corresponding author upon reasonable request.                                                                         |\n",
    "| 10.1016/j.neuroimage.2022.119050       | zenodo.org (doi: 10.5281/zenodo.6110595) | Raw EEG data from all healthy individuals, as well as Matlab code, are publicly available on zenodo.org (doi: 10.5281/zenodo.6110595).                         |\n",
    "| 10.1016/j.neuroimage.2021.118854       | Human Connectome Project website (https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation) | The data used in this study was downloaded from the Human Connectome Project website (https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation). |\n",
    "|                                       | https://github.com/ferreirafabio80/gfa | The GFA models and experiments were implemented in Python 3.9.1 and are available here: https://github.com/ferreirafabio80/gfa.                                          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f8d3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on the groundtruth DOI values\n",
    "validation_set = pat_1[pat_1['DOI'].isin(validation_dois)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9f6a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the rows\n",
    "rows_list = []\n",
    "# Column name to use for text extraction\n",
    "text_column = 'Section_wo_pattern'\n",
    "\n",
    "# Iterate through each row of the original DataFrame\n",
    "for index, row in validation_set.iterrows():\n",
    "    # Call the custom function to extract datasets and add new rows\n",
    "    new_rows = extract_and_add_datasets(row, text_column)\n",
    "    \n",
    "    # Append the new rows to the list\n",
    "    rows_list.extend(new_rows)\n",
    "\n",
    "# Create the final DataFrame from the list of rows\n",
    "validation_df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0914f214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "      <th>Matched_pattern</th>\n",
       "      <th>Start_pattern</th>\n",
       "      <th>End_pattern</th>\n",
       "      <th>Start_pattern_clean</th>\n",
       "      <th>Section_wo_pattern</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "      <td>Data and code availability Original data was o...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(73770, 73799), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(488, 526), match=' \\nD...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "      <td>Human Connectome Project (1U54MH091657, PIs Va...</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "      <td>Data and code availability Original data was o...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(73770, 73799), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(488, 526), match=' \\nD...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "      <td>Allen Hu-man Brain Atlas (http://human.brain-m...</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "      <td>Data and code availability Original data was o...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(73770, 73799), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(488, 526), match=' \\nD...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "      <td>https://github.com/jbrown81/gradients.</td>\n",
       "      <td>All code (latent space derivation, dynamical s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/gazx2/</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/eucqf/</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/thsqg</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/bndjg/</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/guwnm/</td>\n",
       "      <td>Code used to reproduce the plots in Fig. 1 , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>Data availability statement Data used in this ...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(59756, 59777), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(130, 169), match='  \\n...</td>\n",
       "      <td>Data availability</td>\n",
       "      <td>statement Data used in this study are availab...</td>\n",
       "      <td>Request</td>\n",
       "      <td>statement Data used in this study are availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119050</td>\n",
       "      <td>Data and code availability Raw EEG data from a...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(37690, 37718), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(172, 177), match=' \\n3...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Raw EEG data from all healthy individuals, as...</td>\n",
       "      <td>doi: 10.5281/zenodo.6110595).</td>\n",
       "      <td>Raw EEG data from all healthy individuals, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118854</td>\n",
       "      <td>Data and code availability The data used in th...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(44928, 44956), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(548, 565), match=' Eth...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>The data used in this study was downloaded fr...</td>\n",
       "      <td>https://www.humanconnectome.org/study/hcp-youn...</td>\n",
       "      <td>The data used in this study was downloaded fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118854</td>\n",
       "      <td>Data and code availability The data used in th...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(44928, 44956), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(548, 565), match=' Eth...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>The data used in this study was downloaded fr...</td>\n",
       "      <td>https://github.com/ferreirafabio80/gfa</td>\n",
       "      <td>The GFA models and experiments were implemente...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DOI  \\\n",
       "302  10.1016/j.neuroimage.2022.119526   \n",
       "302  10.1016/j.neuroimage.2022.119526   \n",
       "302  10.1016/j.neuroimage.2022.119526   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "437  10.1016/j.neuroimage.2022.119240   \n",
       "583  10.1016/j.neuroimage.2022.119050   \n",
       "716  10.1016/j.neuroimage.2021.118854   \n",
       "716  10.1016/j.neuroimage.2021.118854   \n",
       "\n",
       "                                               Section  \\\n",
       "302  Data and code availability Original data was o...   \n",
       "302  Data and code availability Original data was o...   \n",
       "302  Data and code availability Original data was o...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "437  Data availability statement Data used in this ...   \n",
       "583  Data and code availability Raw EEG data from a...   \n",
       "716  Data and code availability The data used in th...   \n",
       "716  Data and code availability The data used in th...   \n",
       "\n",
       "                                       Matched_pattern  \\\n",
       "302  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "302  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "302  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "437  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "583  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "716  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "716  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "\n",
       "                                         Start_pattern  \\\n",
       "302  <re.Match object; span=(73770, 73799), match='...   \n",
       "302  <re.Match object; span=(73770, 73799), match='...   \n",
       "302  <re.Match object; span=(73770, 73799), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "437  <re.Match object; span=(59756, 59777), match='...   \n",
       "583  <re.Match object; span=(37690, 37718), match='...   \n",
       "716  <re.Match object; span=(44928, 44956), match='...   \n",
       "716  <re.Match object; span=(44928, 44956), match='...   \n",
       "\n",
       "                                           End_pattern  \\\n",
       "302  <re.Match object; span=(488, 526), match=' \\nD...   \n",
       "302  <re.Match object; span=(488, 526), match=' \\nD...   \n",
       "302  <re.Match object; span=(488, 526), match=' \\nD...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "437  <re.Match object; span=(130, 169), match='  \\n...   \n",
       "583  <re.Match object; span=(172, 177), match=' \\n3...   \n",
       "716  <re.Match object; span=(548, 565), match=' Eth...   \n",
       "716  <re.Match object; span=(548, 565), match=' Eth...   \n",
       "\n",
       "            Start_pattern_clean  \\\n",
       "302  Data and code availability   \n",
       "302  Data and code availability   \n",
       "302  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "437           Data availability   \n",
       "583  Data and code availability   \n",
       "716  Data and code availability   \n",
       "716  Data and code availability   \n",
       "\n",
       "                                    Section_wo_pattern  \\\n",
       "302   Original data was obtained from the Human Con...   \n",
       "302   Original data was obtained from the Human Con...   \n",
       "302   Original data was obtained from the Human Con...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "437   statement Data used in this study are availab...   \n",
       "583   Raw EEG data from all healthy individuals, as...   \n",
       "716   The data used in this study was downloaded fr...   \n",
       "716   The data used in this study was downloaded fr...   \n",
       "\n",
       "                                               dataset  \\\n",
       "302  Human Connectome Project (1U54MH091657, PIs Va...   \n",
       "302  Allen Hu-man Brain Atlas (http://human.brain-m...   \n",
       "302             https://github.com/jbrown81/gradients.   \n",
       "355                                      osf.io/gazx2/   \n",
       "355                                      osf.io/eucqf/   \n",
       "355                                       osf.io/thsqg   \n",
       "355                                      osf.io/bndjg/   \n",
       "355                                      osf.io/guwnm/   \n",
       "437                                            Request   \n",
       "583                      doi: 10.5281/zenodo.6110595).   \n",
       "716  https://www.humanconnectome.org/study/hcp-youn...   \n",
       "716             https://github.com/ferreirafabio80/gfa   \n",
       "\n",
       "                                      dataset_sentence  \n",
       "302   Original data was obtained from the Human Con...  \n",
       "302   Original data was obtained from the Human Con...  \n",
       "302  All code (latent space derivation, dynamical s...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355  Code used to reproduce the plots in Fig. 1 , a...  \n",
       "437   statement Data used in this study are availab...  \n",
       "583   Raw EEG data from all healthy individuals, as...  \n",
       "716   The data used in this study was downloaded fr...  \n",
       "716  The GFA models and experiments were implemente...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85c8d7",
   "metadata": {},
   "source": [
    "<a name='extractingallavailabilitydatasets'></a>\n",
    "#### 1.3.1.2. Extracting all availability datasets\n",
    "I will now run the code on all articles that matched with the availability pattern.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ba63c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DOI', 'Section', 'Matched_pattern', 'Start_pattern', 'End_pattern',\n",
       "       'Start_pattern_clean', 'Section_wo_pattern'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd848d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the rows\n",
    "rows_list = []\n",
    "# Column name to use for text extraction\n",
    "text_column = 'Section_wo_pattern'\n",
    "\n",
    "# Iterate through each row of the original DataFrame\n",
    "for index, row in pat_1.iterrows():\n",
    "    # Call the custom function to extract datasets and add new rows\n",
    "    new_rows = extract_and_add_datasets(row, text_column)\n",
    "    \n",
    "    # Append the new rows to the list\n",
    "    rows_list.extend(new_rows)\n",
    "\n",
    "# Create the final DataFrame from the list of rows\n",
    "articles_datasets = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b9b05",
   "metadata": {},
   "source": [
    "I want to separate the code links from the data links by simply searching the 'dataset_sentence' to see if it contains code or not. \n",
    "- If it contains either data or (data and code), I save the articles as articles_dataset\n",
    "- If it contains code and not (data and code), I save the articles as articles_code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ff6e430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links, capitalized words, and other in total:  1266\n"
     ]
    }
   ],
   "source": [
    "print(\"Links, capitalized words, and other in total: \", len(articles_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55447dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles with 'data' or both 'data' and 'code': 688\n",
      "Articles with 'code' but not 'data': 223\n",
      "Articles that do not fit either mask: 355\n"
     ]
    }
   ],
   "source": [
    "# Create a regex pattern for variations of \"data\" (match \"data\" as a standalone word or within other words)\n",
    "data_pattern = r'\\w*data\\w*'\n",
    "code_pattern = r'\\w*code\\w*'\n",
    "\n",
    "# Create a mask for rows containing variations of \"data\"\n",
    "data_mask = articles_datasets['dataset_sentence'].str.contains(data_pattern, case=False, regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# Create a mask for rows containing \"code\" but not \"data\"\n",
    "code_mask = (articles_datasets['dataset_sentence'].str.contains(code_pattern, case=False, regex=True, flags=re.IGNORECASE)) & (~data_mask)\n",
    "\n",
    "# Create a mask for rows that do not fit either of the mentioned masks\n",
    "other_mask = ~data_mask & ~code_mask\n",
    "\n",
    "# Separate rows into articles_dataset, articles_code, and articles_other\n",
    "articles_dataset = articles_datasets[data_mask]\n",
    "articles_code = articles_datasets[code_mask]\n",
    "articles_other = articles_datasets[other_mask]\n",
    "\n",
    "# Reset the index for all dataframes\n",
    "articles_dataset.reset_index(drop=True, inplace=True)\n",
    "articles_code.reset_index(drop=True, inplace=True)\n",
    "articles_other.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the counts for each dataframe\n",
    "print(f\"Articles with 'data' or both 'data' and 'code': {len(articles_dataset)}\")\n",
    "print(f\"Articles with 'code' but not 'data': {len(articles_code)}\")\n",
    "print(f\"Articles that do not fit either mask: {len(articles_other)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cce5ef",
   "metadata": {},
   "source": [
    "Data: database, dataset, image(s), (neuro)(map(s)), DOI(s), atlas, (freely available)\n",
    "Other: tool(kit, box), scripts, results, algorithm, software, package, plugin, function, analysis, \n",
    "\n",
    "Still not all links are finished: \n",
    "['https://osf',\n",
    "        '2) are available on the Open Science Framework repository: https://osf.io/95ftn/?view_only = 9a1a085583544c3eac44d1c75870599c.'],\n",
    "         ['https://www',\n",
    "        'humanconnectome.org/and https://www.developingconnectome.'],\n",
    "       ['https://www.developingconnectome',\n",
    "        'humanconnectome.org/and https://www.developingconnectome.'],\n",
    "       ['projects.nitrc.org/indi/indiPRIME.html',\n",
    "        'projects.nitrc.org/indi/indiPRIME.html.'],\n",
    "         ['https://www',\n",
    "        ' statement MRI images can be downloaded from HCP website: https://www.'],\n",
    "         ['https://github',\n",
    "        'Processing and analysis scripts used in this study are available at: https://github.com/ofgulban/meso-MRI (v1.0.2 saved at https://zenodo.org/record/7210802).'],\n",
    "        ['https://doi.org/10.5281/zenodo',\n",
    "        'The interactive web application accompanying Fig. 2 is published at https://doi.org/10.5281/zenodo.6579997 and is hosted at https://representational-dynamics.herokuapp.com/.'],\n",
    "        ['https://www.lead-dbs',\n",
    "        ' statements The open source Matlab toolboxes that were used in this study can be obtained from: Lead-DBS: https://www.lead-dbs.org SPM12: http://www.ﬁl.ion.ucl.ac.uk/spm Fieldtrip: http://ﬁeldtriptoolbox.org Custom-written Matlab scripts are available for sharing upon re-quest.'],\n",
    "       ['http://www.ﬁl.ion.ucl.ac',\n",
    "        ' statements The open source Matlab toolboxes that were used in this study can be obtained from: Lead-DBS: https://www.lead-dbs.org SPM12: http://www.ﬁl.ion.ucl.ac.uk/spm Fieldtrip: http://ﬁeldtriptoolbox.org Custom-written Matlab scripts are available for sharing upon re-quest.'],\n",
    "        ['https://github',\n",
    "        'Volumetric PET receptor images can be found on neuromaps (https://netneurolab.github.io/neuromaps/(Markello et al., 2022)) and at https://github.com/netneurolab/hansen_receptors (Hansen et al., 2021).'],\n",
    "        ['https://netneurolab.github',\n",
    "        '(2021) and is available in neuromaps (https://netneurolab.github.io/neuromaps/) (Markello et al., 2022).'],\n",
    "        ['https://github',\n",
    "        'All processing was performed using the abagen toolbox (https://github.com/netneurolab/abagen (Markello et al., 2021)).'],\n",
    "        ['https://github',\n",
    "        'We created a surface-based representation of the parcellation on the FreeSurfer fsaverage left hemi-sphere surface, via ﬁles from the Connectome Mapper toolkit (https://github.com/LTS5/cmp).'],\n",
    "        ['https://meg.univ-amu',\n",
    "        'The toolboxes used in this work are available at https://meg.univ-amu.fr/wiki/Main_Page and https://ins-amu.fr/software.'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f94a19ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['https://cran.r-project.org/web/packages/pcalg/',\n",
       "        ' statements Speciﬁcally, GES, PC and LiNGAM were implemented using the widely used R package pcalg , which is available at https://cran.r-project.org/web/packages/pcalg/.'],\n",
       "       ['https://github.com/xunzheng/notears',\n",
       "        'Notears method was implemented using Python available at https://github.com/xunzheng/notears.'],\n",
       "       ['GitHub (https://github.com/tierneytim/OPM/blob/master/testScripts/testVSM.m)',\n",
       "        'Examples and tests can also be found on GitHub (https://github.com/tierneytim/OPM/blob/master/testScripts/testVSM.m).'],\n",
       "       ['https://www.ieeg.org',\n",
       "        'iEEG snippets used speciﬁ-cally in this manuscript are also available, while full iEEG recordings are publicly available at https://www.ieeg.org.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github.com/BioMag/dbs_pd_beta_burst',\n",
       "        'Scripts used to produce the results and ﬁg-ures presented in the study are published on the BioMag Gitlab page (https://github.com/BioMag/dbs_pd_beta_burst).'],\n",
       "       ['https://www',\n",
       "        'humanconnectome.org/and https://www.developingconnectome.'],\n",
       "       ['https://www.developingconnectome',\n",
       "        'humanconnectome.org/and https://www.developingconnectome.'],\n",
       "       ['projects.nitrc.org/indi/indiPRIME.html',\n",
       "        'projects.nitrc.org/indi/indiPRIME.html.'],\n",
       "       ['Pre-cision Medicine (CAMIPM)',\n",
       "        'The gluCEST sequence used in this study is available upon request from researchers at the Center for Advanced Metabolic Imaging in Pre-cision Medicine (CAMIPM).'],\n",
       "       ['Request',\n",
       "        'The gluCEST sequence used in this study is available upon request from researchers at the Center for Advanced Metabolic Imaging in Pre-cision Medicine (CAMIPM).'],\n",
       "       ['https://www',\n",
       "        ' statement MRI images can be downloaded from HCP website: https://www.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Clinical Neu-roscience Research Unit (CNRU)',\n",
       "        'Research support and acknowledgments We would like to thank the staﬀof the Yale PET Center, Clinical Neu-roscience Research Unit (CNRU) at the Connecticut Mental Health Cen-ter (CMHC) of the Connecticut Department of Mental Health and Addic-tion Services (DMHAS), the Hospital Research Unit (HRU) at Yale-New Haven Hospital (YNHH) and the Yale Magnetic Resonance Research Center (MRRC).'],\n",
       "       ['Connecticut Mental Health Cen-ter (CMHC)',\n",
       "        'Research support and acknowledgments We would like to thank the staﬀof the Yale PET Center, Clinical Neu-roscience Research Unit (CNRU) at the Connecticut Mental Health Cen-ter (CMHC) of the Connecticut Department of Mental Health and Addic-tion Services (DMHAS), the Hospital Research Unit (HRU) at Yale-New Haven Hospital (YNHH) and the Yale Magnetic Resonance Research Center (MRRC).'],\n",
       "       ['Addic-tion Services (DMHAS), the Hospital Research Unit (HRU)',\n",
       "        'Research support and acknowledgments We would like to thank the staﬀof the Yale PET Center, Clinical Neu-roscience Research Unit (CNRU) at the Connecticut Mental Health Cen-ter (CMHC) of the Connecticut Department of Mental Health and Addic-tion Services (DMHAS), the Hospital Research Unit (HRU) at Yale-New Haven Hospital (YNHH) and the Yale Magnetic Resonance Research Center (MRRC).'],\n",
       "       ['Yale-New Haven Hospital (YNHH)',\n",
       "        'Research support and acknowledgments We would like to thank the staﬀof the Yale PET Center, Clinical Neu-roscience Research Unit (CNRU) at the Connecticut Mental Health Cen-ter (CMHC) of the Connecticut Department of Mental Health and Addic-tion Services (DMHAS), the Hospital Research Unit (HRU) at Yale-New Haven Hospital (YNHH) and the Yale Magnetic Resonance Research Center (MRRC).'],\n",
       "       ['Yale Magnetic Resonance Research Center (MRRC)',\n",
       "        'Research support and acknowledgments We would like to thank the staﬀof the Yale PET Center, Clinical Neu-roscience Research Unit (CNRU) at the Connecticut Mental Health Cen-ter (CMHC) of the Connecticut Department of Mental Health and Addic-tion Services (DMHAS), the Hospital Research Unit (HRU) at Yale-New Haven Hospital (YNHH) and the Yale Magnetic Resonance Research Center (MRRC).'],\n",
       "       ['Clinical Investigation (YCCI UL1 TR001863)',\n",
       "        'This work was supported by the Yale Center for Clinical Investigation (YCCI UL1 TR001863).'],\n",
       "       ['http://www.nitrc.org/projects/conn',\n",
       "        ' The Coon toolbox is available to download from http://www.nitrc.org/projects/conn.'],\n",
       "       ['https://sites.google.com/site/bctnet/',\n",
       "        'The brain connectivity tool-box, which was used for the graph theory measures can be ob-tained gratuitously online (https://sites.google.com/site/bctnet/).'],\n",
       "       ['https://physionet.org/content/sampen/1.0.0/',\n",
       "        'The sample entropy func-tion is freely available (https://physionet.org/content/sampen/1.0.0/).'],\n",
       "       ['Emmanuel Stamatakis (eas46@cam.ac.uk)',\n",
       "        'Emmanuel Stamatakis (eas46@cam.ac.uk).'],\n",
       "       ['https://github.com/FNNDSC/fetal-brain-segmentation',\n",
       "        'For MRI processing, the algo-rithms in the Methods are publicly available:1) brain extraction (https://github.com/FNNDSC/fetal-brain-segmentation) and 2) cor-tical plate segmentation (https://github.com/jwhong1125/fetal_CP_segmentation).'],\n",
       "       ['https://github.com/jwhong1125/fetal_CP_segmentation',\n",
       "        'For MRI processing, the algo-rithms in the Methods are publicly available:1) brain extraction (https://github.com/FNNDSC/fetal-brain-segmentation) and 2) cor-tical plate segmentation (https://github.com/jwhong1125/fetal_CP_segmentation).'],\n",
       "       ['MRI (v1.0.2 saved at https://zenodo.org/record/7210802)',\n",
       "        'Processing and analysis scripts used in this study are available at: https://github.com/ofgulban/meso-MRI (v1.0.2 saved at https://zenodo.org/record/7210802).'],\n",
       "       ['https://github',\n",
       "        'Processing and analysis scripts used in this study are available at: https://github.com/ofgulban/meso-MRI (v1.0.2 saved at https://zenodo.org/record/7210802).'],\n",
       "       ['https://github.com/alvarouc/polyssiﬁer',\n",
       "        'Machine learning models’ results are computed using python package Polyssiﬁer, available at https://github.com/alvarouc/polyssiﬁer'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://doi.org/10.5281/ZENODO.6402375',\n",
       "        ' statement Z-score maps in MNI152 space for each network presented in the paper are available in the Zenodo public repository: https://doi.org/10.5281/ZENODO.6402375. 12 J.A.'],\n",
       "       ['https://store.teamplay.siemens.com/apps',\n",
       "        'caliPER will be uploaded to the Siemens Healthineers Digital Marketplace and made available to users after creating and registering a free account (https://store.teamplay.siemens.com/apps).'],\n",
       "       ['Github (https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal)',\n",
       "        'The parcellation atlas is publicly available on Github (https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal).'],\n",
       "       ['LZ (link), TE (link), and NBS (link)',\n",
       "        'Open-source implementations are available online for all tools used in the study, in-cluding LZ (link), TE (link), and NBS (link).'],\n",
       "       ['https://github.com/abhogal-lab/seeVR',\n",
       "        ' The analysis tools used to generate the results presented in this manuscript are freely available via the open-source seeVR toolbox (https://github.com/abhogal-lab/seeVR).'],\n",
       "       ['https://cfn.upenn.edu/zewang/software',\n",
       "        'The brain entropy mapping tool is freely available from our website https://cfn.upenn.edu/zewang/software.html or https://github.com/zewangnew/BENtbx.'],\n",
       "       ['https://github.com/zewangnew/BENtbx.',\n",
       "        'The brain entropy mapping tool is freely available from our website https://cfn.upenn.edu/zewang/software.html or https://github.com/zewangnew/BENtbx.'],\n",
       "       ['https://optics.martinos',\n",
       "        'The hardware (circuit schematic and 3D drawing) and the software ﬁles are available on https://optics.martinos.org/ﬂexnirs/for non-commercial use.'],\n",
       "       ['https://github.com/XiZhu-CU/Transfer-Learning-Submission',\n",
       "        ' statement MATLAB scripts for cascade neural networks, transfer learning, statistical evaluations, and visualizations can be found here: https://github.com/XiZhu-CU/Transfer-Learning-Submission.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['German Primate Center (https://www.dpz.eu/en/home.html)',\n",
       "        ' statement The information about the non-human primate research can be found on the website of the German Primate Center (https://www.dpz.eu/en/home.html).'],\n",
       "       ['https://doi.org/10.5281/zenodo',\n",
       "        'The interactive web application accompanying Fig. 2 is published at https://doi.org/10.5281/zenodo.6579997 and is hosted at https://representational-dynamics.herokuapp.com/.'],\n",
       "       ['https://representational-dynamics.herokuapp.com/.',\n",
       "        'The interactive web application accompanying Fig. 2 is published at https://doi.org/10.5281/zenodo.6579997 and is hosted at https://representational-dynamics.herokuapp.com/.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Request',\n",
       "        'These matrices can be accessed by request by any qualiﬁed investigator.'],\n",
       "       ['https://github.com/nimh-sﬁm/hcp7t_fv_sleep',\n",
       "        'Processing scripts publicly available at https://github.com/nimh-sﬁm/hcp7t_fv_sleep'],\n",
       "       ['http://www.fz-juelich.de/inm/inm-1/jugex',\n",
       "        ' The JuGEx Toolbox is available at http://www.fz-juelich.de/inm/inm-1/jugex.'],\n",
       "       ['http://www.jubrain.fz-juelich.de',\n",
       "        'The Julich-Brain Atlas is available at http://www.jubrain.fz-juelich.de.'],\n",
       "       ['https://kg.ebrains.eu',\n",
       "        'Detailed information on cytoarchitectonic areas is stored in the ebrains knowledge graph (https://kg.ebrains.eu) Competing Interest Statement none declared'],\n",
       "       ['https://www.ukbiobank.ac.uk/',\n",
       "        'NeuroImage 262 (2022) 119534 website https://www.ukbiobank.ac.uk/.'],\n",
       "       ['Imagery Recall (i.e., presence or absence of imagery)',\n",
       "        'We ﬁrst determined the degree of Imagery Recall (i.e., presence or absence of imagery) for the diﬀerent sleep-wake stages.'],\n",
       "       ['Imagery Recall (Wilcoxon Ranksum p values: Ver-tex: N1 = 0.3086, N2 = 0.8876; Spindles: N2 = 0.4178; K Complexes: N2 = 0.6372)',\n",
       "        'No diﬀerences related to sleep oscillations were found between trials with and without Imagery Recall (Wilcoxon Ranksum p values: Ver-tex: N1 = 0.3086, N2 = 0.8876; Spindles: N2 = 0.4178; K Complexes: N2 = 0.6372).'],\n",
       "       ['Residues (Table 1)',\n",
       "        'There were no signiﬁcant correlations between sleep biomarkers and either Image or Aﬀect Residues (Table 1).'],\n",
       "       ['Residues (Table 1)',\n",
       "        'There were no signiﬁcant correlations between sleep biomarkers and either Image or Aﬀect Residues (Table 1).'],\n",
       "       ['Image Residues (Fig. 1 c, correlation matrix)',\n",
       "        'Power spectrum density versus Image or Aﬀect Residue In contrast with aﬀective valences, the visual contents were far from neutralized in Imagery, which produced a semantically rich set of re-ports and a wide dynamic range of Image Residues (Fig. 1 c, correlation matrix).'],\n",
       "       ['Residues (Table 1)',\n",
       "        'Similar results were observed for Aﬀect Residues (Table 1).'],\n",
       "       ['Residues (Table 1)',\n",
       "        'Similar results were observed for Aﬀect Residues (Table 1).'],\n",
       "       ['https://jubrain.fz-juelich.de/apps/cytoviewer2/cytoviewer-maintenance',\n",
       "        ' The probability maps and the maximum probability maps are pub-licly and freely available for download at the Julich-Brain atlas (https://jubrain.fz-juelich.de/apps/cytoviewer2/cytoviewer-maintenance.php# #mitte) and the Human Brain Project (https://atlases.ebrains.eu/viewer/-/a:juelich:iav:atlas:v1.0.0:1/t:minds:core:referencespace:v1.0.'],\n",
       "       ['https://github.com/JQuab/Insula-cytoarchitecure-.',\n",
       "        '0:tmp-fsaverage/p:minds:core:parcellationatlas:v1.0.0:94c1125b-b87e-45e4-901c-00daee7f2579-290/@:0.0.0.-W000..2_qztu.-8_uv.–2o6B.2_iz3G..23x6..0.0.0..1) Matlab script for multidimensional scaling and bins of microstructural areas as used in our analysis can be downloaded from: https://github.com/JQuab/Insula-cytoarchitecure-.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Func-tional NeuroImages (AFNI)',\n",
       "        ' statement Publicly available software used for analyses is Analysis of Func-tional NeuroImages (AFNI) https://afni.nimh.nih.gov/afni/.'],\n",
       "       ['https://afni.nimh.nih.gov/afni/',\n",
       "        ' statement Publicly available software used for analyses is Analysis of Func-tional NeuroImages (AFNI) https://afni.nimh.nih.gov/afni/.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github.com/HarrisBrainLab/lm4hz.',\n",
       "        'Scripts for the linear model procedure can be found at https://github.com/HarrisBrainLab/lm4hz.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Fast Greedy Equiv-alence Search (FGES)',\n",
       "        'Fast Greedy Equiv-alence Search (FGES) was conducted using causal-cmd software, available at https://bd2kccd.github.io/docs/causal-cmd/.'],\n",
       "       ['https://bd2kccd.github.io/docs/causal-cmd/',\n",
       "        'Fast Greedy Equiv-alence Search (FGES) was conducted using causal-cmd software, available at https://bd2kccd.github.io/docs/causal-cmd/.'],\n",
       "       ['https://sites.google.com/site/bctnet/.',\n",
       "        'All graph theory metrics were computed using the Brain Connectivity Toolbox (BCT), available at https://sites.google.com/site/bctnet/.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://www.lead-dbs',\n",
       "        ' statements The open source Matlab toolboxes that were used in this study can be obtained from: Lead-DBS: https://www.lead-dbs.org SPM12: http://www.ﬁl.ion.ucl.ac.uk/spm Fieldtrip: http://ﬁeldtriptoolbox.org Custom-written Matlab scripts are available for sharing upon re-quest.'],\n",
       "       ['http://www.ﬁl.ion.ucl.ac',\n",
       "        ' statements The open source Matlab toolboxes that were used in this study can be obtained from: Lead-DBS: https://www.lead-dbs.org SPM12: http://www.ﬁl.ion.ucl.ac.uk/spm Fieldtrip: http://ﬁeldtriptoolbox.org Custom-written Matlab scripts are available for sharing upon re-quest.'],\n",
       "       ['http://ﬁeldtriptoolbox',\n",
       "        ' statements The open source Matlab toolboxes that were used in this study can be obtained from: Lead-DBS: https://www.lead-dbs.org SPM12: http://www.ﬁl.ion.ucl.ac.uk/spm Fieldtrip: http://ﬁeldtriptoolbox.org Custom-written Matlab scripts are available for sharing upon re-quest.'],\n",
       "       ['Request',\n",
       "        'It will also be shared in a diﬀerent format by request from any qualiﬁed investigator. 22 K.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://osf.io/uyhra/',\n",
       "        'Semantic material and script for the task are accessible in the Open Sci-ence Framework at https://osf.io/uyhra/.'],\n",
       "       ['Open Science Framework (OSF)',\n",
       "        ' statement Thresholds t-statistic maps for within modality fMRI category decoding and MEG-fMRI analysis for each time window are freely available on the Open Science Framework (OSF) at the following URL: https://osf.io/8qfw4/?view_only = 3d50679935434bdf84a582ad7db 96231.'],\n",
       "       ['https://osf',\n",
       "        ' statement Thresholds t-statistic maps for within modality fMRI category decoding and MEG-fMRI analysis for each time window are freely available on the Open Science Framework (OSF) at the following URL: https://osf.io/8qfw4/?view_only = 3d50679935434bdf84a582ad7db 96231.'],\n",
       "       ['https://osf',\n",
       "        'The reconstructed images presented in this paper are also available as a MATLAB ﬁgure in the OSF project associated with this paper [ https://osf.io/mv47n/].'],\n",
       "       ['https://osf.io/mv47n/]',\n",
       "        'The reconstructed images presented in this paper are also available as a MATLAB ﬁgure in the OSF project associated with this paper [ https://osf.io/mv47n/].'],\n",
       "       ['https://osf.io/mv47n/].',\n",
       "        'The reconstructed images presented in this paper are also available as a MATLAB ﬁgure in the OSF project associated with this paper [ https://osf.io/mv47n/].'],\n",
       "       ['EP (i.e., Evoked Po-tential)',\n",
       "        'And then the training set and the testing set would be exchanged Since AEP, SEP and VEP are in the same runs, we treated them as one condition/task, EP (i.e., Evoked Po-tential).'],\n",
       "       ['ME (Motor execution)',\n",
       "        'Also, the term ME (Motor execution) was used to repre-sent the LH, RH, and RF conditions.'],\n",
       "       ['https://human.brain-map',\n",
       "        'The Allen Human Brain Atlas is available at https://human.brain-map.org/(Hawrylycz et al., 2012).'],\n",
       "       ['https://netneurolab.github',\n",
       "        'Volumetric PET receptor images can be found on neuromaps (https://netneurolab.github.io/neuromaps/(Markello et al., 2022)) and at https://github.com/netneurolab/hansen_receptors (Hansen et al., 2021).'],\n",
       "       ['https://github',\n",
       "        'Volumetric PET receptor images can be found on neuromaps (https://netneurolab.github.io/neuromaps/(Markello et al., 2022)) and at https://github.com/netneurolab/hansen_receptors (Hansen et al., 2021).'],\n",
       "       ['https://netneurolab.github.io/neuromaps/',\n",
       "        'Volumetric PET receptor images can be found on neuromaps (https://netneurolab.github.io/neuromaps/(Markello et al., 2022)) and at https://github.com/netneurolab/hansen_receptors (Hansen et al., 2021).'],\n",
       "       ['https://github',\n",
       "        'Volumetric PET receptor images can be found on neuromaps (https://netneurolab.github.io/neuromaps/(Markello et al., 2022)) and at https://github.com/netneurolab/hansen_receptors (Hansen et al., 2021).'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Autoradiography re-ceptor densities can be found in Supplementary Table 2 of Zilles and Palomero-Gallagher (2017).'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Autoradiography re-ceptor densities can be found in Supplementary Table 2 of Zilles and Palomero-Gallagher (2017).'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Autoradiography re-ceptor densities can be found in Supplementary Table 2 of Zilles and Palomero-Gallagher (2017).'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Autoradiography re-ceptor densities can be found in Supplementary Table 2 of Zilles and Palomero-Gallagher (2017).'],\n",
       "       ['https://netneurolab.github',\n",
       "        '(2021) and is available in neuromaps (https://netneurolab.github.io/neuromaps/) (Markello et al., 2022).'],\n",
       "       ['https://netneurolab.github.io/neuromaps/',\n",
       "        '(2021) and is available in neuromaps (https://netneurolab.github.io/neuromaps/) (Markello et al., 2022).'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Detailed information concerning the standard incubation protocols es-tablished over the last 25 years at Julich Research Centre and neces-sary for labeling the receptors is provided in Supplementary Table of Zilles and Palomero-Gallagher (2017) (see also Palomero-Gallagher and Zilles (2018) ; Zilles et al.'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Detailed information concerning the standard incubation protocols es-tablished over the last 25 years at Julich Research Centre and neces-sary for labeling the receptors is provided in Supplementary Table of Zilles and Palomero-Gallagher (2017) (see also Palomero-Gallagher and Zilles (2018) ; Zilles et al.'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Detailed information concerning the standard incubation protocols es-tablished over the last 25 years at Julich Research Centre and neces-sary for labeling the receptors is provided in Supplementary Table of Zilles and Palomero-Gallagher (2017) (see also Palomero-Gallagher and Zilles (2018) ; Zilles et al.'],\n",
       "       ['Palomero-Gallagher (2017)',\n",
       "        'Detailed information concerning the standard incubation protocols es-tablished over the last 25 years at Julich Research Centre and neces-sary for labeling the receptors is provided in Supplementary Table of Zilles and Palomero-Gallagher (2017) (see also Palomero-Gallagher and Zilles (2018) ; Zilles et al.'],\n",
       "       ['Zilles (2018)',\n",
       "        'Detailed information concerning the standard incubation protocols es-tablished over the last 25 years at Julich Research Centre and neces-sary for labeling the receptors is provided in Supplementary Table of Zilles and Palomero-Gallagher (2017) (see also Palomero-Gallagher and Zilles (2018) ; Zilles et al.'],\n",
       "       ['https://github',\n",
       "        'All processing was performed using the abagen toolbox (https://github.com/netneurolab/abagen (Markello et al., 2021)).'],\n",
       "       ['https://github',\n",
       "        'All processing was performed using the abagen toolbox (https://github.com/netneurolab/abagen (Markello et al., 2021)).'],\n",
       "       ['https://github',\n",
       "        'Next, samples were assigned to brain regions using MNI coor-dinates generated via non-linear registrations (https://github.com/chrisﬁlo/alleninf) by ﬁnding the nearest region, up to 2 mm away.'],\n",
       "       ['https://github',\n",
       "        'Next, samples were assigned to brain regions using MNI coor-dinates generated via non-linear registrations (https://github.com/chrisﬁlo/alleninf) by ﬁnding the nearest region, up to 2 mm away.'],\n",
       "       ['https://github.com/chrisﬁlo/alleninf',\n",
       "        'Next, samples were assigned to brain regions using MNI coor-dinates generated via non-linear registrations (https://github.com/chrisﬁlo/alleninf) by ﬁnding the nearest region, up to 2 mm away.'],\n",
       "       ['https://github',\n",
       "        'We created a surface-based representation of the parcellation on the FreeSurfer fsaverage left hemi-sphere surface, via ﬁles from the Connectome Mapper toolkit (https://github.com/LTS5/cmp).'],\n",
       "       ['https://github',\n",
       "        'We created a surface-based representation of the parcellation on the FreeSurfer fsaverage left hemi-sphere surface, via ﬁles from the Connectome Mapper toolkit (https://github.com/LTS5/cmp).'],\n",
       "       ['https://github.com/LTS5/cmp',\n",
       "        'We created a surface-based representation of the parcellation on the FreeSurfer fsaverage left hemi-sphere surface, via ﬁles from the Connectome Mapper toolkit (https://github.com/LTS5/cmp).'],\n",
       "       ['MRtrix (Dhollander et al., 2016; Jeurissen et al., 2014)',\n",
       "        'More speciﬁcally, ﬁber orientation distributions were generated using the multi-shell multi-tissue con-strained spherical deconvolution algorithm from MRtrix (Dhollander et al., 2016; Jeurissen et al., 2014).'],\n",
       "       ['https://neurovault.org/collections/RSLLSFTQ/',\n",
       "        'Unthresholded statistical maps from the reported comparisons are also available at Neurovault, https://neurovault.org/collections/RSLLSFTQ/.'],\n",
       "       ['Open Science Framework (OSF)',\n",
       "        ' statement Analysis scripts and ﬁnal results matrices are openly available on Open Science Framework (OSF) at https://osf.io/nt45v/(doi: 10.17605/OSF.IO/NT45V).'],\n",
       "       ['https://osf',\n",
       "        ' statement Analysis scripts and ﬁnal results matrices are openly available on Open Science Framework (OSF) at https://osf.io/nt45v/(doi: 10.17605/OSF.IO/NT45V).'],\n",
       "       ['doi: 10.17605/OSF.IO/NT45V)',\n",
       "        ' statement Analysis scripts and ﬁnal results matrices are openly available on Open Science Framework (OSF) at https://osf.io/nt45v/(doi: 10.17605/OSF.IO/NT45V).'],\n",
       "       ['https://nda.nih.gov/abcd',\n",
       "        'DOIs can be found at https://nda.nih.gov/abcd.'],\n",
       "       ['ADNI (http://adni.loni.usc.edu/)',\n",
       "        'ADNI images are available directly through ADNI (http://adni.loni.usc.edu/).'],\n",
       "       ['https://www.nitrc.org/projects/mri_reface',\n",
       "        'Our mri_reface software is avail-able at https://www.nitrc.org/projects/mri_reface.'],\n",
       "       ['NIH (NIA, NCI)',\n",
       "        'Lowe consults for Bayer Schering Pharma, Piramal Life Sciences, Eisai, Inc., and Merck Research and receives research support from GE Healthcare, Siemens Molecular Imaging, AVID Radiopharmaceu-ticals and the NIH (NIA, NCI).'],\n",
       "       ['Mild Cognitive Impairment (Ox-ford University Press, 2003)',\n",
       "        'Petersen is a consultant for Roche, Inc., Merck, Inc., Biogen, Inc., Nestle, Inc., and Eisai, Inc., served on a DSMB for Genentech, Inc.; receives royalties from publishing Mild Cognitive Impairment (Ox-ford University Press, 2003) and UpToDate; and receives research support from the NIH (P30 AG062677 (PI) and U01-AG006786 (PI), R01-AG011378 (Co-I), U24 AG057437 (Co-PI), UF1 NS125417 (C0-PI) and U01–024904 (Co-I)).'],\n",
       "       ['NIH (P30 AG062677 (PI)',\n",
       "        'Petersen is a consultant for Roche, Inc., Merck, Inc., Biogen, Inc., Nestle, Inc., and Eisai, Inc., served on a DSMB for Genentech, Inc.; receives royalties from publishing Mild Cognitive Impairment (Ox-ford University Press, 2003) and UpToDate; and receives research support from the NIH (P30 AG062677 (PI) and U01-AG006786 (PI), R01-AG011378 (Co-I), U24 AG057437 (Co-PI), UF1 NS125417 (C0-PI) and U01–024904 (Co-I)).'],\n",
       "       ['https://brainspace',\n",
       "        ' In performing these analyses, functional connectivity gradients were calculated based on the BrainSpace toolbox (https://brainspace.'],\n",
       "       ['readthedocs.io/en/latest/',\n",
       "        'readthedocs.io/en/latest/), and the FRF was derived from (https://github.com/DCAN-Labs/functional-random-forest).'],\n",
       "       ['https://github.com/DCAN-Labs/functional-random-forest',\n",
       "        'readthedocs.io/en/latest/), and the FRF was derived from (https://github.com/DCAN-Labs/functional-random-forest).'],\n",
       "       ['https://github.com/qluo2018/GCSDN',\n",
       "        'A Matlab toolbox of this algorithm is also available at https://github.com/qluo2018/GCSDN.'],\n",
       "       ['Innovation (SERI)',\n",
       "        'Study funding This project has received funding from the European Union’s Hori-zon 2020 research and innovation programme under the grant agree-ment No 681094 and is supported by the Swiss State Secretariat for Education, Research and Innovation (SERI) under contract number 15.0137.'],\n",
       "       ['Research (IRP-2022-01-158)',\n",
       "        'Moreover, MS receive funds from Wings for life charity (No WFL-CH-19/20) and grants from International Foundation for Research (IRP-2022-01-158).'],\n",
       "       ['NeuroVault (https://neurovault.org/)',\n",
       "        'All summary maps and parcel-lations will be made available on NeuroVault (https://neurovault.org/) at the time of publication.'],\n",
       "       ['https://github.com/BrayNeuroimagingLab/BNL_open/blob/main/individualization/Individualization.py',\n",
       "        'Python script is available at https://github.com/BrayNeuroimagingLab/BNL_open/blob/main/individualization/Individualization.py.'],\n",
       "       ['ANTs Regis-tration (Avants et al., 2011)',\n",
       "        'We used ANTs Regis-tration (Avants et al., 2011) to warp the EPI image to a study-speciﬁc 2 K.'],\n",
       "       ['Brain Con-nectivity Toolbox (https://sites.google.com/site/bctnet/)',\n",
       "        'Graph theory measures were calculated using the Brain Con-nectivity Toolbox (https://sites.google.com/site/bctnet/) and GRETNA toolkit (https://www.nitrc.org/projects/gretna).'],\n",
       "       ['https://www.nitrc.org/projects/gretna',\n",
       "        'Graph theory measures were calculated using the Brain Con-nectivity Toolbox (https://sites.google.com/site/bctnet/) and GRETNA toolkit (https://www.nitrc.org/projects/gretna).'],\n",
       "       ['https://github.com/GenLouvain/GenLouvain',\n",
       "        'The GenLouvain MATLAB pack-age (Jutla et al., 2011) used for multi-layer community detection is freely available online (https://github.com/GenLouvain/GenLouvain).'],\n",
       "       ['https://www.nitrc.org/projects/mouselemuratlas',\n",
       "        ' The template and atlas used in this study are available for download in NIfTI-1 format at https://www.nitrc.org/projects/mouselemuratlas.'],\n",
       "       ['MTRasym (in%)',\n",
       "        'B 1 , B 0 and regional Zspectrum and MTRasym (in%) in area 21 (temporal region) of middle-aged adult and old mouse lemurs.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Request',\n",
       "        'R scripts written for analyses are available upon request to Ryan M.'],\n",
       "       ['Barker (ryan.barker@mail.utoronto.ca)',\n",
       "        'Barker (ryan.barker@mail.utoronto.ca).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://eeglab.org',\n",
       "        'EEG preprocessing was performed using EEGLAB toolbox (https://eeglab.org) and FASTER plugin (https://sourceforge.net/projects/faster/).'],\n",
       "       ['https://sourceforge.net/projects/faster/',\n",
       "        'EEG preprocessing was performed using EEGLAB toolbox (https://eeglab.org) and FASTER plugin (https://sourceforge.net/projects/faster/).'],\n",
       "       ['https://www.mathworks.com/help/stats/kmeans.html',\n",
       "        'Clustering analysis was conducted using the MATLAB kmeans function (https://www.mathworks.com/help/stats/kmeans.html).'],\n",
       "       ['Request',\n",
       "        'NeuroImage 260 (2022) 119461 statistical regression tomography were implemented using MATLAB and are available from the corresponding author on reasonable request.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['http://www.nitrc.org/projects/conn',\n",
       "        ' statement The CONN toolbox is freely available online (http://www.nitrc.org/projects/conn).'],\n",
       "       ['https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/',\n",
       "        'The process of image registration can be reproduced using the SPM12 tool (https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/) and the MATLAB function of the 3D vesselness ﬁlter can be downloaded from (https://www.mathworks.com/matlabcentral/ﬁleexchange/24409-hessian-based-frangi-vesselness-ﬁlter).'],\n",
       "       ['https://www.mathworks.com/matlabcentral/ﬁleexchange/24409-hessian-based-frangi-vesselness-ﬁlter',\n",
       "        'The process of image registration can be reproduced using the SPM12 tool (https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/) and the MATLAB function of the 3D vesselness ﬁlter can be downloaded from (https://www.mathworks.com/matlabcentral/ﬁleexchange/24409-hessian-based-frangi-vesselness-ﬁlter).'],\n",
       "       ['Freesurfer (version 6.0.0, http://surfer.nmr.mgh.harvard.edu/)',\n",
       "        'Similarly, the hippocampus subﬁeld segmentation was performed using Freesurfer (version 6.0.0, http://surfer.nmr.mgh.harvard.edu/).'],\n",
       "       ['https://meg.univ-amu',\n",
       "        'The toolboxes used in this work are available at https://meg.univ-amu.fr/wiki/Main_Page and https://ins-amu.fr/software.'],\n",
       "       ['https://ins-amu.fr/software',\n",
       "        'The toolboxes used in this work are available at https://meg.univ-amu.fr/wiki/Main_Page and https://ins-amu.fr/software.'],\n",
       "       ['Request',\n",
       "        'The scripts used to get the results presented in this study are accessible upon rea-sonable request from the corresponding authors'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Proac-tive Life LLC (formerly Mobile Sleep Technologies)',\n",
       "        'Buxton dis-closes that he received subcontract grants to Penn State from Proac-tive Life LLC (formerly Mobile Sleep Technologies) doing business as SleepScape (NSF/STTR #1622766, NIH/NIA SBIR R43-AG056250, R44-AG056250), received honoraria/travel support for lectures from Boston University, Boston College, Tufts School of Dental Medicine, New York University, the University of Miami, and Allstate, consulting fees from SleepNumber, and receives an honorarium for his role as the Editor in Chief of Sleep Health (sleephealthjournal.org).'],\n",
       "       ['SleepScape (NSF/STTR #1622766, NIH/NIA SBIR R43-AG056250, R44-AG056250), received honoraria/travel support for lectures from Boston University, Boston College, Tufts School of Dental Medicine, New York University, the University of Miami, and Allstate, consulting fees from SleepNumber, and receives an honorarium for his role as the Editor in Chief of Sleep Health (sleephealthjournal.org)',\n",
       "        'Buxton dis-closes that he received subcontract grants to Penn State from Proac-tive Life LLC (formerly Mobile Sleep Technologies) doing business as SleepScape (NSF/STTR #1622766, NIH/NIA SBIR R43-AG056250, R44-AG056250), received honoraria/travel support for lectures from Boston University, Boston College, Tufts School of Dental Medicine, New York University, the University of Miami, and Allstate, consulting fees from SleepNumber, and receives an honorarium for his role as the Editor in Chief of Sleep Health (sleephealthjournal.org).'],\n",
       "       ['https://www.macromolecularmri',\n",
       "        'Software for recon-struction of MPF maps is available at https://www.macromolecularmri.'],\n",
       "       ['Request',\n",
       "        'The dicom images are only made available under a sharing agreement which could be obtained via request to the corresponding author. 9 Q.'],\n",
       "       ['https://osf.io/yn6gb/',\n",
       "        '(2019) and is available for download at https://osf.io/yn6gb/.'],\n",
       "       ['https://github.com/NYU-DiﬀusionMRI/mppca_denoise',\n",
       "        '(Veraart et al., 2016), on the following reposi-tory: https://github.com/NYU-DiﬀusionMRI/mppca_denoise.'],\n",
       "       ['https://github',\n",
       "        '(Veraart et al., 2016), on the following reposi-tory: https://github.com/NYU-DiﬀusionMRI/mppca_denoise.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://fsl.fmrib.ox.ac.uk/fsl/fslwiki',\n",
       "        'The toolboxes used in preprocessing (FSL) and analyzing resting state metrics (DPARSF) are available to the community at a public repository, https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/and http://rfmri.org/DPARSF.'],\n",
       "       ['http://rfmri.org/DPARSF',\n",
       "        'The toolboxes used in preprocessing (FSL) and analyzing resting state metrics (DPARSF) are available to the community at a public repository, https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/and http://rfmri.org/DPARSF.'],\n",
       "       ['https://github.com/utooley/Tooley_2020_child_functional_comms/tree/master/partitions',\n",
       "        ' We provide two freely available partitions (in fsaverage6, fsLR, and MNI volumetric spaces), at https://github.com/utooley/Tooley_2020_child_functional_comms/tree/master/partitions.'],\n",
       "       ['https://github',\n",
       "        ' We provide two freely available partitions (in fsaverage6, fsLR, and MNI volumetric spaces), at https://github.com/utooley/Tooley_2020_child_functional_comms/tree/master/partitions.'],\n",
       "       ['https://github',\n",
       "        'Other toolboxes used in this project are available at https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects and https://aaronclauset.github.io/wsbm.'],\n",
       "       ['https://aaronclauset.github.io/wsbm',\n",
       "        'Other toolboxes used in this project are available at https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects and https://aaronclauset.github.io/wsbm.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['MNI (mm)',\n",
       "        'MNI (mm) Region of Interest Side Cluster size F-value q-value (FDR -voxel) X Y Z Amygdala Right 24 27.671 0.012 24 − 4 − 18 Amygdala Left 10 11.243 0.028 − 18 − 4 − 18 OFC Left 25 24.027 0.034 − 36 41 − 6 Fig.'],\n",
       "       ['doi.org/10.15154/1523041', 'doi.org/10.15154/1523041.'],\n",
       "       ['ColorBrewer (2.0; Brewer et al., 2021)',\n",
       "        'The color scheme used for color-coding was an adapted version of the BrBG palette from ColorBrewer (2.0; Brewer et al., 2021) retrieved via R (3.5.3; R Core Team, 2018) and the package RColorBrewer (1.1-2; Neuwirth, 2014).'],\n",
       "       ['RColorBrewer (1.1-2; Neuwirth, 2014)',\n",
       "        'The color scheme used for color-coding was an adapted version of the BrBG palette from ColorBrewer (2.0; Brewer et al., 2021) retrieved via R (3.5.3; R Core Team, 2018) and the package RColorBrewer (1.1-2; Neuwirth, 2014).'],\n",
       "       ['Torch (Ketkar, 2017)',\n",
       "        'The original imple-mentation (Fonov et al., 2018) was done using the Torch library (Collobert et al., 2011), and we have re-implemented the software in pyTorch (Ketkar, 2017).'],\n",
       "       ['Request',\n",
       "        'Please contact ru-pert.lanzenberger@meduniwien.ac.at with any questions or requests.'],\n",
       "       ['Statistical Parametric Mapping (SPM)',\n",
       "        'The pre-processing and analyses steps have been well documented in the Methods section and were mostly exe-cuted using publicly available Statistical Parametric Mapping (SPM) (https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/) and FMRIB Soft-ware Library (FSL) (http://www.fmrib.ox.ac.uk/fsl) utilities.'],\n",
       "       ['FMRIB Soft-ware Library (FSL)',\n",
       "        'The pre-processing and analyses steps have been well documented in the Methods section and were mostly exe-cuted using publicly available Statistical Parametric Mapping (SPM) (https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/) and FMRIB Soft-ware Library (FSL) (http://www.fmrib.ox.ac.uk/fsl) utilities.'],\n",
       "       ['https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/',\n",
       "        'The pre-processing and analyses steps have been well documented in the Methods section and were mostly exe-cuted using publicly available Statistical Parametric Mapping (SPM) (https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/) and FMRIB Soft-ware Library (FSL) (http://www.fmrib.ox.ac.uk/fsl) utilities.'],\n",
       "       ['http://www.fmrib.ox.ac.uk/fsl',\n",
       "        'The pre-processing and analyses steps have been well documented in the Methods section and were mostly exe-cuted using publicly available Statistical Parametric Mapping (SPM) (https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm12/) and FMRIB Soft-ware Library (FSL) (http://www.fmrib.ox.ac.uk/fsl) utilities.'],\n",
       "       ['Request',\n",
       "        'If required, the IDL scripts used for this purpose can be made available upon request.'],\n",
       "       ['Request',\n",
       "        'Please contact ru-pert.lanzenberger@meduniwien.ac.at with any questions or requests.'],\n",
       "       ['https://cloud.tsinghua.edu.cn/d/3d176032a5a545c1b927/',\n",
       "        '(https://cloud.tsinghua.edu.cn/d/3d176032a5a545c1b927/)'],\n",
       "       ['https://www.humanconnectome',\n",
       "        'in Aging are publicly available (https://www.humanconnectome.'],\n",
       "       ['https://sites.google.com/site/pierrickcoupe/softwares/denoising-for-medical-imaging/mri-denoising/mri-denoising-software',\n",
       "        'The MATLAB-based software of AONLM is publicly available (https://sites.google.com/site/pierrickcoupe/softwares/denoising-for-medical-imaging/mri-denoising/mri-denoising-software).'],\n",
       "       ['ND (i.e., Δlog(𝐵𝑃 ND)',\n",
       "        'To evaluate power, we simulated two groups, with a true global (i.e., across all 9 regions) group diﬀerence of 20% in 𝐵𝑃 ND (i.e., Δlog(𝐵𝑃 ND) = 0.182).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://www.nitrc.org/projects/bioimagesuite/',\n",
       "        ' statement Matlab scripts to run the CPM analyses can be found at https://www.nitrc.org/projects/bioimagesuite/.'],\n",
       "       ['http://bioimagesuite.com/',\n",
       "        'Tools used for visual-ization can be accessed at http://bioimagesuite.com/.'],\n",
       "       ['AHEAD (Alkemade et al., 2020a)',\n",
       "        ' statement A prior version of the individual qMRI maps has been re-leased as AHEAD (Alkemade et al., 2020a) can be found at https://doi.org/10.21942/uva.10007840.v1.'],\n",
       "       ['https://doi.org/10.21942/uva.10007840.v1',\n",
       "        ' statement A prior version of the individual qMRI maps has been re-leased as AHEAD (Alkemade et al., 2020a) can be found at https://doi.org/10.21942/uva.10007840.v1.'],\n",
       "       ['https://subcortex.eu/app',\n",
       "        'All derived participant-wise and region-wise measures can be downloaded from our app at https://subcortex.eu/app.'],\n",
       "       ['http://openfnirs.org/',\n",
       "        'FNIRS preprocessing was performed using HOMER2 (http://openfnirs.org/).'],\n",
       "       ['FreeSurfer (https://surfer.nmr.mgh.harvard.edu), Mesh-Mixer (https://www.meshmixer.com), and ISO2MESH toolbox (http://iso2mesh.sourceforge.net/)',\n",
       "        'The segmentation and FEM modeling were per-formed using FreeSurfer (https://surfer.nmr.mgh.harvard.edu), Mesh-Mixer (https://www.meshmixer.com), and ISO2MESH toolbox (http://iso2mesh.sourceforge.net/).'],\n",
       "       ['NIRFAST (https://milab.host.dartmouth.edu/nirfast/)',\n",
       "        'The Jacobian was calculated using NIRFAST (https://milab.host.dartmouth.edu/nirfast/).'],\n",
       "       ['FASTICA (http://research.ics.aalto.ﬁ/ica/fastica/)',\n",
       "        'PCA reduc-tion was performed using FASTICA (http://research.ics.aalto.ﬁ/ica/fastica/).'],\n",
       "       ['https://sccn.ucsd.edu/',\n",
       "        'Group spatial ICA was performed using MATLAB runica function (https://sccn.ucsd.edu/).'],\n",
       "       ['https://www.mathworks.com/help/stats/kmeans.html',\n",
       "        'Clustering was performed us-ing MATLAB kmeans function (https://www.mathworks.com/help/stats/kmeans.html).'],\n",
       "       ['https://www.jstatsoft.org',\n",
       "        'Phase analyses were performed using MATLAB CircStat toolbox (https://www.jstatsoft.org).'],\n",
       "       ['https://github.com/andy1764/FCHarmony',\n",
       "        'The harmonization methods used in the paper are implemented in the FCHarmony package available at https://github.com/andy1764/FCHarmony.'],\n",
       "       ['Brain Connec-tivity Toolbox (BCT)',\n",
       "        'Network analyses are performed using the Brain Connec-tivity Toolbox (BCT) version 2019-03-03 available on their website at https://sites.google.com/site/bctnet/.'],\n",
       "       ['https://sites.google.com/site/bctnet/.',\n",
       "        'Network analyses are performed using the Brain Connec-tivity Toolbox (BCT) version 2019-03-03 available on their website at https://sites.google.com/site/bctnet/.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://nda.nih.gov/abcd/',\n",
       "        'Access can be requested at https://nda.nih.gov/abcd/.'],\n",
       "       ['Request',\n",
       "        'Access can be requested at https://nda.nih.gov/abcd/.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['ROIs (derived from the Yeo2011 resting-state networks)',\n",
       "        'The 51 resting-state ROIs (derived from the Yeo2011 resting-state networks) can be found here at https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Yeo2011_fcMRI_clustering.'],\n",
       "       ['https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Yeo2011_fcMRI_clustering',\n",
       "        'The 51 resting-state ROIs (derived from the Yeo2011 resting-state networks) can be found here at https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Yeo2011_fcMRI_clustering.'],\n",
       "       ['Yongling Lin (linyl@mail.bnu.edu.cn)',\n",
       "        'Further inquiries can be directed to the ﬁrst au-thor Yongling Lin (linyl@mail.bnu.edu.cn).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github',\n",
       "        'The Matlab toolboxes used for the EEG analysis are freely available online (EEGLAB: https://github.com/sccn/eeglab; Chronux: http://chronux.org/; Brainstorm: https://neuroimage.usc.'],\n",
       "       ['http://chronux',\n",
       "        'The Matlab toolboxes used for the EEG analysis are freely available online (EEGLAB: https://github.com/sccn/eeglab; Chronux: http://chronux.org/; Brainstorm: https://neuroimage.usc.'],\n",
       "       ['https://neuroimage.usc',\n",
       "        'The Matlab toolboxes used for the EEG analysis are freely available online (EEGLAB: https://github.com/sccn/eeglab; Chronux: http://chronux.org/; Brainstorm: https://neuroimage.usc.'],\n",
       "       ['Request',\n",
       "        'edu/brainstorm/), and the custom-written scripts for this study are available upon reasonable request.'],\n",
       "       ['Request',\n",
       "        'The processing script for ihMTR calculation can be made avail-able upon request.'],\n",
       "       ['https://github.com/MNagtegaal/SPIJN',\n",
       "        'A demo ver-sion is available via https://github.com/MNagtegaal/SPIJN.'],\n",
       "       ['FLAIR (A), lesion segmentations (B), and maps of myelin-sensitive markers (C-G)',\n",
       "        'Representative slices of FLAIR (A), lesion segmentations (B), and maps of myelin-sensitive markers (C-G) from two MS patients, including expanded regions.'],\n",
       "       ['MWF NNLS (C)',\n",
       "        'Myelin-sensitive markers include two reconstructions of the myelin water fraction, MWF NNLS (C) and MWF SPIJN (D), inhomogeneous magnetization transfer ratio (ihMTR) (E), MT saturation (MTsat) (F), and macromolecular tissue volume (MTV) (G).'],\n",
       "       ['MWF SPIJN (D), inhomogeneous magnetization transfer ratio (ihMTR)',\n",
       "        'Myelin-sensitive markers include two reconstructions of the myelin water fraction, MWF NNLS (C) and MWF SPIJN (D), inhomogeneous magnetization transfer ratio (ihMTR) (E), MT saturation (MTsat) (F), and macromolecular tissue volume (MTV) (G).'],\n",
       "       ['https://www.nitrc.org/projects/noddi_toolbox',\n",
       "        'from https://www.nitrc.org/projects/noddi_toolbox.'],\n",
       "       ['https://www',\n",
       "        '-Eye tracking videos can be found on YouTube: https://www.'],\n",
       "       ['youtube.com/channel/UCXojt8KD3bCsUlT_zaWzWWQ',\n",
       "        'youtube.com/channel/UCXojt8KD3bCsUlT_zaWzWWQ.'],\n",
       "       ['Docker (Merkel, 2014)',\n",
       "        'Some softwares we used were distributed as Docker (Merkel, 2014) containers, and compiled and run with Singularity (3.6.3) (Kurtzer et al., 2017): •QSIPrep 0.13.0RC1 (singularity build qsiprep.simg docker://pennbbl/qsiprep:0.13.0RC1) •TractSeg 2.3 (singularity build tractseg.simg docker://wasserth/tractseg:master) •MRtrix 3.0.3 (singularity build mrtrix.simg docker://mrtrix3/mrtrix3:3.0.3) •FSL 6.0.4 (singularity build fsl.simg docker://brainlife/fsl:6.0.4-patched) We encourage anyone to use the latest stable releases of these soft-wares.'],\n",
       "       ['Singularity (3.6.3)',\n",
       "        'Some softwares we used were distributed as Docker (Merkel, 2014) containers, and compiled and run with Singularity (3.6.3) (Kurtzer et al., 2017): •QSIPrep 0.13.0RC1 (singularity build qsiprep.simg docker://pennbbl/qsiprep:0.13.0RC1) •TractSeg 2.3 (singularity build tractseg.simg docker://wasserth/tractseg:master) •MRtrix 3.0.3 (singularity build mrtrix.simg docker://mrtrix3/mrtrix3:3.0.3) •FSL 6.0.4 (singularity build fsl.simg docker://brainlife/fsl:6.0.4-patched) We encourage anyone to use the latest stable releases of these soft-wares.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github.com/chiaramﬀ/IronTract',\n",
       "        'The post-processing scripts used in Round2 are available at https://github.com/chiaramﬀ/IronTract.'],\n",
       "       ['https://github.com/chassall/averagetaskvalue.',\n",
       "        'Task and analysis scripts are available at https://github.com/chassall/averagetaskvalue.'],\n",
       "       ['http://www.adrianﬁscher.de/teaching.html.',\n",
       "        'The scripts for the regression anal-ysis can be accessed here: http://www.adrianﬁscher.de/teaching.html.'],\n",
       "       ['https://osf.io/bkep4',\n",
       "        ' The experimental design and hypotheses reported here were preregistered (https://osf.io/bkep4).'],\n",
       "       ['https://www.biorxiv.org/content/10.1101/2021.09.18.460905',\n",
       "        'The manuscript was uploaded to a preprint server (https://www.biorxiv.org/content/10.1101/2021.09.18.460905).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Request',\n",
       "        'It is not yet in a very user-friendly form but is available upon request.'],\n",
       "       ['https://github.com/OHBA-analysis/HMM-MAR.',\n",
       "        'The HMM-MAR toolbox used to run the HMMs is available under https://github.com/OHBA-analysis/HMM-MAR.'],\n",
       "       ['Request',\n",
       "        'Also in the supplement, we provide a list of the English word spoken by the ﬁrst author (ECB) as our forward speech stimuli; the associated sound ﬁles can be provided at any time upon reasonable request.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Request',\n",
       "        'Please contact d.fernandez-espejo@bham.ac.uk with any ques-tions or requests.'],\n",
       "       ['Request',\n",
       "        'Please contact x.y.liu@buaa.edu.cn at with any requests.'],\n",
       "       ['Berlin (Approval number: EA1/169/11)',\n",
       "        'Ethics approval statement The study was carried out in accordance with the 2008 Declaration of Helsinki and was approved by the ethics commission of the Charité–Universitätsmedizin Berlin (Approval number: EA1/169/11).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['http://www.adrianﬁscher.de/teaching.html.',\n",
       "        'The scripts for the regression analysis can be accessed here: http://www.adrianﬁscher.de/teaching.html.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://lobi',\n",
       "        ' statement Norms for the stimuli used in the experiment are available as supplementary materials to the previous publications: https://lobi.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['http://neuroimage.yonsei.ac.kr:3000',\n",
       "        'The sug-gested connection distribution map in the current study is available at http://neuroimage.yonsei.ac.kr:3000.'],\n",
       "       ['https://identiﬁers.org/neurovault.collection:10447.',\n",
       "        'Thresholded and unthresholded statistical maps are located on https://identiﬁers.org/neurovault.collection:10447.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['ox.ac.uk/spet4877/ihcpy', 'ox.ac.uk/spet4877/ihcpy.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['OSF.IO/TMHUP',\n",
       "        ' Maps and ﬁles from the present analyses are available at: DOI 10.17605/OSF.IO/TMHUP'],\n",
       "       ['Animal Care (CCAC)',\n",
       "        ' statement Animal protocols used in this research were approved by the Ani-mal Care Committee of the University of Calgary and conformed to the guidelines established by the Canadian Council of Animal Care (CCAC).'],\n",
       "       ['https://identiﬁers.org/neurovault',\n",
       "        'and https://identiﬁers.org/neurovault.'],\n",
       "       ['http://www.medizin.uni-tuebingen.de/kinder/en/research/neuroimaging/software/.',\n",
       "        'The LI-tool toolbox is freely available at: http://www.medizin.uni-tuebingen.de/kinder/en/research/neuroimaging/software/.'],\n",
       "       ['https://github.com/multifunkim/spark-matlab',\n",
       "        'The MATLAB scripts for SPARK im-plementation are available on https://github.com/multifunkim/spark-matlab.'],\n",
       "       ['https://github.com/Kangjoo/arousal-rsfMRIpupil-hub',\n",
       "        'Several additional MATLAB scripts for SPARK adapted for this study are available on https://github.com/Kangjoo/arousal-rsfMRIpupil-hub.'],\n",
       "       ['http://www.ﬁl.ion.ucl.ac.uk/spm/',\n",
       "        'Analyses were conducted using standard processing scripts in SPM12 (Statistical Parametric Mapping, http://www.ﬁl.ion.ucl.ac.uk/spm/) implemented in MATLAB 2014a (MathWorks, Inc., USA), and SPSS 24 (IBM SPSS Statistics for Windows, Version 24.0.'],\n",
       "       ['GitHub (https://github.com/Jekline2/DWMA.git)',\n",
       "        ' statement Parameter maps used in this study can be found on GitHub (https://github.com/Jekline2/DWMA.git).'],\n",
       "       ['https://github.com/MIDIconsortium/BrainAge',\n",
       "        ' Scripts to enable readers to run our trained brain-age mod-els using their own scans are available at https://github.com/MIDIconsortium/BrainAge.'],\n",
       "       ['https://github',\n",
       "        ' Scripts to enable readers to run our trained brain-age mod-els using their own scans are available at https://github.com/MIDIconsortium/BrainAge.'],\n",
       "       ['European Research Council(ERC)',\n",
       "        'GDP was funded by the European Research Council(ERC) Starting Grant 2015 RESHAPE: REstoring the Selfwith embodiable Hand ProsthesEs (ERC-2015-STG, projectn.'],\n",
       "       ['http://prepro-cessed-connectomes-project.org/abide/index.html',\n",
       "        'humanconnectome.org) and the ABIDE consortium (http://prepro-cessed-connectomes-project.org/abide/index.html).'],\n",
       "       ['https://cran.r-project.org/web/packages/nlshrink/index.html',\n",
       "        'The nlshrink library (version 1.0.1, https://cran.r-project.org/web/packages/nlshrink/index.html) was the only external covariance shrinkage method package used in this work.'],\n",
       "       ['https://github.com/UTHSCSA-NAL/shrinkage.',\n",
       "        'A clean copy of these methods is freely available under a MIT licence in the following GitHub repository: https://github.com/UTHSCSA-NAL/shrinkage.'],\n",
       "       ['https://osf',\n",
       "        '2) are available on the Open Science Framework repository: https://osf.io/95ftn/?view_only = 9a1a085583544c3eac44d1c75870599c.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Neurovault (https://neurovault.org/)',\n",
       "        ' statements Activation maps in the group-level analyses will be available on the website of Neurovault (https://neurovault.org/).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github.com/SayginLab/neonate_molloy',\n",
       "        'Resulting neonate parcellations and full genetic expression results can be found at https://github.com/SayginLab/neonate_molloy.'],\n",
       "       ['https://github.com/SayginLab/neonate_molloy',\n",
       "        'Resulting neonate parcellations and full genetic expression results can be found at https://github.com/SayginLab/neonate_molloy.'],\n",
       "       ['French National Research Agency (reference: Hanuman ANR-18-CE45–0014 and EquipEX FIGURES 10-EQPX-0001)',\n",
       "        'Formating of funding sources This research was funded by the French National Research Agency (reference: Hanuman ANR-18-CE45–0014 and EquipEX FIGURES 10-EQPX-0001) and INTERREG France (Channel) England Programme (RE-VERT project).'],\n",
       "       ['INTERREG France (Channel)',\n",
       "        'Formating of funding sources This research was funded by the French National Research Agency (reference: Hanuman ANR-18-CE45–0014 and EquipEX FIGURES 10-EQPX-0001) and INTERREG France (Channel) England Programme (RE-VERT project).'],\n",
       "       ['England Programme (RE-VERT project)',\n",
       "        'Formating of funding sources This research was funded by the French National Research Agency (reference: Hanuman ANR-18-CE45–0014 and EquipEX FIGURES 10-EQPX-0001) and INTERREG France (Channel) England Programme (RE-VERT project).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github.com/TomMaullin/BLM',\n",
       "        'The BLM toolbox, which is also referenced several times throughout this work, may be found at: https://github.com/TomMaullin/BLM.'],\n",
       "       ['https://identiﬁers.org/neurovault.collection:13110',\n",
       "        'The images generated by BLMM for the three models discussed in Sections 2.3 and 3.2 may be found at: Model 1: https://identiﬁers.org/neurovault.collection:13110.'],\n",
       "       ['https://identiﬁers.org/neurovault.collection:13111',\n",
       "        'Model 2: https://identiﬁers.org/neurovault.collection:13111.'],\n",
       "       ['https://identiﬁers.org/neurovault.collection:13112',\n",
       "        'Model 3: https://identiﬁers.org/neurovault.collection:13112.'],\n",
       "       ['https://identiﬁers.org/neurovault.collection:10451.',\n",
       "        'The results of the LRT’s for model comparison discussed in Sections 2.3 and 3.2 may also be found at: https://identiﬁers.org/neurovault.collection:10451.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github.com/yundumbledore/NeuroProcImager',\n",
       "        'The inference-based neural processes imaging framework is implemented in a MATLAB package called NeuroProcImager and is available at https://github.com/yundumbledore/NeuroProcImager.'],\n",
       "       ['https://git.ecdf.ed.ac.uk/jbrl/ena',\n",
       "        'The seg-mented tracts in the ENA50 template space are available here: https://git.ecdf.ed.ac.uk/jbrl/ena.'],\n",
       "       ['https://sccn.ucsd.edu/eeglab/index.php',\n",
       "        'All the toolsets used in the processing and analysis pipeline are publicly available (EEGLAB: https://sccn.ucsd.edu/eeglab/index.php , SPM8: https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm8/, WFU_PickAtlas toolbox https://www.nitrc.org/projects/wfu_pickatlas/, Human Motor Area Template and Basal Ganglia Human Area Template: http://lrnlab.org/).'],\n",
       "       ['https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm8/',\n",
       "        'All the toolsets used in the processing and analysis pipeline are publicly available (EEGLAB: https://sccn.ucsd.edu/eeglab/index.php , SPM8: https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm8/, WFU_PickAtlas toolbox https://www.nitrc.org/projects/wfu_pickatlas/, Human Motor Area Template and Basal Ganglia Human Area Template: http://lrnlab.org/).'],\n",
       "       ['https://www.nitrc.org/projects/wfu_pickatlas/',\n",
       "        'All the toolsets used in the processing and analysis pipeline are publicly available (EEGLAB: https://sccn.ucsd.edu/eeglab/index.php , SPM8: https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm8/, WFU_PickAtlas toolbox https://www.nitrc.org/projects/wfu_pickatlas/, Human Motor Area Template and Basal Ganglia Human Area Template: http://lrnlab.org/).'],\n",
       "       ['http://lrnlab.org/',\n",
       "        'All the toolsets used in the processing and analysis pipeline are publicly available (EEGLAB: https://sccn.ucsd.edu/eeglab/index.php , SPM8: https://www.ﬁl.ion.ucl.ac.uk/spm/software/spm8/, WFU_PickAtlas toolbox https://www.nitrc.org/projects/wfu_pickatlas/, Human Motor Area Template and Basal Ganglia Human Area Template: http://lrnlab.org/).'],\n",
       "       ['Fast Fourier Transformation (FFT)',\n",
       "        'The oscillatory power of neural signal was cal-culated by means of Fast Fourier Transformation (FFT) using the new-timef function in EEGLAB.'],\n",
       "       ['Human Mo-tor Area Template (HMAT)',\n",
       "        'For anatomical struc-tures that are relatively large and well identiﬁed, such as the cortical motor regions, thalamus, caudate and putamen, we used anatomical masks adapted from standardized templates including the Human Mo-tor Area Template (HMAT) (Mayka et al., 2006), WFU PickAtlas toolbox (Maldjian et al., 2003), and the Basal Ganglia Human Area Template (BGHAT) (Prodoehl et al., 2008).'],\n",
       "       ['Basal Ganglia Human Area Template (BGHAT)',\n",
       "        'For anatomical struc-tures that are relatively large and well identiﬁed, such as the cortical motor regions, thalamus, caudate and putamen, we used anatomical masks adapted from standardized templates including the Human Mo-tor Area Template (HMAT) (Mayka et al., 2006), WFU PickAtlas toolbox (Maldjian et al., 2003), and the Basal Ganglia Human Area Template (BGHAT) (Prodoehl et al., 2008).'],\n",
       "       ['ROIs (Table 1)',\n",
       "        'For smaller basal ganglia nuclei (i.e., GPi, GPe, STN, SN), beta-power modulation was tested within the corresponding spherical ROIs (Table 1).'],\n",
       "       ['Human Connec-tome Project (WU-Minn HCP)',\n",
       "        'The access to this sample should be directly requested to the Washington University -University of Minnesota Consortium of the Human Connec-tome Project (WU-Minn HCP).'],\n",
       "       ['Request',\n",
       "        'The access to this sample should be directly requested to the Washington University -University of Minnesota Consortium of the Human Connec-tome Project (WU-Minn HCP).'],\n",
       "       ['https://github.com/ferreirafabio80/gfa',\n",
       "        'The GFA models and experiments were implemented in Python 3.9.1 and are available here: https://github.com/ferreirafabio80/gfa.'],\n",
       "       ['Marburg (UKGM)',\n",
       "        'JA 1890/11-1) and the Univer-sity Medical Center Giessen and Marburg (UKGM) (Grant no.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['EGFP (rAAV-retro-AQP1-EGFP)',\n",
       "        'The rAAV2-retro expressing AQP1-EGFP (rAAV-retro-AQP1-EGFP) or EGFP alone (rAAV-retro-EGFP) were constructed and micro-injected into the CPU region. 21 days after infection, the living mouse brain was imaged using the in vivo DWI method.'],\n",
       "       ['AAV-retro-EGFP (Fig. 4 A)',\n",
       "        'No discernable hypointensity MRI contrast was observed in the brain infected with rAAV-retro-EGFP (Fig. 4 A).'],\n",
       "       ['Ctx (cere-bral cortex), BLA (basolateral amygdala), Ins (insular cortex), right Tha (thalamus), right HIP (hippocampus)',\n",
       "        'Hypointensity DWI contrast could be found in multiple brain regions, including the injection site of the right CPU, Ctx (cere-bral cortex), BLA (basolateral amygdala), Ins (insular cortex), right Tha (thalamus), right HIP (hippocampus).'],\n",
       "       ['CPU (Davidsson et al., 2019 ; Tervo et al., 2016)',\n",
       "        'These tracing re-sults are consistent with the reported anatomical connectivity of the CPU (Davidsson et al., 2019 ; Tervo et al., 2016).'],\n",
       "       ['mgh.harvard.edu/fswiki/DownloadAndInstall5.3',\n",
       "        'mgh.harvard.edu/fswiki/DownloadAndInstall5.3) for preprocessing and MSM v2 30–32 (https://www.doc.ic.ac.uk/∼ecr05/MSM_HOCR_v2/) and mapalign (https://github.com/satra/mapalign) for functional alignment.'],\n",
       "       ['https://www.doc.ic.ac.uk/∼ecr05/MSM_HOCR_v2/',\n",
       "        'mgh.harvard.edu/fswiki/DownloadAndInstall5.3) for preprocessing and MSM v2 30–32 (https://www.doc.ic.ac.uk/∼ecr05/MSM_HOCR_v2/) and mapalign (https://github.com/satra/mapalign) for functional alignment.'],\n",
       "       ['https://github.com/satra/mapalign',\n",
       "        'mgh.harvard.edu/fswiki/DownloadAndInstall5.3) for preprocessing and MSM v2 30–32 (https://www.doc.ic.ac.uk/∼ecr05/MSM_HOCR_v2/) and mapalign (https://github.com/satra/mapalign) for functional alignment.'],\n",
       "       ['https://www.github.com/spin-test',\n",
       "        'Matlab 2018 was used for generation of ﬁgures and the spin test (https://www.github.com/spin-test).'],\n",
       "       ['https://www.nitrc.org/projects/MacromolecularMRS/',\n",
       "        'They will be available on the NITRC portal in the “Macromolecular MRS ”project repository (https://www.nitrc.org/projects/MacromolecularMRS/).'],\n",
       "       ['LAB (R2020b, MathWorks, Natick, USA)',\n",
       "        'NeuroImage 264 (2022) 119740 LAB (R2020b, MathWorks, Natick, USA).'],\n",
       "       ['https://doi.org/10.1101/2021.11.22.469500',\n",
       "        ' statement A preprint of this article is published at the BioRxiv preprint server (https://doi.org/10.1101/2021.11.22.469500).'],\n",
       "       ['https://neurovault.org/collections/FBHLSKJX/',\n",
       "        'The unthresholded statistical maps of the fMRI results can be accessed at https://neurovault.org/collections/FBHLSKJX/.'],\n",
       "       ['Kuijf (2021)',\n",
       "        'Kuijf (2021) On most occasions, these three factors (size, accuracy, diversity) can-not be all satisﬁed.'],\n",
       "       ['QSM (Rashid et al., 2021)',\n",
       "        'Although there have been consensus MRI modalities for each CSVD lesion, a small number of studies included additional modalities (e.g., QSM (Rashid et al., 2021) and PD (Ghafaryasl et al., 2012)), that are not commonly available, to improve the performance.'],\n",
       "       ['Mauchly-test (p > 0.05)',\n",
       "        'Both factors and the interaction ‘time x lesion connectivity’ satisﬁed the assumption of sphericity according to the Mauchly-test (p > 0.05).'],\n",
       "       ['LRS (see last three columns of Table 2)',\n",
       "        'As our conclusions are mainly based on longitudinal changes in fMRI activation, we additionally performed correlation analyses between lon-gitudinal changes of fMRI eﬀect sizes and LRS (see last three columns of Table 2).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Request',\n",
       "        'However, they are available on request from the corresponding author.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://biobank.ndph.ox.ac.uk/ukb/docs',\n",
       "        ' The FC endophenotypes are available here : https://biobank.ndph.ox.ac.uk/ukb/docs.cgi?id = 1 with project #64984.'],\n",
       "       ['https://www.ebi.ac.uk/gwas/studies/GCP000274',\n",
       "        'The summury statistics can be accessed via GWAS Cata-log : https://www.ebi.ac.uk/gwas/studies/GCP000274'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['FreeSurfer (V5.3)',\n",
       "        'Structural scans were processed using FreeSurfer (V5.3) (Fischl et al., 2002 ; Fischl et al., 2004).'],\n",
       "       ['Filter-Shift (Parker et al., 2017)',\n",
       "        'Slice timing correction was applied using Filter-Shift (Parker et al., 2017).'],\n",
       "       ['LG-RBSN (He and Razlighi, 2022)',\n",
       "        'Spatial normalization was performed using LG-RBSN (He and Razlighi, 2022).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://micapipe.readthedocs',\n",
       "        ' statement An expandable documentation at https://micapipe.readthedocs.io describes installation, usage, pipeline steps, updates, extra features, and provides a series of ready-to-use tutorials.'],\n",
       "       ['http://bids-apps.neuroimaging',\n",
       "        'Micapipe is delivered as a docker container via BIDS-App [ http://bids-apps.neuroimaging.io/apps/(Gorgolewski et al., 2017)], and available on ReproNim [ https://github.com/ReproNim/containers (Halchenko et al., 2021)].'],\n",
       "       ['https://github',\n",
       "        'Micapipe is delivered as a docker container via BIDS-App [ http://bids-apps.neuroimaging.io/apps/(Gorgolewski et al., 2017)], and available on ReproNim [ https://github.com/ReproNim/containers (Halchenko et al., 2021)].'],\n",
       "       ['Request',\n",
       "        'Material requests will need to be placed with individual prin-cipal investigators.'],\n",
       "       ['Github (https://github.com/BabadiLab/NLGC)',\n",
       "        ' statement A python implementation of the NLGC algorithm is deposited on the open-source repository Github (https://github.com/BabadiLab/NLGC) to facilitate reproducibility and adoption by the neuroimag-ing community.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Dehaene-Lambertz (2019)',\n",
       "        'For example, in Kabdebon and Dehaene-Lambertz (2019) , the background of a target image was ﬂickered at a ﬁxed rate, and the au-thors reported enhanced SS-EPs when the image was expected.'],\n",
       "       ['https://seonjoo.github',\n",
       "        'for statistical evaluations and visualizations can be found here: https://seonjoo.github.io/neural ﬂexibility_submission/.'],\n",
       "       ['https://identiﬁers.org/neurovault.collection:11602.',\n",
       "        'Unthresholded statistical maps are available at https://identiﬁers.org/neurovault.collection:11602.'],\n",
       "       ['https://doi.org/10.7303/syn26712979',\n",
       "        'Norma-tive equations from 8 countries (including z transforms for the 1978 BNS CON/PEM): https://doi.org/10.7303/syn26712979.'],\n",
       "       ['Valdes-Sosa (pedro.valdes@neuroinformatics-collaboratory.org)',\n",
       "        'Valdes-Sosa (pedro.valdes@neuroinformatics-collaboratory.org).'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['Request',\n",
       "        ' statement The 3D US scans used for this work are available from the INTERGROWTH-21 st Consortium upon reasonable request.'],\n",
       "       ['http://crl.med.harvard.edu/research/fetal_brain_atlas/',\n",
       "        '(2017) and is available at http://crl.med.harvard.edu/research/fetal_brain_atlas/.'],\n",
       "       ['https://health.aiaudit.org/web/challenges/challenge-page/337/overview',\n",
       "        'The multi-task multi-label classiﬁcation challenge is hosted here: https://health.aiaudit.org/web/challenges/challenge-page/337/overview.'],\n",
       "       ['https://health.aiaudit.org/web/challenges/challenge-page/338/overview.',\n",
       "        'The multi-target regression benchmark challenge is accessible here: https://health.aiaudit.org/web/challenges/challenge-page/338/overview.'],\n",
       "       ['http://github.com/CBORT-NCBIB/oct-cbort',\n",
       "        ' statement An open-source Python package for reconstruction of conventional OCT tomograms and depth-resolved tissue birefringence is available on http://github.com/CBORT-NCBIB/oct-cbort.'],\n",
       "       ['Request',\n",
       "        'The raw OCT measurements are also available upon request.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://neurovault.org/collections/11009/',\n",
       "        ' Group-level results maps and ROI masks are archived at: https://neurovault.org/collections/11009/.'],\n",
       "       ['N/A', 'N/A'],\n",
       "       ['https://github.com/marietvbuuren/self_other_longitudinal',\n",
       "        '(https://github.com/marietvbuuren/self_other_longitudinal).'],\n",
       "       ['https://github.com/necog-UAM/OMEGA-NaturalFrequencies',\n",
       "        'All scripts necessary to reproduce the analysis and the ﬁgures in this paper are available at https://github.com/necog-UAM/OMEGA-NaturalFrequencies.'],\n",
       "       ['Dandan Zhang (zhangdd05@gmail.com)',\n",
       "        'Dandan Zhang (zhangdd05@gmail.com).'],\n",
       "       ['Dandan Zhang (email: zhangdd05@gmail.com)',\n",
       "        'Dandan Zhang (email: zhangdd05@gmail.com).']], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_other[['dataset', 'dataset_sentence']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f950738",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## URL extract \n",
    "\n",
    "Based on the results in the groundtruth exploration, 75 % of the datasets were mentioned with links. That will be the method of extraction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b194164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlextract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45966184",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### SENTENCES ################################################\n",
    "def split_text_into_sentences(text):\n",
    "    \"\"\"This function splits a given text into sentences based on a regular expression pattern. \n",
    "    It uses re.split() to identify sentence boundaries, considering common sentence-ending \n",
    "    punctuation like \".\", \"!\", or \"?\". It avoids splitting sentences if a digit immediately \n",
    "    follows the punctuation, e.g., 'Fig. 1'. \n",
    "    \n",
    "    Parameters: \n",
    "    :param text(str): \n",
    "    \n",
    "    Returns: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    sentence_pattern = r'(?<=[.!?])\\s+(?![0-9]+\\s)'\n",
    "    sentences = re.split(sentence_pattern, text)\n",
    "    return sentences\n",
    "\n",
    "############### CAPITALIZED ################################################\n",
    "def extract_capitalized_words(text):\n",
    "    \"\"\"This function detects and extracts capitalized words and DOIs from a text. \n",
    "    It also includes capitalized words followed by parentheses. e.g., \"In this sentence \n",
    "    Dataset Example (www.linktodataset.com) would be extracted\" returns \n",
    "    \"Dataset Example (www.linktodataset.com)\"\n",
    "    \n",
    "    Parameters: \n",
    "    :param text(str): \n",
    "    \n",
    "    Returns: \n",
    "    :return: all capitalized words  \n",
    "    \"\"\"\n",
    "    pattern = r'([A-Z][a-zA-Z\\-]+(?:\\s+[A-Z][a-zA-Z\\-]+)*(?:\\s*\\(.*?\\)))|(doi:\\s*10\\.\\d+/\\S+)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # Filter out empty strings from the matches\n",
    "    non_empty_matches = [match for match in matches if match[0] or match[1]]\n",
    "    # Extract the non-empty matches into a list\n",
    "    extracted_words = [match[0] if match[0] else match[1] for match in non_empty_matches]\n",
    "    \n",
    "    return extracted_words\n",
    "\n",
    "############### LINKS ################################################\n",
    "def extract_links(text): \n",
    "    # Create an instance of the URLExtract class\n",
    "    extractor = urlextract.URLExtract()\n",
    "\n",
    "    urls = []\n",
    "    for url in extractor.gen_urls(text):\n",
    "        urls.append(url)\n",
    "        \n",
    "    return urls \n",
    "\n",
    "############### DATASETS ################################################\n",
    "def get_datasets(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Initialize lists to store extracted datasets and their corresponding sentences\n",
    "    extracted_datasets = []\n",
    "    dataset_sentences = []\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = split_text_into_sentences(text)\n",
    "    \n",
    "    # Extract links and capitalized words\n",
    "    links = extract_links(text)\n",
    "    capitalized_words = extract_capitalized_words(text)    \n",
    "    \n",
    "    for sentence in sentences:\n",
    "        datasets_in_sentence = []\n",
    "        \n",
    "        # Check if the sentence contains any capitalized words or DOIs \n",
    "        for cap_word in capitalized_words:\n",
    "            if cap_word in sentence:\n",
    "                datasets_in_sentence.append(cap_word)\n",
    "        \n",
    "        # Check if the sentence contains a link\n",
    "        for link in links:\n",
    "            if link in sentence:\n",
    "                # Check if the link is already captured as a capitalized word in the same sentence\n",
    "                if not any(link in cap_word for cap_word in capitalized_words):\n",
    "                    datasets_in_sentence.append(link)\n",
    "        \n",
    "        # Check if the sentence contains the word \"request\"\n",
    "        if \"request\" in sentence.lower():\n",
    "            datasets_in_sentence.append(\"Request\")\n",
    "        \n",
    "        if datasets_in_sentence:\n",
    "            # If any datasets were found in the sentence, add them and the sentence itself\n",
    "            extracted_datasets.extend(datasets_in_sentence)\n",
    "            dataset_sentences.extend([sentence] * len(datasets_in_sentence))\n",
    "    \n",
    "    # If no dataset was found, return None\n",
    "    if not extracted_datasets:\n",
    "        return None\n",
    "    \n",
    "    #df = pd.DataFrame({'dataset': extracted_datasets, 'dataset_sentence': dataset_sentences})\n",
    "    #return df\n",
    "\n",
    "    return extracted_datasets, dataset_sentences\n",
    "\n",
    "\n",
    "###############\n",
    "def extract_and_add_datasets(row, text_column):\n",
    "    \"\"\"This function needs a description \n",
    "    \n",
    "    Parameters: \n",
    "    :param row: \n",
    "    :param text_column: \n",
    "    \n",
    "    Returns: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    result = get_datasets(row[text_column])\n",
    "    \n",
    "    if result is None:\n",
    "        return None\n",
    "    \n",
    "    if len(result) == 2:\n",
    "        datasets, sentences = result\n",
    "    else:\n",
    "        # Handle the case where get_datasets didn't return the expected two values\n",
    "        datasets, sentences = [\"N/A\"], [\"N/A\"]\n",
    "    \n",
    "    rows_list = []\n",
    "    for dataset, sentence in zip(datasets, sentences):\n",
    "        new_row = row.copy()\n",
    "        new_row['dataset'] = dataset\n",
    "        new_row['dataset_sentence'] = sentence\n",
    "        rows_list.append(new_row)\n",
    "    \n",
    "    return rows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a25b85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the rows\n",
    "rows_list = []\n",
    "# Column name to use for text extraction\n",
    "text_column = 'Section_wo_pattern'\n",
    "\n",
    "# Iterate through each row of the original DataFrame\n",
    "for index, row in validation_set.iterrows():\n",
    "    # Call the custom function to extract datasets and add new rows\n",
    "    new_rows = extract_and_add_datasets(row, text_column)\n",
    "    \n",
    "    # Append the new rows to the list\n",
    "    rows_list.extend(new_rows)\n",
    "\n",
    "# Create the final DataFrame from the list of rows\n",
    "validation_df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f145255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "      <th>Matched_pattern</th>\n",
       "      <th>Start_pattern</th>\n",
       "      <th>End_pattern</th>\n",
       "      <th>Start_pattern_clean</th>\n",
       "      <th>Section_wo_pattern</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "      <td>Data and code availability Original data was o...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(73770, 73799), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(488, 526), match=' \\nD...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "      <td>Human Connectome Project (1U54MH091657, PIs Va...</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "      <td>Data and code availability Original data was o...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(73770, 73799), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(488, 526), match=' \\nD...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "      <td>Allen Hu-man Brain Atlas (http://human.brain-m...</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119526</td>\n",
       "      <td>Data and code availability Original data was o...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(73770, 73799), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(488, 526), match=' \\nD...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Original data was obtained from the Human Con...</td>\n",
       "      <td>https://github.com/jbrown81/gradients.</td>\n",
       "      <td>All code (latent space derivation, dynamical s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/gazx2/,</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/eucqf/,</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/thsqg/and</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/bndjg/.</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119443</td>\n",
       "      <td>Data and code availability statement EEG datas...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(22317, 22347), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(312, 331), match=' \\nA...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>statement EEG datasets used to create the ﬁgu...</td>\n",
       "      <td>osf.io/guwnm/.</td>\n",
       "      <td>Code used to reproduce the plots in Fig. 1 , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119240</td>\n",
       "      <td>Data availability statement Data used in this ...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(59756, 59777), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(130, 169), match='  \\n...</td>\n",
       "      <td>Data availability</td>\n",
       "      <td>statement Data used in this study are availab...</td>\n",
       "      <td>Request</td>\n",
       "      <td>statement Data used in this study are availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119050</td>\n",
       "      <td>Data and code availability Raw EEG data from a...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(37690, 37718), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(172, 177), match=' \\n3...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Raw EEG data from all healthy individuals, as...</td>\n",
       "      <td>doi: 10.5281/zenodo.6110595).</td>\n",
       "      <td>Raw EEG data from all healthy individuals, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119050</td>\n",
       "      <td>Data and code availability Raw EEG data from a...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(37690, 37718), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(172, 177), match=' \\n3...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>Raw EEG data from all healthy individuals, as...</td>\n",
       "      <td>zenodo.org</td>\n",
       "      <td>Raw EEG data from all healthy individuals, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118854</td>\n",
       "      <td>Data and code availability The data used in th...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(44928, 44956), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(548, 565), match=' Eth...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>The data used in this study was downloaded fr...</td>\n",
       "      <td>https://www.humanconnectome.org/study/hcp-youn...</td>\n",
       "      <td>The data used in this study was downloaded fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118854</td>\n",
       "      <td>Data and code availability The data used in th...</td>\n",
       "      <td>(?&lt;![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...</td>\n",
       "      <td>&lt;re.Match object; span=(44928, 44956), match='...</td>\n",
       "      <td>&lt;re.Match object; span=(548, 565), match=' Eth...</td>\n",
       "      <td>Data and code availability</td>\n",
       "      <td>The data used in this study was downloaded fr...</td>\n",
       "      <td>https://github.com/ferreirafabio80/gfa.</td>\n",
       "      <td>The GFA models and experiments were implemente...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DOI  \\\n",
       "302  10.1016/j.neuroimage.2022.119526   \n",
       "302  10.1016/j.neuroimage.2022.119526   \n",
       "302  10.1016/j.neuroimage.2022.119526   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "355  10.1016/j.neuroimage.2022.119443   \n",
       "437  10.1016/j.neuroimage.2022.119240   \n",
       "583  10.1016/j.neuroimage.2022.119050   \n",
       "583  10.1016/j.neuroimage.2022.119050   \n",
       "716  10.1016/j.neuroimage.2021.118854   \n",
       "716  10.1016/j.neuroimage.2021.118854   \n",
       "\n",
       "                                               Section  \\\n",
       "302  Data and code availability Original data was o...   \n",
       "302  Data and code availability Original data was o...   \n",
       "302  Data and code availability Original data was o...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "355  Data and code availability statement EEG datas...   \n",
       "437  Data availability statement Data used in this ...   \n",
       "583  Data and code availability Raw EEG data from a...   \n",
       "583  Data and code availability Raw EEG data from a...   \n",
       "716  Data and code availability The data used in th...   \n",
       "716  Data and code availability The data used in th...   \n",
       "\n",
       "                                       Matched_pattern  \\\n",
       "302  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "302  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "302  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "355  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "437  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "583  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "583  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "716  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "716  (?<![\\'\"]) \\s*?\\n?Data\\s+and\\s+code\\s+availabi...   \n",
       "\n",
       "                                         Start_pattern  \\\n",
       "302  <re.Match object; span=(73770, 73799), match='...   \n",
       "302  <re.Match object; span=(73770, 73799), match='...   \n",
       "302  <re.Match object; span=(73770, 73799), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "355  <re.Match object; span=(22317, 22347), match='...   \n",
       "437  <re.Match object; span=(59756, 59777), match='...   \n",
       "583  <re.Match object; span=(37690, 37718), match='...   \n",
       "583  <re.Match object; span=(37690, 37718), match='...   \n",
       "716  <re.Match object; span=(44928, 44956), match='...   \n",
       "716  <re.Match object; span=(44928, 44956), match='...   \n",
       "\n",
       "                                           End_pattern  \\\n",
       "302  <re.Match object; span=(488, 526), match=' \\nD...   \n",
       "302  <re.Match object; span=(488, 526), match=' \\nD...   \n",
       "302  <re.Match object; span=(488, 526), match=' \\nD...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "355  <re.Match object; span=(312, 331), match=' \\nA...   \n",
       "437  <re.Match object; span=(130, 169), match='  \\n...   \n",
       "583  <re.Match object; span=(172, 177), match=' \\n3...   \n",
       "583  <re.Match object; span=(172, 177), match=' \\n3...   \n",
       "716  <re.Match object; span=(548, 565), match=' Eth...   \n",
       "716  <re.Match object; span=(548, 565), match=' Eth...   \n",
       "\n",
       "            Start_pattern_clean  \\\n",
       "302  Data and code availability   \n",
       "302  Data and code availability   \n",
       "302  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "355  Data and code availability   \n",
       "437           Data availability   \n",
       "583  Data and code availability   \n",
       "583  Data and code availability   \n",
       "716  Data and code availability   \n",
       "716  Data and code availability   \n",
       "\n",
       "                                    Section_wo_pattern  \\\n",
       "302   Original data was obtained from the Human Con...   \n",
       "302   Original data was obtained from the Human Con...   \n",
       "302   Original data was obtained from the Human Con...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "355   statement EEG datasets used to create the ﬁgu...   \n",
       "437   statement Data used in this study are availab...   \n",
       "583   Raw EEG data from all healthy individuals, as...   \n",
       "583   Raw EEG data from all healthy individuals, as...   \n",
       "716   The data used in this study was downloaded fr...   \n",
       "716   The data used in this study was downloaded fr...   \n",
       "\n",
       "                                               dataset  \\\n",
       "302  Human Connectome Project (1U54MH091657, PIs Va...   \n",
       "302  Allen Hu-man Brain Atlas (http://human.brain-m...   \n",
       "302             https://github.com/jbrown81/gradients.   \n",
       "355                                     osf.io/gazx2/,   \n",
       "355                                     osf.io/eucqf/,   \n",
       "355                                   osf.io/thsqg/and   \n",
       "355                                     osf.io/bndjg/.   \n",
       "355                                     osf.io/guwnm/.   \n",
       "437                                            Request   \n",
       "583                      doi: 10.5281/zenodo.6110595).   \n",
       "583                                         zenodo.org   \n",
       "716  https://www.humanconnectome.org/study/hcp-youn...   \n",
       "716            https://github.com/ferreirafabio80/gfa.   \n",
       "\n",
       "                                      dataset_sentence  \n",
       "302   Original data was obtained from the Human Con...  \n",
       "302   Original data was obtained from the Human Con...  \n",
       "302  All code (latent space derivation, dynamical s...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355   statement EEG datasets used to create the ﬁgu...  \n",
       "355  Code used to reproduce the plots in Fig. 1 , a...  \n",
       "437   statement Data used in this study are availab...  \n",
       "583   Raw EEG data from all healthy individuals, as...  \n",
       "583   Raw EEG data from all healthy individuals, as...  \n",
       "716   The data used in this study was downloaded fr...  \n",
       "716  The GFA models and experiments were implemente...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d71275cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://human.brain-map.org/\n",
      "https://github.com/jbrown81/gradients.\n",
      "osf.io/gazx2/,\n",
      "osf.io/eucqf/,\n",
      "osf.io/thsqg/and\n",
      "osf.io/bndjg/.\n",
      "osf.io/guwnm/.\n",
      "zenodo.org\n",
      "https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation\n",
      "https://github.com/ferreirafabio80/gfa.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the URLExtract class\n",
    "extractor = urlextract.URLExtract()\n",
    "\n",
    "text_column = validation_set['Section_wo_pattern']\n",
    "\n",
    "# Iterate through each cell in the text_column\n",
    "for text in text_column:\n",
    "    # Use the gen_urls function to extract URLs from the text\n",
    "    for url in extractor.gen_urls(text):\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ed269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdae644d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5b64e",
   "metadata": {},
   "source": [
    "<a name='othersectionpatterns'></a>\n",
    "### 1.3.2. Other section patterns\n",
    "The other section patterns: \n",
    "\n",
    "  (r'\\n?2\\.1\\.', r'\\n?2\\.2. | \\n\\n '),\n",
    "    (r'\\n?Resource | \\n?3\\.1\\.\\s*?\\n?', r'\\n?3\\.2.\\s*?| \\s*?\\n\\n '),\n",
    "    (r'\\n?Introduction\\s*?\\n? | \\s*?\\n?1\\.\\s*?\\n? ', r'\\s*?\\n?2\\.\\s*?\\n? | \\s*?\\n\\n '),\n",
    "    (r'\\n?Fig\\.\\d+ | \\n?Fig\\.\\d+\\.? | \\n?Figure \\d+', r'https?://[^\\s]+ | \\s*?\\n\\n '),\n",
    "    (r'\\n?Tab\\.\\d+ | \\n?Table \\d+\\.?', r'https?://[^\\s]+ | [\\w\\s-]+\\d{4} | \\s*?\\n\\n '),\n",
    "    (r'\\n?Abstract\\s*?\\n? | \\s*?\\n?1\\.\\s*?\\n? ', r'\\n?Introduction\\s*?\\n? | \\s*?\\n\\n ')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2c72f",
   "metadata": {},
   "source": [
    "### 1.3.3. Validate code \n",
    "In the code-file 'articles_groundtruth_v2.ipynb', I manually extracted datasets from ten articles. I will now use these ten articles to validate the code I have written so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80e58bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (1381813082.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [52]\u001b[0;36m\u001b[0m\n\u001b[0;31m    'DOI': '10.1016/j.neuroimage.2021.118839',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "        'DOI': '10.1016/j.neuroimage.2021.118839',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119030',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119050',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119240',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119443',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119526',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119549',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119646',\n",
    "        'DOI': '10.1016/j.neuroimage.2022.119676',\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a58a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34fcfc09",
   "metadata": {},
   "source": [
    "# Save datasets \n",
    "\n",
    "- Store the extracted datasets for further analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac298936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be94c596",
   "metadata": {},
   "source": [
    "# X. References\n",
    "\n",
    "- Akkoç, A. (2023). PublicDatasets [Jupyter Notebook]. https://github.com/madprogramer/PublicDatasets (Original work published 2022)\n",
    "- Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
