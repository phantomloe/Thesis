{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169e72f4-45b1-4e88-aa5d-0ff254c06599",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "- [Setup](#setup)\n",
    "    - [Purpose](#purpose)\n",
    "    - [Libraries](#libraries)\n",
    "- [40 random research papers](#40randomresearchpapers)\n",
    "\n",
    "<a name='setup'></a>\n",
    "# 0. Setup  \n",
    "\n",
    "<a name='purpose'></a>\n",
    "## 0.1. Purpose  \n",
    "\n",
    "The purpose of this notebook is following: \n",
    "\n",
    "The following steps are performed: \n",
    "- Randomly select 40 articles to be manually labelled\n",
    "- Gather the extracted URLs and sentences (this is done in 'Code/datasets_v5.ipynb')\n",
    "- The sentences are manually coded by three people\n",
    "- Gather the manually coded data\n",
    "    - Investigate inter-labeller agreement\n",
    "    - Save most-agreed-upon label for each sentence\n",
    "- Fine-tune SciBERT (this is done in 'Code/datasets_v5.ipynb')\n",
    "\n",
    "<a name='libraries'></a>\n",
    "## 0.2. Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47db2c53-65ac-4e62-b599-c6284356a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json \n",
    "import os \n",
    "import re \n",
    "import io\n",
    "\n",
    "# Random \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e771eb6-bb2e-4f23-8796-4dfe587c51f2",
   "metadata": {},
   "source": [
    "# Groundtruth articles \n",
    "I need to get the list of groundtruth research papers to make sure I do not select them for manual labelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ffdb61-db16-49ee-9a1f-22086eb3602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the 'Label' directory\n",
    "groundtruth_path = os.path.join(os.pardir, 'Data/articles_groundtruth_urls_and_sentences.csv')\n",
    "groundtruth_articles = pd.read_csv(groundtruth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be340d08-ec7e-459f-aa45-4a4d7876ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_dois = groundtruth_articles['DOI'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08115670-7650-4a3a-94f6-a45b69630d00",
   "metadata": {},
   "source": [
    "<a name='40randomresearchpapers'></a>\n",
    "# 40 random research papers \n",
    "I want to manually label the sentences containing URLs from 40 randomly selected research papers. First, I need to get the research papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e164611-02fa-4ab6-a36e-3c185def2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_dois(json_file_path, num_samples, dois_to_exclude=None, random_seed=42):\n",
    "    \"\"\"\n",
    "    Get a list of random DOIs from a JSON file while ensuring that they are not in the groundtruth DOI list.\n",
    "\n",
    "    Parameters:\n",
    "    json_file_path (str): The path to the JSON file containing DOI data.\n",
    "    num_samples (int): The number of random DOIs to sample.\n",
    "    dois_to_exclude (list, optional): A list of DOIs to exclude from the random sampling. Default is None.\n",
    "    random_seed (int, optional): Seed for the random number generator for reproducibility. Default is 42.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of unique random DOIs not in the groundtruth DOI list.\n",
    "    \"\"\"\n",
    "    # Set the random seed for reproducibility\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # Load the DOI data from the JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        doi_data = json.load(json_file)\n",
    "        doi_list = doi_data['DOIs']\n",
    "\n",
    "    doi_list = [doi for doi in doi_list if doi not in groundtruth_dois]\n",
    "\n",
    "    # Ensure the number of requested samples does not exceed available DOIs\n",
    "    num_samples = min(num_samples, len(doi_list))\n",
    "\n",
    "    # Get a sample of DOIs\n",
    "    random_dois = random.sample(doi_list, num_samples)\n",
    "\n",
    "    return random_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bdae6ee-97be-4e80-88db-b3b4df58f97e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10.1016/j.neuroimage.2022.119290',\n",
       " '10.1016/j.neuroimage.2022.118980',\n",
       " '10.1016/j.neuroimage.2022.119191',\n",
       " '10.1016/j.neuroimage.2022.119140',\n",
       " '10.1016/j.neuroimage.2022.119203',\n",
       " '10.1016/j.neuroimage.2022.119494',\n",
       " '10.1016/j.neuroimage.2022.119708',\n",
       " '10.1016/j.neuroimage.2022.119245',\n",
       " '10.1016/j.neuroimage.2022.119418',\n",
       " '10.1016/j.neuroimage.2022.119616',\n",
       " '10.1016/j.neuroimage.2022.118920',\n",
       " '10.1016/j.neuroimage.2022.119122',\n",
       " '10.1016/j.neuroimage.2021.118811',\n",
       " '10.1016/j.neuroimage.2022.119353',\n",
       " '10.1016/j.neuroimage.2022.119094',\n",
       " '10.1016/j.neuroimage.2022.119626',\n",
       " '10.1016/j.neuroimage.2022.119742',\n",
       " '10.1016/j.neuroimage.2022.119135',\n",
       " '10.1016/j.neuroimage.2022.119331',\n",
       " '10.1016/j.neuroimage.2022.119278',\n",
       " '10.1016/j.neuroimage.2021.118798',\n",
       " '10.1016/j.neuroimage.2022.119055',\n",
       " '10.1016/j.neuroimage.2022.119507',\n",
       " '10.1016/j.neuroimage.2022.119642',\n",
       " '10.1016/j.neuroimage.2022.119627',\n",
       " '10.1016/j.neuroimage.2022.119668',\n",
       " '10.1016/j.neuroimage.2022.119528',\n",
       " '10.1016/j.neuroimage.2022.119097',\n",
       " '10.1016/j.neuroimage.2022.119354',\n",
       " '10.1016/j.neuroimage.2022.119164',\n",
       " '10.1016/j.neuroimage.2022.119212',\n",
       " '10.1016/j.neuroimage.2022.119332',\n",
       " '10.1016/j.neuroimage.2022.119116',\n",
       " '10.1016/j.neuroimage.2022.119721',\n",
       " '10.1016/j.neuroimage.2022.118986',\n",
       " '10.1016/j.neuroimage.2022.119200',\n",
       " '10.1016/j.neuroimage.2022.119016',\n",
       " '10.1016/j.neuroimage.2022.119021',\n",
       " '10.1016/j.neuroimage.2022.119513',\n",
       " '10.1016/j.neuroimage.2022.119423']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the JSON file containing DOI values\n",
    "json_file_path = '../Data/ElsevierAPI/downloadedPDFs_info.json'\n",
    "samples = 40\n",
    "\n",
    "# Get 40 random DOIs with a specific random seed (1)\n",
    "random_dois = get_random_dois(json_file_path, samples, groundtruth_dois)\n",
    "\n",
    "random_dois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8675f1d-dd6d-4d6e-9d98-bf6a1d60b3dd",
   "metadata": {},
   "source": [
    "Now, I will save all of the extracted URLs and sentences (which is performed in Code/datasets_v5) to csv, so that the sentences can be labelled manually by a group of annotators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab93577-2f8a-497a-b764-94070c6b13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_filtered_urls = os.path.join(os.pardir, 'Data/articles_filtered_urls.csv')\n",
    "filtered_urls = pd.read_csv(path_filtered_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f1db76-21d1-4e0a-9f14-dcfd4249424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_urls = filtered_urls[filtered_urls['URL'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a522c37-257e-4bd4-b3fe-c05f516c504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_articles = filtered_urls[filtered_urls['DOI'].isin(random_dois)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe5ca787-77e4-43aa-b853-3952ac9b05ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc7f933-21f7-4616-a6c1-ca24544a90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.pardir, 'Data/articles_manually_labelled.txt')\n",
    "\n",
    "with open(path, \"w\") as file:\n",
    "    file.write(random_articles.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c4445-c295-467b-a95f-6b26ceb35064",
   "metadata": {},
   "source": [
    "# Inter-coder agreement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b8070f-d5dc-4b9f-8774-4c6d08845fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the labelled data \n",
    "# How much do they agree? \n",
    "# Save the label most people voted on - if it's four different labels, pick a random \n",
    "# Save the data and use it to finetune SciBERT "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
