DOI,URL,Sentence(s)
10.1016/j.neuroimage.2021.118868,https://github.com/vistalab/vistasoft,"Pre-processed functional data were then analyzed in the vistasoft
software (https://github.com/vistalab/vistasoft)."
10.1016/j.neuroimage.2022.118960,N/A,N/A
10.1016/j.neuroimage.2022.118992,N/A,N/A
10.1016/j.neuroimage.2022.119048,N/A,N/A
10.1016/j.neuroimage.2022.119077,https://www.neurobs.com/,"The stimuli were presented us-
ing NBS Presentation software (https://www.neurobs.com/)."
10.1016/j.neuroimage.2022.119077,http://neuroimage.usc.edu/brainstorm,"Brainstorm is documented and
freely available for download under GNU general public license
(http://neuroimage.usc.edu/brainstorm)."
10.1016/j.neuroimage.2022.119077,https://neuroimage.usc.edu/brainstorm/Introduction,"The data presented in this manuscript were acquired as part
of an ongoing longitudinal study of dyslexia (2018–2023). Some
data derivatives will be made available after completion of the
study by contacting the senior author (UG) of the study. The
analysis was performed in MATLAB using Brainstorm toolbox
https://neuroimage.usc.edu/brainstorm/Introduction and Brain Con-
nectivity toolbox https://sites.google.com/site/bctnet/home."
10.1016/j.neuroimage.2022.119077,https://sites.google.com/site/bctnet/home,"The data presented in this manuscript were acquired as part
of an ongoing longitudinal study of dyslexia (2018–2023). Some
data derivatives will be made available after completion of the
study by contacting the senior author (UG) of the study. The
analysis was performed in MATLAB using Brainstorm toolbox
https://neuroimage.usc.edu/brainstorm/Introduction and Brain Con-
nectivity toolbox https://sites.google.com/site/bctnet/home."
10.1016/j.neuroimage.2022.119199,https://civmvoxport.vm.duke.edu upon request,"The diffusion MRI met-
rics are available from: https://civmvoxport.vm.duke.edu upon request."
10.1016/j.neuroimage.2022.119199,https://www.mrtrix.org/,"To validate the fiber orientation distribution at each voxel for the brain,
the constrained spherical deconvolution (CSD) method provided by MR-
Trix3 (https://www.mrtrix.org/) was also performed with a maximum
harmonic order of 6."
10.1016/j.neuroimage.2022.119199,https://connectivity.brain-map.org/,"The
tracer injection and projection density images were downloaded from
AMBA (25 μm resolution) (https://connectivity.brain-map.org/) and
converted to NIFTI format."
10.1016/j.neuroimage.2022.119294,https://osf.io/8weum/,"All result files and
analysis scripts pertaining to this study are available via an OSF repos-
itory (https://osf.io/8weum/)."
10.1016/j.neuroimage.2022.119294,https://github.com/ViCCo-Group/frrsa,"The toolbox to run FR-RSA in Python is
available via GitHub (https://github.com/ViCCo-Group/frrsa)."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/study/show/mDBP0,"The data for this
study are available at the BALSA neuroimaging study results database
(https://balsa.wustl.edu/study/show/mDBP0; Van Essen et al., 2017),
and a link to each figure’s specific data is provided in the legend. "
10.1016/j.neuroimage.2022.119360,https://github.com/Washington-University/HCPpipelines,"The
methods presented in this study will be released as an HCP Pipeline
(https://github.com/Washington-University/HCPpipelines)."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/PrBrK,"Methods sections 2.2 and 2.3 describe the participants and data
and preprocessing is described in methods sections 2.6 and 2.7. https://balsa.wustl.edu/PrBrK."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/1BgBP,"Methods
sections 2.2 and 2.3 describe the participants and data and preprocessing is described in methods sections 2.6 and 2.7. https://balsa.wustl.edu/1BgBP."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/5XqXP,"Methods sections 2.2 and 2.3 describe the participants and data, preprocessing is described in methods sections 2.6 and 2.7, and
the analyses are described in methods sections 2.10 and 2.11. https://balsa.wustl.edu/5XqXP."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/g767V.,"Methods sections 2.2 and 2.4 describe the participants and data, and preprocessing is described in methods sections 2.6 and 2.8.
https://balsa.wustl.edu/g767V."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/Mxnx8,"Methods sections 2.2 and 2.4 describe the participants and data, preprocessing is described in methods
sections 2.6 and 2.8, and the analyses are described in methods sections 2.10 and 2.11. https://balsa.wustl.edu/Mxnx8."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/B494V,"Methods sections 2.2 and 2.4 describe the participants and data, and
preprocessing is described in methods sections 2.6 and 2.8. https://balsa.wustl.edu/B494V."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/lLMLp,"The data on the right were corrected with the I-T cost function (Eq. 7). Methods sections 2.2 and
2.4 describe the participants and data, and preprocessing is described in methods sections 2.6 and 2.8. https://balsa.wustl.edu/lLMLp"
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/qNwNZ,"Methods sections 2.2 and 2.4 describe the participants and data, preprocessing is described in
methods sections 2.6 and 2.8, and the analyses are described in methods sections 2.10 and 2.11. https://balsa.wustl.edu/qNwNZ."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/jjnjZ.,"Methods sections 2.2 and 2.5 describe the participants and data, and preprocessing is described in methods sections 2.6 and 2.9. https://balsa.wustl.
edu/jjnjZ."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/wNzNZ,"Methods sections 2.2 and 2.5 describe the participants and data, and
preprocessing is described in methods sections 2.6 and 2.9. https://balsa.wustl.edu/wNzNZ."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/4mlml,"Methods sections 2.2 and 2.5 describe the participants and data, and preprocessing is described in methods sections 2.6 and 2.9 https://balsa.wustl.edu/4mlml."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/mDBD3,"Methods
sections 2.2 and 2.3 describe the participants and data, and preprocessing is described in methods sections 2.6., 2.7, and 2.13. https://balsa.wustl.edu/mDBD3.
Corresponding uncorrected data is available in the BALSA scene."
10.1016/j.neuroimage.2022.119360,https://balsa.wustl.edu/study/show/mDBP0,"The study results data from this manuscript are already
available in the BALSA neuroimaging study results database:
https://balsa.wustl.edu/study/show/mDBP0."
10.1016/j.neuroimage.2022.119360,https://db.humanconnectome.org/,"The raw HCP-YA data
are available in ConnectomeDB (https://db.humanconnectome.org/)
or Amazon Public Datasets (https://registry.opendata.aws/hcp-
openaccess; https://wiki.humanconnectome.org/display/PublicData/
How+To+Connect+to+Connectome+Data+via+AWS). "
10.1016/j.neuroimage.2022.119360,https://registry.opendata.aws/hcp-openaccess,"The raw HCP-YA data
are available in ConnectomeDB (https://db.humanconnectome.org/)
or Amazon Public Datasets (https://registry.opendata.aws/hcp-
openaccess; https://wiki.humanconnectome.org/display/PublicData/
How+To+Connect+to+Connectome+Data+via+AWS). "
10.1016/j.neuroimage.2022.119360,https://wiki.humanconnectome.org/display/PublicData/How+To+Connect+to+Connectome+Data+via+AWS,"The raw HCP-YA data
are available in ConnectomeDB (https://db.humanconnectome.org/)
or Amazon Public Datasets (https://registry.opendata.aws/hcp-
openaccess; https://wiki.humanconnectome.org/display/PublicData/
How+To+Connect+to+Connectome+Data+via+AWS). "
10.1016/j.neuroimage.2022.119360,https://nda.nih.gov/general-query.html?q=query=featured-datasets:HCP\04520Aging\04520and\04520Development,"The raw
HCD and HCA data are available in the NDA (https://nda.nih.gov/
general-query.html?q=query=featured-datasets:HCP%20Aging%20and
%20Development). "
10.1016/j.neuroimage.2022.119360,https://github.com/Washington-University/HCPpipelines,"The code will be made available as a part of the HCP
Pipelines (https://github.com/Washington-University/HCPpipelines)
when the various analysis streams presented here (currently existing
as 3 separate pipelines) are integrated into a single multi-functional
pipeline to make this approach easier for users to use."
10.1016/j.neuroimage.2022.119742,https://db.humanconnectome.org,"The data used in this study for inference and benchmarking
are open-source: HCP (https://db.humanconnectome.org), HBN
(http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/
sharing.html), and PNC (https://www.ncbi.nlm.nih.gov/projects/gap/
cgi-bin/study.cgi?study_id=phs000607.v3.p2). "
10.1016/j.neuroimage.2022.119742,"http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/
sharing.html","The data used in this study for inference and benchmarking
are open-source: HCP (https://db.humanconnectome.org), HBN
(http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/
sharing.html), and PNC (https://www.ncbi.nlm.nih.gov/projects/gap/
cgi-bin/study.cgi?study_id=phs000607.v3.p2). "
10.1016/j.neuroimage.2022.119742,"https://www.ncbi.nlm.nih.gov/projects/gap/
cgi-bin/study.cgi?study_id=phs000607.v3.p2","The data used in this study for inference and benchmarking
are open-source: HCP (https://db.humanconnectome.org), HBN
(http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/
sharing.html), and PNC (https://www.ncbi.nlm.nih.gov/projects/gap/
cgi-bin/study.cgi?study_id=phs000607.v3.p2). "
10.1016/j.neuroimage.2022.119742,"http://fcon_1000.projects.nitrc.org/indi/retro/.
yale_hires.html","The Yale data used in
this study to construct edge-centric networks are open-source and
available here: http://fcon_1000.projects.nitrc.org/indi/retro/
yale_hires.html."
10.1016/j.neuroimage.2022.119769,http://surfer.nmr.mgh.harvard.edu,"The resulting map was
registered to Talairach space and visualized using FreeSurfer (version
6.0, http://surfer.nmr.mgh.harvard.edu)."
10.1016/j.neuroimage.2022.119769,https://github.com/brainneuro/Multi- Face-attribution,"Python and matlab codes for training the CNN models and
analysis are available at https://github.com/brainneuro/Multi-
Face-attribution."