DOI,URL,Sentence,Class
10.1016/j.neuroimage.2021.118839,http://neuroimage.usc.edu/brainstorm,"Subsequently the results were loaded in a Matlab Tool Box, Brainstorm (Tadel et al. 2011), an accredited software freely available for download online under the GNU general public license (http://neuroimage.usc.edu/brainstorm).",Code
10.1016/j.neuroimage.2021.118854,https://www.humanconnectome.org/study/hcp-young-adult/data-releases,"We applied our GFA extension to the publicly available resting-state functional MRI (rs-fMRI) and non-imaging measures (e.g., demograph-ics, psychometrics and other behavioural measures) obtained from 1003 subjects (only these had rs-fMRI data available) of the 1200-subject data release of the HCP (https://www.humanconnectome.org/study/hcp-young-adult/data-releases).",Data
10.1016/j.neuroimage.2021.118854,https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation,The data used in this study was downloaded from the Human Connectome Project website (https://www.humanconnectome.org/study/hcp-young-adult/document/extensively-processed-fmri-data-documentation).,Data
10.1016/j.neuroimage.2021.118854,https://github.com/ferreirafabio80/gfa,The GFA models and experiments were implemented in Python 3.9.1 and are available here: https://github.com/ferreirafabio80/gfa.,Code
10.1016/j.neuroimage.2022.119030,marmosetbrainconnectome.org,"To accelerate such progress, we present the Marmoset Functional Brain Connectivity Resource (marmosetbrainconnectome.org), currently consisting of over 70 h of resting-state fMRI (RS-fMRI) data acquired at 500 μm isotropic resolution from 31 fully awake marmosets in a common stereotactic space.""",Data
10.1016/j.neuroimage.2022.119030,https://www.marmosetbrainconnectome.org/download.html,"(B) The data download page (https://www.marmosetbrainconnectome.org/download.html) allows the user to download all raw (BIDS standard formated) (Gorgolewski et al., 2016) and pre-processed data.",Data
10.1016/j.neuroimage.2022.119030,https://rii-mango.github.io/Papaya/,"The resource makes use of the Papaya viewer (https://rii-mango.github.io/Papaya/), with several additional features (illustrated in Fig. 1C & D), including (1) calculation of surface over-lay maps on-demand based on the threshold chosen in volume space, (2) the ability to display atlas borders in surface space, (3) support for rotating the underlying volume, overlaying functional connectiv-ity map, and atlas boundaries together – such obliquing of the images can be of utility for presurgical planning, and (4) the ability to choose between group- and subject-level topologies.",Code
10.1016/j.neuroimage.2022.119030,https://gitlab.com/cfmm/marmoset,The development of the Marmoset Functional Connectivity Resource is described in full detail at https://gitlab.com/cfmm/marmoset.,Other
10.1016/j.neuroimage.2022.119030,https://gitlab.com/cfmm/marmoset-connectivity,Users can also download all code used to generate the functional connectivity maps from https://gitlab.com/cfmm/marmoset-connectivity.,Code
10.1016/j.neuroimage.2022.119030,marmosetbrain.org.,"Green labeled ROIs indicate FC data, whereas purple labeled ROIs show where tracer data is publicly available within area TE3 from marmosetbrain.org.",Data
10.1016/j.neuroimage.2022.119050,http://audition.ens.fr/adc/NoiseTools/,"EEG analysis used FieldTrip (Oostenveld et al., 2011), Noise-Tools (De Cheveigne and Parra, 2014; http://audition.ens.fr/adc/NoiseTools/), and custom-written scripts in Matlab.",Code
10.1016/j.neuroimage.2022.119050,zenodo.org,"Raw EEG data from all healthy individuals, as well as Matlab code, are publicly available on zenodo.org (doi:10.5281/zenodo.6110595).",
10.1016/j.neuroimage.2022.119240,www.cni.stanford.edu,"MRI data were acquired on a 3T Discovery MR750 scanner (Gen-eral Electric Healthcare, Milwaukee, WI, USA) equipped with a 32-channel head coil (Nova Medical, Wilmington, MA, USA) at the Cen-ter for Cognitive and Neurobiological Imaging at Stanford Univer-sity (www.cni.stanford.edu).",Data
10.1016/j.neuroimage.2022.119240,http://github.com/vistalab/vistasoft/mrDiffusion,"The T1w images were first aligned to the canonical ac-pc orienta-tion. Diffusion weighted images were pre-processed with Vistasoft (http://github.com/vistalab/vistasoft/mrDiffusion), an open-source software package implemented in MATLAB R2012a (Mathworks, Natick, MA).",Code
10.1016/j.neuroimage.2022.119240,http://www.fil.ion.ucl.ac.uk/spm/,"Each diffusion weighted image was registered to the mean of the b=0 images and the mean b=0 image was registered automatically to the participant’s T1w image, using a rigid body transformation (imple-mented in SPM8, http://www.fil.ion.ucl.ac.uk/spm/; no warping was applied).",Code
10.1016/j.neuroimage.2022.119240,https://github.com/mezera/mrQ,"Quantitative T1 (relaxation time, seconds) maps were calculated us-ing mrQ, (https://github.com/mezera/mrQ), an open-source software package implemented in MATLAB R2012a (Mathworks, Natick, MA).",Code
10.1016/j.neuroimage.2022.119240,https://github.jyeatman/AFQ,"Automated Fiber Quantification (AFQ; https://github.jyeatman/ AFQ; (Yeatman, Dougherty, Myall, et al., 2012)), a software package implemented in MATLAB R2012a (Mathworks, Natick, MA), was used to isolate and characterize white matter metrics from three dorsal tracts (Arc-L and bilateral SLF) and four ventral white matter tracts (bilat-eral ILF and bilateral UF).",Code
10.1016/j.neuroimage.2022.119443,osf.io/gazx2/,"EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.",Data
10.1016/j.neuroimage.2022.119443,osf.io/eucqf/,"EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.",Data
10.1016/j.neuroimage.2022.119443,osf.io/thsqg/,"EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.",Data
10.1016/j.neuroimage.2022.119443,osf.io/bndjg/,"EEG datasets used to create the figure in this commentary are freely available at osf.io/gazx2/, osf.io/eucqf/, osf.io/thsqg/ and osf.io/bndjg/.",Data
10.1016/j.neuroimage.2022.119443,osf.io/guwnm/,"Code used to reproduce the plots in Fig. 1, as well as averaged ERP data, is available from osf.io/guwnm/.",Code
10.1016/j.neuroimage.2022.119526,https://db.humanconnectome.org/data/projects/HCP_1200,200 unrelated subjects were selected from the Human Con-nectome Project (HCP) 1200 Subjects Data Release with avail-able resting (task-free) and task fMRI data from a 3T MRI scan-ner (https://db.humanconnectome.org/data/projects/HCP_1200).,Data
10.1016/j.neuroimage.2022.119526,https://www.humanconnectome.org/study/hcp-young-adult/document/wu-minn-hcp-consortium-open-access-data-use-terms,This study agreed to the Open Access Data Use Terms (https://www.humanconnectome.org/study/hcp-young-adult/document/wu-minn-hcp-consortium-open-access-data-use-terms) and was exempt from the UCSF IRB because investigators could not readily ascertain the identities of the individuals to whom the data belonged.,Other
10.1016/j.neuroimage.2022.119526,https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/,We used FSL (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/) and AFNI (https://afni.nimh.nih.gov/) for additional fMRI preprocessing.,Code
10.1016/j.neuroimage.2022.119526,https://afni.nimh.nih.gov/,We used FSL (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/) and AFNI (https://afni.nimh.nih.gov/) for additional fMRI preprocessing.,Code
10.1016/j.neuroimage.2022.119526,http://www.brainnetome.org/,"Maps were averaged within 273 regions of interest by combining a parcella-tion of 210 cortical regions and 36 subcortical regions from the Brainnetome atlas (Fan et al., 2016) (http://www.brainnetome.org/) and 27 cerebellar regions from the SUIT atlas (Diedrichsen, 2006) (http://www.diedrichsenlab.org/imaging/suit.htm).",Data
10.1016/j.neuroimage.2022.119526,http://www.diedrichsenlab.org/imaging/suit.htm,"Maps were averaged within 273 regions of interest by combining a parcella-tion of 210 cortical regions and 36 subcortical regions from the Brainnetome atlas (Fan et al., 2016) (http://www.brainnetome.org/) and 27 cerebellar regions from the SUIT atlas (Diedrichsen, 2006) (http://www.diedrichsenlab.org/imaging/suit.htm).",Data
10.1016/j.neuroimage.2022.119526,https://www.fil.ion.ucl.ac.uk/spm/software/spm12/,Task condition block regressors were convolved with a hemo-dynamic response function using the ‘spm_get_bf’ function in SPM12 (https://www.fil.ion.ucl.ac.uk/spm/software/spm12/).,Code
10.1016/j.neuroimage.2022.119526,https://github.com/rmarkello/abagen,"We compared each gradient map to Allen Human Brain spatial gene expression patterns using the ‘abagen’ package (https://github.com/rmarkello/abagen) (Arnatkevici ̆ūtė et al., 2019; Hawrylycz et al., 2012).",Code
10.1016/j.neuroimage.2022.119526,https://brainsmash.readthedocs.io/en/latest/,These surrogate gradient maps were estimated using BrainSMASH (https://brainsmash.readthedocs.io/en/latest/).,Code
10.1016/j.neuroimage.2022.119526,https://sites.google.com/site/bctnet/,Graph the-ory analyses were run using the Brain Connectivity Toolbox (BCT; https://sites.google.com/site/bctnet/).,Code
10.1016/j.neuroimage.2022.119526,http://human.brain-map.org/,"Original data was obtained from the Human Connectome Project (1U54MH091657, PIs Van Essen and Ugurbil) and the Allen Hu-man Brain Atlas (http://human.brain-map.org/).",Data
10.1016/j.neuroimage.2022.119526,https://github.com/jbrown81/gradients,"All code (latent space derivation, dynamical system modeling, and gene expression corre-lation) and processed data (gradient maps/region weights, gradient timeseries, and region gene expression values) are available at https://github.com/jbrown81/gradients.",Code
10.1016/j.neuroimage.2022.119549,,,
10.1016/j.neuroimage.2022.119646,,,
10.1016/j.neuroimage.2022.119676,https://www.shutterstock.com,"Both experiments employed static images (modified from Shutterstock, https://www.shutterstock.com).",Other
10.1016/j.neuroimage.2022.119676,https://clippingmagic.com,"All image transformations were done with Clipping Magic (https://clippingmagic.com), ImageMagick, GIMP, Microsoft Paint, the MATLAB SHINE toolbox, and custom MATLAB code.",Code
10.1016/j.neuroimage.2022.119676,http://www.nitrc.org/projects/jip,"Functional volumes were realigned and motion-corrected with the Statistical Parametric Mapping software (SPM12, RRID: SCR_007037), followed by non-rigid co-registration (using JIP, http://www.nitrc.org/projects/jip, RRID: SCR_009588) to the high-resolution anatomical template of the skull-stripped brain of each monkey.",Other
10.1016/j.neuroimage.2022.119676,https://caffe.berkeleyvision.org/model_zoo.html,Another version of pre-trained AlexNet was im-ported from Caffe Model Zoo (https://caffe.berkeleyvision.org/model_zoo.html).,Unsure
10.1016/j.neuroimage.2022.119676,https://osf.io/b8pfa/?view_only=b6dbb5dd6a044989a7eecdc99facb43c,Preprocessed fMRI data are available at https://osf.io/b8pfa/?view_only=b6dbb5dd6a044989a7eecdc99facb43c.,Data
10.1016/j.neuroimage.2022.119676,https://github.com/Yozafirova/monkey-fMRI-codes,Codes for the fMRI data analysis at https://github.com/Yozafirova/monkey-fMRI-codes and for the CNN data analysis at https://github.com/RajaniRaman/face_body_integration.,Code
10.1016/j.neuroimage.2022.119676,https://github.com/RajaniRaman/face_body_integration,Codes for the fMRI data analysis at https://github.com/Yozafirova/monkey-fMRI-codes and for the CNN data analysis at https://github.com/RajaniRaman/face_body_integration.,Code
