{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7067776c",
   "metadata": {},
   "source": [
    "# Table of contents \n",
    "- [Setup](#setup) \n",
    "    - [Target](#target)\n",
    "    - [Libraries](#libraries)\n",
    "- [Gather datasets](#gatherdatasets)\n",
    "    - [Get content](#getcontent)\n",
    "        - [Evaluation of section patterns (so far)](#evaluationofsectionpatterns(sofar))\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af309d",
   "metadata": {},
   "source": [
    "<a name='setup'></a>\n",
    "# 0. Setup \n",
    "\n",
    "This notebook contains the code to extract the datasets used in the articles published in NeuroImage in 2022. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='target'></a> \n",
    "## 0.1. Target\n",
    "The goal is the use pypdf to locate and extract the datasets used for analysis in the research articles. Based on an initial review of nine random \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='libraries'></a>\n",
    "## 0.2. Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0a00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json \n",
    "import os \n",
    "import re \n",
    "\n",
    "import pypdf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd6525d",
   "metadata": {},
   "source": [
    "<a name='gatherdatasets'></a>\n",
    "# 1. Gather datasets \n",
    "\n",
    "PLAN OF ATTACK TO EXPLORE: \n",
    "* IF - Locate 'Data availability' (or similar) section and look for links - if multiple, save all of them and look at surrounding words for context \n",
    "* ELSE If there is no 'Data availability' (or similar) section \n",
    "\t* Look at wording in section 2.1 \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name='getcontent'></a>\n",
    "## 1.1. Get content \n",
    "\n",
    "I use the work of Akkoç (2023) and Sourget (2023) to search the PDFs for their datasets. I am using the code from two separate git repositories as inspiration for the two functions presented in this section. \n",
    "- *get_section* is losely interpreted from Akkoç (2023) using the following breadcrumb in the github repository: PublicDatasets/ArticleAnalyser.ipynb, section '2.1 Get section function'\n",
    "- *get_content* is losely interpreted from Soruget (2023) using the following breadcrumb in the github repository: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "\n",
    "<br>\n",
    "\n",
    "References: \n",
    "- Akkoç, A. (2023). PublicDatasets [Jupyter Notebook]. https://github.com/madprogramer/PublicDatasets (Original work published 2022)\n",
    "- Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc7a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(pdf_path, section_patterns):\n",
    "    \"\"\"Get a PDF. \n",
    "    This function is losely interpreted from Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget\n",
    "    specifically: DDSA_Sourget/code/other/download_fulltext.ipynb, section '3. Check for dataset's organ in figures'.\n",
    "    \n",
    "    Parameters: \n",
    "    :param pdf_path (str): Path to the PDF file.\n",
    "    :param json_file_path (str): Path to the JSON file containing the DOIs of the relevant research articles. \n",
    "    \n",
    "    Returns: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_file = open(pdf_path, 'rb')\n",
    "        pdf_reader = pypdf.PdfReader(pdf_file)\n",
    "         # Read the entire PDF content\n",
    "        pdf_text = \" \".join(page.extract_text() for page in pdf_reader.pages)\n",
    "        \n",
    "        # Extract sections using the provided section patterns\n",
    "        content = get_section(pdf_text, section_patterns)\n",
    "        if content: \n",
    "            # print(f\"Section content: '{content}''\")\n",
    "            return content \n",
    "        pdf_file.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")  \n",
    "    \n",
    "        \"\"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            print(page_text)\n",
    "            \n",
    "            # Search for the regex pattern in the page text\n",
    "            #if re.search(target_text_pattern, page_text, re.IGNORECASE):\n",
    "            #    print(f\"Found '{target_text_pattern}' on page {page_num + 1} of {pdf_path}\")\n",
    "\n",
    "            # Extract sections using the provided section patterns\n",
    "            content = get_section(page_text, section_patterns)\n",
    "            if content:\n",
    "                print(f\"Section Content: {content}\")\n",
    "        \"\"\"\n",
    "        \n",
    "def get_section(article, section_patterns):\n",
    "    \"\"\"Get sections from a research paper based on patterns.\n",
    "    This function is losely interpreted from Akkoç, A. (2023). PublicDatasets [Jupyter Notebook]. https://github.com/madprogramer/PublicDatasets (Original work published 2022) with some alterations.\n",
    "    specifically PublicDatasets/ArticleAnalyser.ipynb, section '2.1 Get section function'\n",
    "    \n",
    "    Parameters: \n",
    "    :param article (str): Text contents of the research paper.\n",
    "    :param section_patterns (list of lists): A list of lists where each inner list represents the start and end patterns.\n",
    "    \n",
    "    Returns: \n",
    "    :return: The extracted section text.\n",
    "    \"\"\"\n",
    "    article_lower = article.lower()  # Convert contents to lowercase\n",
    "\n",
    "    # Attempt to find the section based on the current patterns (case-insensitive)\n",
    "    for start_patterns, end_patterns in section_patterns:\n",
    "        for start_pattern in start_patterns:\n",
    "            start_pattern = re.compile(re.escape(start_pattern), re.IGNORECASE)\n",
    "            match_start = start_pattern.search(article_lower)\n",
    "            if match_start:\n",
    "                idx0 = match_start.start()\n",
    "                for end_pattern in end_patterns:\n",
    "                    end_pattern = re.compile(re.escape(end_pattern), re.IGNORECASE)\n",
    "                    match_end = end_pattern.search(article_lower[idx0:])\n",
    "                    if match_end:\n",
    "                        end_idx = idx0 + match_end.end()\n",
    "                        section = article[idx0:end_idx]  # Extract the matched section\n",
    "                        return section\n",
    "\n",
    "    # If no match is found, return an empty string\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10f9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing PDFs\n",
    "pdf_directory = '../Data/ElsevierAPI/downloaded_pdfs/fulltext_articles_doi/'\n",
    "\n",
    "# Path to the JSON file containing DOI values\n",
    "json_file_path = '../Data/ElsevierAPI/downloadedPDFs_info.json'\n",
    "\n",
    "section_patterns = [\n",
    "    ([\"Data and Code Availability\", \"Data Availability\"], [\"3\", \"CRediT authorship contribution statement\", \"Acknowledgements\", \"References\"]),\n",
    "    ([\"2.1\"], [\"2.2\"]),\n",
    "    ([\"Resource\", \"3.1 'Resource'\"], [\"3.2\"]),\n",
    "    ([\"Fig.\\d+\", \"Fig.\\d+\\.?\", \"Figure \\d+\"], [\"https?://[^\\s]+\"]),\n",
    "    ([\"Tab.\\d+\", \"Table \\d+\\.?\"], [\"https?://[^\\s]+\", \"[\\w\\s-]+\\d{4}\"]),\n",
    "    ([\"Introduction\", \"1\"], [\"2\"]),\n",
    "    ([\"Abstract\"], [\"1\", \"Introduction\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55515205",
   "metadata": {},
   "source": [
    "<a name='evaluationofsectionpatterns(sofar)'></a>\n",
    "### 1.1.1. Evaluation of section patterns (so far)\n",
    "Before I continue working on extracting the dataset names and potential links from the sections, I am curious to see how the section pattern performs. \n",
    "\n",
    "I investigate the first ten DOIs in downloadedPDFs_info.json() to see exactly what text sections were extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c16b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store individual results\n",
    "results_list = []\n",
    "\n",
    "# Read DOI values from the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    doi_data = json.load(json_file)\n",
    "\n",
    "    # Get the first 10 DOIs\n",
    "    first_10_dois = doi_data['DOIs'][:10]\n",
    "\n",
    "    for doi in first_10_dois:\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(pdf_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content function for each DOI\n",
    "        section_content = get_content(pdf_path, section_patterns)\n",
    "\n",
    "        # Create a dictionary for each result and add it to the list\n",
    "        results_list.append({\"DOI\": doi, \"Section\": section_content})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2f1b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119451</td>\n",
       "      <td>Data and code availability  statements  \\nSpec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119632</td>\n",
       "      <td>Data and code availability  \\nThe data incorpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119584</td>\n",
       "      <td>Data Availability  \\nData will be made availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119550</td>\n",
       "      <td>Data and code availability  \\nAll data used in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119710</td>\n",
       "      <td>Data and code availability  statement  \\nAll i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119338</td>\n",
       "      <td>Data and code availability  \\nNo data were acq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118986</td>\n",
       "      <td>Data and Code Availability  Statement  \\nAll c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119192</td>\n",
       "      <td>Data and code availability  statement  \\nData ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119177</td>\n",
       "      <td>Data and code availability  statement  \\nThe E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119110</td>\n",
       "      <td>Data and code availability  statements  : The ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DOI  \\\n",
       "0  10.1016/j.neuroimage.2022.119451   \n",
       "1  10.1016/j.neuroimage.2022.119632   \n",
       "2  10.1016/j.neuroimage.2022.119584   \n",
       "3  10.1016/j.neuroimage.2022.119550   \n",
       "4  10.1016/j.neuroimage.2022.119710   \n",
       "5  10.1016/j.neuroimage.2022.119338   \n",
       "6  10.1016/j.neuroimage.2022.118986   \n",
       "7  10.1016/j.neuroimage.2022.119192   \n",
       "8  10.1016/j.neuroimage.2022.119177   \n",
       "9  10.1016/j.neuroimage.2022.119110   \n",
       "\n",
       "                                             Section  \n",
       "0  Data and code availability  statements  \\nSpec...  \n",
       "1  Data and code availability  \\nThe data incorpo...  \n",
       "2  Data Availability  \\nData will be made availab...  \n",
       "3  Data and code availability  \\nAll data used in...  \n",
       "4  Data and code availability  statement  \\nAll i...  \n",
       "5  Data and code availability  \\nNo data were acq...  \n",
       "6  Data and Code Availability  Statement  \\nAll c...  \n",
       "7  Data and code availability  statement  \\nData ...  \n",
       "8  Data and code availability  statement  \\nThe E...  \n",
       "9  Data and code availability  statements  : The ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b125b",
   "metadata": {},
   "source": [
    "From this investigation I can see that I need to edit the section patterns, because: \n",
    "* In 10.1016/j.neuroimage.2022.119632, 10.1016/j.neuroimage.2022.119584, 10.1016/j.neuroimage.2022.119710, 10.1016/j.neuroimage.2022.119192, and 10.1016/j.neuroimage.2022.119110, **the text is cut short because there's a mention of a number 3** within the section (in a link, in a release number, etc.). \n",
    "* In 10.1016/j.neuroimage.2022.119584, they call it: 'Data/code availability statement'\n",
    "* In 10.1016/j.neuroimage.2022.119584 and 10.1016/j.neuroimage.2022.119110, the **end of the section can be 'Acknowledgements'**.\n",
    "* In 10.1016/j.neuroimage.2022.119550 and 10.1016/j.neuroimage.2022.118986, the **end of the section can be 'Declaration of Competing Interest'**.\n",
    "* In 10.1016/j.neuroimage.2022.119710, 10.1016/j.neuroimage.2022.119338, and 10.1016/j.neuroimage.2022.119177, the **section ends with 'Credit authorship contribution statement'**.\n",
    "* In 10.1016/j.neuroimage.2022.119338, we see that the use of a **URL does not necessarily mean that it's pointing to data (in this case, it's code and software)**. \n",
    "* In 10.1016/j.neuroimage.2022.118986, we see that **the formulation of the text is important** (as the github link both contains data and code, but that is tricky to see). \n",
    "* In 10.1016/j.neuroimage.2022.119192 and 10.1016/j.neuroimage.2022.119177, they **mention which dataset they used, but do not link it**. \n",
    "* In 10.1016/j.neuroimage.2022.119110, it says: \"The review summarizes data but does not contain new data.\" (this is important if I want to look into and further filter the documents for significance testing). \n",
    "\n",
    "CHANGES: \n",
    "- Maybe the end of a section can be \\n\\n? \n",
    "- Section end '3' should be called '3. ' - maybe this will fix some \n",
    "- Add variations: \n",
    "    - Section starts: \n",
    "        - Data/code availability statement\n",
    "    - Section ends: \n",
    "        - [data and code] Declaration of Competing Interest\n",
    "        - [data and code] Acknowledgements\n",
    "        - [data and code] Credit authorship contribution statement\n",
    "- For future steps: \n",
    "    - URLs do not necessarily link to the data. \n",
    "    - A git repository can contain both data and code - but not always. \n",
    "    - The dataset might only be mentioned by name and not linked (so far, I've only seen the names in camelcase). \n",
    "    - QUESTION: How do we treat reviews that summarizes data but does not contain new data? Is the reuse of a dataset not also the same as not containing new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d0abd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_patterns_v2 = [\n",
    "    ([\"Data and Code Availability\", \"Data Availability\", \"Data/code availability\"], [\"3. \", \"CRediT authorship contribution statement\", \"Acknowledgements\", \"References\", \"Declaration of Competing Interests\", \"Credit authorship contribution statement\", \"\\n\\n\"]),\n",
    "    ([\"2.1.\"], [\"2.2.\"]),\n",
    "    ([\"Resource\", \"3.1.\"], [\"3.2.\"]),\n",
    "    ([\"Fig.\\d+\", \"Fig.\\d+\\.?\", \"Figure \\d+\"], [\"https?://[^\\s]+\"]),\n",
    "    ([\"Tab.\\d+\", \"Table \\d+\\.?\"], [\"https?://[^\\s]+\", \"[\\w\\s-]+\\d{4}\"]),\n",
    "    ([\"Introduction\", \"1. \"], [\"2. \"]),\n",
    "    ([\"Abstract\"], [\"1. \", \"Introduction\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7288886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading PDF: [Errno 2] No such file or directory: '../Data/ElsevierAPI/downloaded_pdfs/fulltext_articles_doi/10.1016.S1053-8119(22)00043-X.pdf'\n"
     ]
    }
   ],
   "source": [
    "# Empty list to store individual results\n",
    "results_list_v2 = []\n",
    "\n",
    "# Read DOI values from the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    doi_data = json.load(json_file)\n",
    "\n",
    "    # Get the first 10 DOIs\n",
    "    first_10_dois = doi_data['DOIs'][11:21]\n",
    "\n",
    "    for doi in first_10_dois:\n",
    "        doi_replaced = doi.replace('/', '.')\n",
    "        pdf_path = os.path.join(pdf_directory, f\"{doi_replaced}.pdf\")\n",
    "\n",
    "        # Call the get_content function for each DOI\n",
    "        section_content = get_content(pdf_path, section_patterns_v2)\n",
    "\n",
    "        # Create a dictionary for each result and add it to the list\n",
    "        results_list_v2.append({\"DOI\": doi, \"Section\": section_content})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df2 = pd.DataFrame(results_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ed8e5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118931</td>\n",
       "      <td>Data availability  \\nThe Matlab code for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119447</td>\n",
       "      <td>2.1. Participants  \\nThirty-ﬁve  people (20 fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119403</td>\n",
       "      <td>Data and code availability  statement  \\nData ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118831</td>\n",
       "      <td>Data and code availability  statements  \\nThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119308</td>\n",
       "      <td>Data and code availability  statement  \\nFinni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1016/S1053-8119(22)00043-X</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1016/j.neuroimage.2021.118792</td>\n",
       "      <td>data availability  \\nThe Shen 268 atlas is ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1016/j.neuroimage.2022.118890</td>\n",
       "      <td>data availability  \\nThe code used to run the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119339</td>\n",
       "      <td>Data and code availability  statement  \\nThe h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119295</td>\n",
       "      <td>Introduction  \\nReal-time  functional  magneti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DOI  \\\n",
       "0  10.1016/j.neuroimage.2022.118931   \n",
       "1  10.1016/j.neuroimage.2022.119447   \n",
       "2  10.1016/j.neuroimage.2022.119403   \n",
       "3  10.1016/j.neuroimage.2021.118831   \n",
       "4  10.1016/j.neuroimage.2022.119308   \n",
       "5     10.1016/S1053-8119(22)00043-X   \n",
       "6  10.1016/j.neuroimage.2021.118792   \n",
       "7  10.1016/j.neuroimage.2022.118890   \n",
       "8  10.1016/j.neuroimage.2022.119339   \n",
       "9  10.1016/j.neuroimage.2022.119295   \n",
       "\n",
       "                                             Section  \n",
       "0  Data availability  \\nThe Matlab code for the p...  \n",
       "1  2.1. Participants  \\nThirty-ﬁve  people (20 fe...  \n",
       "2  Data and code availability  statement  \\nData ...  \n",
       "3  Data and code availability  statements  \\nThe ...  \n",
       "4  Data and code availability  statement  \\nFinni...  \n",
       "5                                               None  \n",
       "6  data availability  \\nThe Shen 268 atlas is ava...  \n",
       "7  data availability  \\nThe code used to run the ...  \n",
       "8  Data and code availability  statement  \\nThe h...  \n",
       "9  Introduction  \\nReal-time  functional  magneti...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8b90b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction  \\nReal-time  functional  magnetic  resonance  imaging  (RT-fMRI)  is an \\nemerging  technology  that holds tremendous  promise  for breakthroughs  \\nin basic science  and clinical  applications.  In contrast  to traditional,  of- \\nﬂine fMRI analysis,  RT-fMRI  involves  analyzing  data while participants  \\nare still in the scanner,  giving experimenters  the ability to modify the \\nstimuli or tasks that they present  as a function  of the participant’s  mea- \\nsured neural state. RT-fMRI  can be used in neurofeedback  designs,  in \\nwhich participants  are given feedback  on how well they are instantiat-  \\ning a target brain state, and they use this information  to learn how to \\nbetter instantiate  that state (for a historical  review of fMRI neurofeed-  \\nback, see Linden et al., 2021 ; this review is part of a recent textbook  \\non fMRI neurofeedback  edited by Hampson,  2021 ). In another  use of \\nRT-fMRI,  stimuli are modiﬁed  as a function  of brain activation,  but par- \\n∗ Corresponding  author. \\nE-mail address: knorman@princeton.edu  (K.A. Norman)  . ticipants  are not explicitly  given the goal of maximizing  the goodness  of \\ntheir brain state; for example,  in a triggering  design, the results of the \\nfMRI analysis  are used to determine  when stimuli are presented  (e.g., \\nYoo et al., 2012 ). RT-fMRI  reverses  the typical logic of fMRI –instead  of \\nviewing  the fMRI measurements  as a dependent  variable  (i.e., looking  at \\nthe eﬀects of a task manipulation  on fMRI), the fMRI measurements  can \\nbe viewed  as the independent  variable  (i.e., you can look at the eﬀect of \\ninstantiating  a particular  neural pattern  on other behavioral  and neural \\nmeasurements;  Turk-Browne,  2021 ). \\nPrevious  RT-fMRI  studies have led to a wide range of interesting  dis- \\ncoveries  in healthy  participants.  For instance,  participants  given neu- \\nrofeedback  from the ventral tegmental  area (VTA) while they thought  \\nabout personalized  motivational  states were able to learn to upregulate  \\nVTA activity;  this increase  in the ability to upregulate  VTA activity  per- \\nsisted after the end of neurofeedback  training  ( MacInnes  et al., 2016 ). \\nhttps://doi.org/10.1016/j.neuroimage.2022.119295  . \\nReceived  26 January  2022; Accepted  9 May 2022 \\nAvailable  online 14 May 2022. '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2['Section'].loc[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba088a88",
   "metadata": {},
   "source": [
    "Notes from the second attempt: \n",
    "- In 10.1016/j.neuroimage.2022.118931 - there are links, but these are not to the dataset - they write \"The used data can be shared with other researchers upon reasonable request.\" \n",
    "- In 10.1016/j.neuroimage.2022.118931 and 10.1016/j.neuroimage.2022.118890, the next section is called 'Supplementary materials' - which means that my attempt at \\n\\n did not work.  \n",
    "- In 10.1016/j.neuroimage.2022.119447, the only mention of data was picked up in section 2.1.\n",
    "- In 10.1016/j.neuroimage.2022.119403, the 'Declaration  of Competing  Interest' was not picked up - it looks like it's because there are double spaces between the words. \n",
    "- In 10.1016/j.neuroimage.2021.118831, the 'Credit authorship  contribution  statement' is not picked - double spaces?\n",
    "- In 10.1016/j.neuroimage.2021.118792, the data section is called 'Code and data availability' - but it was picked up by 'data availability'. \n",
    "- In 10.1016/j.neuroimage.2021.118792, there are multiple links mentioned - one for data (an atlas), one for the code, and one for the data. \n",
    "    - NB! When copying the URL for the data, it is broken up by the formatting: https://www.humanconnectome.org/study/hcp-young-adult/ document/1200-subjects-data-release - this is also the case for the atlas. \n",
    "- In 10.1016/j.neuroimage.2022.118890 and 10.1016/j.neuroimage.2022.119339, there are spaces in the URL. \n",
    "- In 10.1016/j.neuroimage.2022.119339, the following section 'Declaration of Competing Interest' was not picked up. \n",
    "- In 10.1016/j.neuroimage.2022.119295, the introduction was picked up: but it does not look like any data is analysed in this article. \n",
    "\n",
    "TO DO: \n",
    "- RESEARCH WHY \\n\\n did not work for section end \n",
    "- Section_patterns that do not work: \n",
    "    - Section_end: \\n\\n\n",
    "    - Section_end: 'Declaration  of Competing  Interest' + Section_end: 'Credit authorship  contribution  statement' + Section_end: 'Supplementary materials'\n",
    "        - double-spaces between words \n",
    "- Section_patterns I'm worried about: \n",
    "    - Section_start: 2.1. - what if it's '2.1'?\n",
    "    - Section_start: 'Code and data availability'\n",
    "- Undiscovered section_patterns: \n",
    "    - Section_end: 'Ethics statement'\n",
    "- Worries \n",
    "    - How to get the name of the dataset itself and the url\n",
    "        - The URL can be broken up by spaces (due to line changes in the pdf) - can I find a way to find out which is the entire URL? \n",
    "            - Is there any slashes in the text ahead? A parenthesis, dot, comma, or another symbol might end it URL. \n",
    "    - If someone uses e.g., HCP, do they use all of the data? Do I need to catch more text-sections to learn this (in relation to the discussion of significance testing - if they use different parts of the dataset, they are not testing on the same). \n",
    "        - \"Due to HCP and dHCP privacy policies, the preprocessed resting-state images of human adults and neonates (with their IDs) can only be shared upon request with qualified investigators who agree to the Restricted Data Use Terms of these two datasets.\" (from 10.1016/j.neuroimage.2022.119339)\n",
    "    - What if the article does not analyse any data? (e.g., 10.1016/j.neuroimage.2022.119295 presents a software package for the execution of RT-fMRI experiments. \n",
    "- FUNCTION GET_CONTENT: Make a comment about trying the \"Editorial board\" texts in the other file - just so I don't get en \"Error reading PDF:\" \n",
    "    - Make an addition to 'get_section' where the says 'Editorial board' instead of None for the section text. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81169768",
   "metadata": {},
   "source": [
    "WHAT I WANT: \n",
    "- A column to indicate which pattern was picked up - that way I can more easily sort and handle difficult cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00febc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34fcfc09",
   "metadata": {},
   "source": [
    "# Save datasets \n",
    "\n",
    "- Store the extracted datasets for further analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac298936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be94c596",
   "metadata": {},
   "source": [
    "# X. References\n",
    "\n",
    "- Akkoç, A. (2023). PublicDatasets [Jupyter Notebook]. https://github.com/madprogramer/PublicDatasets (Original work published 2022)\n",
    "- Sourget, T. (2023). TheoSourget/DDSA_Sourget: Repository used during my travel at the ITU of Copenhagen in March 2023 [Computer software]. https://github.com/TheoSourget/DDSA_Sourget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd51f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_v1(article, section_patterns):\n",
    "    \"\"\"Get a section from a research paper. \n",
    "    \n",
    "    Parameters: \n",
    "    :param contents (): Text contents of the resaerch paper.\n",
    "    :param section_patterns (list): A list of strings to indicate the start and ends of the dataset section.\n",
    "    :return: returns substring of text region between section_header and a potential section_end. returns \"\" if it fails to find it.\n",
    "    \n",
    "    This function is adapted from Akkoç, A. (2023). PublicDatasets [Jupyter Notebook]. https://github.com/madprogramer/PublicDatasets (Original work published 2022) with some alterations.\n",
    "    \"\"\"\n",
    "    contents_lower = article.lower()  # Convert contents to lowercase\n",
    "    \n",
    "    \"\"\"THE CODE BELOW DOES WHAT I WANT IT TO DO\"\"\"\n",
    "    #test_start = r'data and code'\n",
    "    #test_end = r'availability'\n",
    "    #idx0 = contents_lower.find(test_start)\n",
    "    #if idx0 != -1:\n",
    "        #idxend = contents_lower.find(test_end, idx0)  # Start searching for test_end from idx0\n",
    "        #if idxend != -1:\n",
    "            #section = article[idx0:idxend]  # \"+ len(test_end)\" to include the end pattern in the extracted section\n",
    "            #print(section)\n",
    "\n",
    "    # If no match is found, return an empty string\n",
    "    return \"\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
